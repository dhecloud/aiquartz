{"index":{"links":{"/10-things-you-should-know-about-dialogue":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"},{"source":"/10-things-you-should-know-about-dialogue","target":"/July-24th-2020","text":"July 24th, 2020"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Act","text":"Dialogue Act"},{"source":"/10-things-you-should-know-about-dialogue","target":"/TriPy","text":"TriPy"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/10-things-you-should-know-about-dialogue","target":"/BLEU","text":"BLEU"},{"source":"/10-things-you-should-know-about-dialogue","target":"/ROUGE","text":"ROUGE"},{"source":"/10-things-you-should-know-about-dialogue","target":"/METEOR","text":"METEOR"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Ravenclaw-dialogue-system","text":"Ravenclaw dialogue system"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Modelling","text":"Dialogue Modelling"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Reinforcement-Learning","text":"Reinforcement Learning"}],"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Yongjing-Yin","text":"Yongjing Yin"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Fandong-Meng","text":"Fandong Meng"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jinsong-Su","text":"Jinsong Su"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Chulun-Zhou","text":"Chulun Zhou"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Zhengyuan-Yang","text":"Zhengyuan Yang"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jiebo-Luo","text":"Jiebo Luo"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/December-23rd-2020","text":"December 23rd 2020"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi30k","text":"Multi30k"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/MSCOCO","text":"MSCOCO"}],"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rogers","text":"Anna Rogers"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Olga-Kovaleva","text":"Olga Kovaleva"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rumshisky","text":"Anna Rumshisky"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/January-12th-2021","text":"January 12th 2021"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Part-of-Speech","text":"Part of Speech"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Predicate-Agreement","text":"Subject-Predicate Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Cloze-Task","text":"Cloze Task"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Named-Entity","text":"Named Entity"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Tacit-Knowledge","text":"Tacit Knowledge"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Probing","text":"Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Isotropy","text":"Isotropy"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Embeddings","text":"Embeddings"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Word-Sense-Disambiguation","text":"Word Sense Disambiguation"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reflexive-Anaphora","text":"Reflexive Anaphora"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/self-attention","text":"self-attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Denoising","text":"Denoising"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Mixout","text":"Mixout"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Turing-NLG","text":"Turing-NLG"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GPT-3","text":"GPT-3"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Neural-Machine-Translation","text":"NMT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Abstractive-Summarization","text":"Abstractive Summarization"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Sentence-Subject-Detection","text":"Sentence Subject Detection"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Quantization","text":"Quantization"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Natural-Language-Inference","text":"Natural Language Inference"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reading-Comprehension","text":"Reading Comprehension"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Text-Classification","text":"Text Classification"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/datasets","text":"datasets"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"}],"/A-Robust-Framework-For-Acoustic-Scene-Classification":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mixup","text":"Mixup"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"}],"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Yi-Ren","text":"Yi Ren"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Jinglin-Liu","text":"Jinglin Liu"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Xu-Tan","text":"Xu Tan"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Zhou-Zhao","text":"Zhou Zhao"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Sheng-Zhao","text":"Sheng Zhao"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Transformer","text":"Transformer"}],"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Ryo-Masumura","text":"Ryo Masumura"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Kyosuke-Nishida","text":"Kyosuke Nishida"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Shoichiro-Saito","text":"Shoichiro Saito"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Transformer","text":"Transformer"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/BLEU","text":"BLEU"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Scaffolding","text":"Scaffolding"}],"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Margaret-Li","text":"Margaret Li"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Stephen-Roller","text":"Stephen Roller"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/June-24th-2020","text":"June 24th, 2020"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"}],"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Cem-Subakan","text":"Cem Subakan"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirco-Ravanelli","text":"Mirco Ravanelli"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Samuele-Cornell","text":"Samuele Cornell"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirko-Bronzi","text":"Mirko Bronzi"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Jianyuan-Zhong","text":"Jianyuan Zhong"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/05-Feb-2022","text":"05-Feb-2022"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Sepformer","text":"Sepformer"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Speech-Separation","text":"Speech Separation"}],"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Yusong-Wu","text":"Yusong Wu"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Kun-Chen","text":"Kun Chen"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Ziyue-Wang","text":"Ziyue Wang"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xuan-Zhang","text":"Xuan Zhang"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Fudong-Nian","text":"Fudong Nian"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Shengchen-Li","text":"Shengchen Li"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xi-Shao","text":"Xi Shao"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Transformer","text":"Transformer"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Clotho-dataset","text":"Clotho dataset"}],"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Mustafa-Sert","text":"Mustafa Sert"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Embeddings","text":"Embeddings"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Clotho-dataset","text":"Clotho dataset"}],"/Accelerating-Machine-Learning-with-Confidential-Computing":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Alex-Shamis","text":"Alex Shamis"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Stavros-Volos","text":"Stavros Volos"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Trusted-Execution-Environments","text":"Trusted Execution Environments"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"}],"/Adaptive-Mean-Margin":[{"source":"/Adaptive-Mean-Margin","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"}],"/Adjacency":[{"source":"/Adjacency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Advancing-Visual-Intelligence-via-Neural-System-Design":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Hengshuang-Zhao","text":"Hengshuang Zhao"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/January-27th-2021","text":"January 27th 2021"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Semantic-Segmentation","text":"Semantic Segmentation"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Pyramid-Scene-Parsing-Network","text":"Pyramid Scene Parsing Network"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/3D-Point-Cloud-Estimation","text":"3D Point Cloud Estimation"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Point-Transformer","text":"Point Transformer"}],"/Alan-Turing-The-Enigma":[{"source":"/Alan-Turing-The-Enigma","target":"/Andrew-Hodges","text":"Andrew Hodges"},{"source":"/Alan-Turing-The-Enigma","target":"/July-31st-2020","text":"July 31st, 2020"}],"/Amnesic-Probing":[{"source":"/Amnesic-Probing","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"}],"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Anh-Nguyen","text":"Anh Nguyen"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Khoa-Pham","text":"Khoa Pham"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dat-Ngo","text":"Dat Ngo"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Thanh-Ngo","text":"Thanh Ngo"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dropout","text":"Dropout"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"}],"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Chris-Baume","text":"Chris Baume"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Qiuqiang-Kong","text":"Qiuqiang Kong"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Tassadaq-Hussain","text":"Tassadaq Hussain"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/AudioSet","text":"AudioSet"}],"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Chulhee-Yun","text":"Chulhee Yun"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Srinadh-Bhojanapalli","text":"Srinadh Bhojanapalli"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Ankit-Singh-Rawat","text":"Ankit Singh Rawat"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Sanjiv-Kumar","text":"Sanjiv Kumar"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/May-28th-2020","text":"May 28th, 2020"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"}],"/Artificial-Intelligence-AI-in-Education":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/August-28th-2020","text":"August 28th, 2020"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Intelligent-Tutoring-Systems-ITS","text":"Intelligent Tutoring Systems (ITS)"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Natural-Language-Processing","text":"Natural Language Processing"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Facial-Recognition","text":"Facial Recognition"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Augmented-Reality","text":"Augmented Reality"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Virtual-Reality","text":"Virtual Reality"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Dragan-Gasevic","text":"Dragan Gasevic"}],"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Kai-Yu","text":"Kai Yu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Pooling","text":"Pooling"}],"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings":[{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Mustafa-Sert","text":"Mustafa Sert"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/AudioCaps","text":"AudioCaps"}],"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daisuke-Niizumi","text":"Daisuke Niizumi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/GPT-2","text":"GPT-2"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/VGGish","text":"VGGish"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BertScore","text":"BertScore"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/AudioCaps","text":"AudioCaps"}],"/Audio-Grounding-dataset":[{"source":"/Audio-Grounding-dataset","target":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","text":"TEXT-TO-AUDIO GROUNDING - BUILDING CORRESPONDENCE BETWEEN CAPTIONS AND SOUND EVENTS"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Grounding-dataset","target":"/AudioSet","text":"AudioSet"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"}],"/AudioCaps":[{"source":"/AudioCaps","target":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","text":"AudioCaps - Generating Captions for Audios in The Wild"}],"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Chris-Dongjoo-Kim","text":"Chris Dongjoo Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Byeongchang-Kim","text":"Byeongchang Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Hyunmin-Lee","text":"Hyunmin Lee"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Gunhee-Kim","text":"Gunhee Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/February-10th-2021","text":"February 10th 2021"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioCaps","text":"AudioCaps"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioSet","text":"AudioSet"}],"/Automated-Audio-Captioning":[{"source":"/Automated-Audio-Captioning","target":"/Speech-Recognition","text":"Speech Recognition"}],"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks":[{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Sharath-Adavanne","text":"Sharath Adavanne"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/BLEU","text":"BLEU"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/PSE-library","text":"PSE library"}],"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification":[{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Yue-Lang","text":"Yue Lang"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Bag-of-Features","text":"Bag of Features"}],"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Maarten-De-Vos","text":"Maarten De Vos"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/May-18th-2021","text":"May 18th 2021"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Accuracy","text":"Accuracy"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/F1-score","text":"F1 score"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"}],"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mechanism-Design-for-Social-Good","text":"Mechanism Design for Social Good"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"}],"/BiLSTM":[{"source":"/BiLSTM","target":"/LSTM","text":"LSTM"}],"/Big-Bird-Transformers-for-Longer-Sequences":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Manzil-Zaheer","text":"Manzil Zaheer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Guru-Guruganesh","text":"Guru Guruganesh"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Avinava-Dubey","text":"Avinava Dubey"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Joshua-Ainslie","text":"Joshua Ainslie"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Chris-Alberti","text":"Chris Alberti"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Santiago-Ontanon","text":"Santiago Ontanon"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Philip-Pham","text":"Philip Pham"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Anirudh-Ravula","text":"Anirudh Ravula"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Qifan-Wang","text":"Qifan Wang"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Li-Yang","text":"Li Yang"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Amr-Ahmed","text":"Amr Ahmed"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/August-11th-2020","text":"August 11th, 2020"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/BigBird","text":"BigBird"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Erd%C5%91s-R%C3%A9nyi-model","text":"Erdős-Rényi model"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Spectral-Graph","text":"Spectral Graph"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Small-World-Graphs","text":"Small World Graphs"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/clustering-coefficient","text":"clustering coefficient"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Orthogonal-Vector-Conjecture","text":"Orthogonal Vector Conjecture"}],"/Big-Ideas-in-Causality-and-Machine-Learning":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Pearl-Causal-Hierarchy","text":"Pearl Causal Hierarchy"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Bayes-Network","text":"Bayes Network"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Decision-Trees","text":"Decision Trees"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Deep-Causal-Manipulation-Augmented-Model","text":"Deep Causal Manipulation Augmented Model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"}],"/Bilinear-Models":[{"source":"/Bilinear-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"}],"/Bootstrap-Your-Own-Latent":[{"source":"/Bootstrap-Your-Own-Latent","target":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","text":"Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning"}],"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Jean-Bastien-Grill","text":"Jean-Bastien Grill"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florian-Strub","text":"Florian Strub"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florent-Altche","text":"Florent Altche"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Corentin-Tallec","text":"Corentin Tallec"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Elena-Buchatskaya","text":"Elena Buchatskaya"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Carl-Doersch","text":"Carl Doersch"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bernado-Avila-Pires","text":"Bernado Avila Pires"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Zhaohan-Daniel-Guo","text":"Zhaohan Daniel Guo"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Mohammad-Gheshlaghi-Azar","text":"Mohammad Gheshlaghi Azar"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bilal-Piot","text":"Bilal Piot"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Koray-Kavukcuoglu","text":"Koray Kavukcuoglu"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Remi-Munos","text":"Remi Munos"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Michal-Valko","text":"Michal Valko"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Contrastive-Loss","text":"Contrastive Loss"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"}],"/Break-into-Natural-Language-Processing":[{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"},{"source":"/Break-into-Natural-Language-Processing","target":"/Marti-Hearst","text":"Marti Hearst"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"},{"source":"/Break-into-Natural-Language-Processing","target":"/July-30th-2020","text":"July 30th, 2020"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/Transformer","text":"Transformer"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-2","text":"GPT-2"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"},{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"}],"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zelin-Zhou","text":"Zelin Zhou"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zhiling-Zhang","text":"Zhiling Zhang"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zeyu-Xie","text":"Zeyu Xie"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/05-Jan-2022","text":"05-Jan-2022"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Fluency-ENhanced-Sentence-bert-Evaluation","text":"FENSE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/METEOR","text":"METEOR"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/TF-IDF","text":"TF-IDF"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/cosine-similarity","text":"cosine similarity"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"}],"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Eric-Jang","text":"Eric Jang"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Shixiang-Gu","text":"Shixiang Gu"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Ben-Poole","text":"Ben Poole"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Max-trick","text":"Gumbel-Max trick"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Distribution","text":"Gumbel Distribution"}],"/CE7429-Computational-Intelligence-Methods-and-Applications":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-2","text":"CE7429 - Lecture 2"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-3","text":"CE7429 - Lecture 3"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-4","text":"CE7429 - Lecture 4"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-5","text":"CE7429 - Lecture 5"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-6","text":"CE7429 - Lecture 6"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-7","text":"CE7429 - Lecture 7"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-8","text":"CE7429 - Lecture 8"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-9","text":"CE7429 - Lecture 9"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-10","text":"CE7429 - Lecture 10"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-11","text":"CE7429 - Lecture 11"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-12","text":"CE7429 - Lecture 12"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-13","text":"CE7429 - Lecture 13"}],"/CE7429-Lecture-10":[{"source":"/CE7429-Lecture-10","target":"/September-8th-2020","text":"September 8th, 2020"},{"source":"/CE7429-Lecture-10","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"}],"/CE7429-Lecture-11":[{"source":"/CE7429-Lecture-11","target":"/September-15th-2020","text":"September 15th, 2020"}],"/CE7429-Lecture-12":[{"source":"/CE7429-Lecture-12","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/CE7429-Lecture-12","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/CE7429-Lecture-12","target":"/Knowledge-Based-Agents","text":"Knowledge Based Agents"},{"source":"/CE7429-Lecture-12","target":"/Memory","text":"Memory"}],"/CE7429-Lecture-13":[{"source":"/CE7429-Lecture-13","target":"/September-22nd-2020","text":"September 22nd, 2020"},{"source":"/CE7429-Lecture-13","target":"/Semantic-Memory-Duration","text":"Semantic Memory Duration"},{"source":"/CE7429-Lecture-13","target":"/Catastrophic-Forgetting","text":"Catastrophic Forgetting"},{"source":"/CE7429-Lecture-13","target":"/Modal-Memory-Model-SOAR","text":"Modal Memory Model (SOAR)"},{"source":"/CE7429-Lecture-13","target":"/Sensory-Memory","text":"Sensory Memory"},{"source":"/CE7429-Lecture-13","target":"/Short-Term-Memory","text":"Short Term Memory"},{"source":"/CE7429-Lecture-13","target":"/Long-Term-Memory","text":"Long Term Memory"},{"source":"/CE7429-Lecture-13","target":"/Adaptive-Character-of-Thought-ACT-Memory-Model","text":"Adaptive Character of Thought (ACT) Memory Model"},{"source":"/CE7429-Lecture-13","target":"/Working-Memory-Model","text":"Working Memory Model"},{"source":"/CE7429-Lecture-13","target":"/Chunking","text":"Chunking"}],"/CE7429-Lecture-2":[{"source":"/CE7429-Lecture-2","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/CE7429-Lecture-2","target":"/Computational-Intelligence","text":"Computational Intelligence"}],"/CE7429-Lecture-3":[{"source":"/CE7429-Lecture-3","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/CE7429-Lecture-3","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"},{"source":"/CE7429-Lecture-3","target":"/Bayes-Theorem","text":"Bayes Theorem"}],"/CE7429-Lecture-4":[{"source":"/CE7429-Lecture-4","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/CE7429-Lecture-4","target":"/Starplots","text":"Starplots"}],"/CE7429-Lecture-5":[{"source":"/CE7429-Lecture-5","target":"/August-21st-2020","text":"August 21st, 2020"},{"source":"/CE7429-Lecture-5","target":"/Chernoff-Faces","text":"Chernoff Faces"},{"source":"/CE7429-Lecture-5","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"},{"source":"/CE7429-Lecture-5","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-5","target":"/Mahalanobis-Distance","text":"Mahalanobis Distance"}],"/CE7429-Lecture-6":[{"source":"/CE7429-Lecture-6","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Discriminant-Component-Analysis","text":"Discriminant Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-6","target":"/Linear-Discriminant-Analysis","text":"Linear Discriminant Analysis"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"}],"/CE7429-Lecture-7":[{"source":"/CE7429-Lecture-7","target":"/August-28th-2020","text":"August 28th, 2020"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Expectation-Mean","text":"Expectation (Mean)"},{"source":"/CE7429-Lecture-7","target":"/Moments","text":"Moments"},{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"},{"source":"/CE7429-Lecture-7","target":"/Normal-Distribution","text":"Normal Distribution"},{"source":"/CE7429-Lecture-7","target":"/Non-Gaussianity","text":"Non-Gaussianity"},{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"},{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"},{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Models-of-Self-Organization","text":"Models of Self-Organization"},{"source":"/CE7429-Lecture-7","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"},{"source":"/CE7429-Lecture-7","target":"/Senso-motoric-Maps","text":"Senso-motoric Maps"},{"source":"/CE7429-Lecture-7","target":"/Somatosensoric-Maps","text":"Somatosensoric Maps"}],"/CE7429-Lecture-8":[{"source":"/CE7429-Lecture-8","target":"/September-1st-2020","text":"September 1st, 2020"},{"source":"/CE7429-Lecture-8","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"}],"/CE7429-Lecture-9":[{"source":"/CE7429-Lecture-9","target":"/September-4th-2020","text":"September 4th, 2020"},{"source":"/CE7429-Lecture-9","target":"/cross-validation","text":"cross validation"},{"source":"/CE7429-Lecture-9","target":"/Curse-of-Dimensionality","text":"Curse of Dimensionality"},{"source":"/CE7429-Lecture-9","target":"/Confusion-Matrix","text":"Confusion Matrix"},{"source":"/CE7429-Lecture-9","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"}],"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism","text":"Graph Isomorphism"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Aggregator-Functions","text":"Aggregator Functions"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Injective","text":"Injective"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Principal-Neighbourhood-Aggregation","text":"Principal Neighbourhood Aggregation"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Feed-forward","text":"Feed-forward"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Symmetric","text":"Symmetry"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Equivariant","text":"Equivariance"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"k-WL tests"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Substructure-Networks","text":"Graph Substructure Networks"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Complexity","text":"Complexity"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/RingGNNs","text":"RingGNNs"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Low-Rank-Global-Attention","text":"Graph Low-Rank Global Attention"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Stochastic-Gradient-Descent","text":"SGD"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism-Networks","text":"GINs"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Node-Positional-Encodings","text":"Node Positional Encodings"}],"/CE7491-Lecture-1":[{"source":"/CE7491-Lecture-1","target":"/Field-of-View","text":"Field of View"},{"source":"/CE7491-Lecture-1","target":"/Depth-of-Field","text":"Depth of Field"},{"source":"/CE7491-Lecture-1","target":"/Gray-Level-Indexing","text":"Gray-Level Indexing"},{"source":"/CE7491-Lecture-1","target":"/Image-Dithering","text":"Image Dithering"}],"/CE7491-Lecture-2":[{"source":"/CE7491-Lecture-2","target":"/August-19th-2020","text":"August 19th, 2020"},{"source":"/CE7491-Lecture-2","target":"/Point-Processing","text":"Point Processing"},{"source":"/CE7491-Lecture-2","target":"/Spatial-Filtering","text":"Spatial Filtering"},{"source":"/CE7491-Lecture-2","target":"/Image-Negatives","text":"Image Negatives"},{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"},{"source":"/CE7491-Lecture-2","target":"/Averaging-Filter","text":"Averaging Filter"},{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"},{"source":"/CE7491-Lecture-2","target":"/High-Boost-Filtering","text":"High Boost Filtering"},{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"},{"source":"/CE7491-Lecture-2","target":"/Median-Filtering","text":"Median Filtering"},{"source":"/CE7491-Lecture-2","target":"/Histogram-Equalization","text":"Histogram Equalization"},{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"}],"/CE7491-Lecture-3":[{"source":"/CE7491-Lecture-3","target":"/August-26th-2020","text":"August 26th, 2020"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Quantitative-Color-Specification","text":"Quantitative Color Specification"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Color-Theory","text":"Tristimulus Color Theory"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Grassmanns-Law","text":"Grassmann's Law"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Luminance","text":"Luminance"},{"source":"/CE7491-Lecture-3","target":"/Chromaticity","text":"Chromaticity"},{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Values","text":"Tristimulus Values"},{"source":"/CE7491-Lecture-3","target":"/Subtractive-Color-Mixing","text":"Subtractive Color Mixing"},{"source":"/CE7491-Lecture-3","target":"/Sobel-Gradient","text":"Sobel Gradient"},{"source":"/CE7491-Lecture-3","target":"/Laplacian-of-Gaussian-Filter","text":"Laplacian of Gaussian Filter"},{"source":"/CE7491-Lecture-3","target":"/Canny-Edge-Detector","text":"Canny Edge Detector"},{"source":"/CE7491-Lecture-3","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"},{"source":"/CE7491-Lecture-3","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"},{"source":"/CE7491-Lecture-3","target":"/Hough-Transform","text":"Hough Transform"}],"/CE7491-Lecture-4":[{"source":"/CE7491-Lecture-4","target":"/September-2nd-2020","text":"September 2nd, 2020"},{"source":"/CE7491-Lecture-4","target":"/Pooling","text":"Pooling"}],"/CE7491-Lecture-5":[{"source":"/CE7491-Lecture-5","target":"/September-9th-2020","text":"September 9th, 2020"},{"source":"/CE7491-Lecture-5","target":"/Batch-Normalization","text":"Batch Normalization"},{"source":"/CE7491-Lecture-5","target":"/Switchable-Normalization","text":"Switchable Normalization"}],"/CE7491-Lecture-6":[{"source":"/CE7491-Lecture-6","target":"/September-16th-2020","text":"September 16th, 2020"},{"source":"/CE7491-Lecture-6","target":"/Region-Proposal-Network","text":"Region Proposal Network"},{"source":"/CE7491-Lecture-6","target":"/Faster-R-CNN","text":"Faster R-CNN"},{"source":"/CE7491-Lecture-6","target":"/Image-Restoration","text":"Image Restoration"},{"source":"/CE7491-Lecture-6","target":"/Super-Resolution","text":"Super-Resolution"},{"source":"/CE7491-Lecture-6","target":"/Deconvolution-Transposed-Convolution","text":"Deconvolution (Transposed Convolution)"},{"source":"/CE7491-Lecture-6","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"}],"/CE7491-Lecture-7":[{"source":"/CE7491-Lecture-7","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/CE7491-Lecture-7","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-7","target":"/Super-Resolution","text":"Super-Resolution"},{"source":"/CE7491-Lecture-7","target":"/GAN-Inversion","text":"GAN-Inversion"},{"source":"/CE7491-Lecture-7","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"}],"/CE7491-Lecture-8":[{"source":"/CE7491-Lecture-8","target":"/October-7th-2020","text":"October 7th, 2020"},{"source":"/CE7491-Lecture-8","target":"/Image-to-Image-Translation","text":"Image-to-Image Translation"},{"source":"/CE7491-Lecture-8","target":"/Deep-Fakes","text":"Deep Fakes"},{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/CE7491-Lecture-8","target":"/Latent-Space","text":"Latent Space"},{"source":"/CE7491-Lecture-8","target":"/Neural-Network","text":"Neural Network"},{"source":"/CE7491-Lecture-8","target":"/Properties","text":"Properties"},{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/CE7491-Lecture-8","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"},{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"},{"source":"/CE7491-Lecture-8","target":"/Mode-Collapse","text":"Mode Collapse"},{"source":"/CE7491-Lecture-8","target":"/Task-Regularization","text":"Task Regularization"}],"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-1","text":"CE7491 Lecture 1"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-2","text":"CE7491 Lecture 2"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-3","text":"CE7491 Lecture 3"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-4","text":"CE7491 Lecture 4"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-5","text":"CE7491 Lecture 5"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-6","text":"CE7491 Lecture 6"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-7","text":"CE7491 Lecture 7"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-8","text":"CE7491 Lecture 8"}],"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Thomas-Lidy","text":"Thomas Lidy"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Alexander-Schindler","text":"Alexander Schindler"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/TUT-acoustic-scenes-2016","text":"TUT acoustic scenes 2016"}],"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT":[{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Augustin-Arnault","text":"Augustin Arnault"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Nicolas-Riche","text":"Nicolas Riche"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/TALNet","text":"TALNet"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Time2Vec","text":"Time2Vec"}],"/CZ1104-Lecture-6.1":[{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Unit-Vector","text":"Unit Vector"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Dot-Product","text":"Dot Product"},{"source":"/CZ1104-Lecture-6.1","target":"/Cauchy-Schwarz-Inequality","text":"Cauchy-Schwarz Inequality"}],"/CZ1104-Lecture-6.2":[{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonality"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Point-Normal-Equations","text":"Point Normal Equations"},{"source":"/CZ1104-Lecture-6.2","target":"/Standard-Basis","text":"Standard Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Pythagoras-Theorem","text":"Pythagoras Theorem"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthonormal","text":"Orthonormal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Best-Approximation-Theorem","text":"Best Approximation Theorem"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"}],"/CZ1104-Lecture-6.3":[{"source":"/CZ1104-Lecture-6.3","target":"/Span","text":"Span"},{"source":"/CZ1104-Lecture-6.3","target":"/Gram-Schmidt","text":"Gram Schmidt"},{"source":"/CZ1104-Lecture-6.3","target":"/QR-Factorization","text":"QR Factorization"}],"/CZ1104-Lecture-7.1":[{"source":"/CZ1104-Lecture-7.1","target":"/Consistency-in-a-System-of-Equations","text":"Consistency in a System of Equations"},{"source":"/CZ1104-Lecture-7.1","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"},{"source":"/CZ1104-Lecture-7.1","target":"/Orthogonal-Decomposition-Thereom","text":"Orthogonal Decomposition Thereom"},{"source":"/CZ1104-Lecture-7.1","target":"/Projection-Matrix","text":"Projection Matrix"}],"/CZ1104-Lecture-7.2":[{"source":"/CZ1104-Lecture-7.2","target":"/Binary-Matrix-Operations","text":"Binary Matrix Operations"},{"source":"/CZ1104-Lecture-7.2","target":"/BC","text":"A"},{"source":"/CZ1104-Lecture-7.2","target":"/Invertibility","text":"Invertibility"},{"source":"/CZ1104-Lecture-7.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-7.2","target":"/Trace","text":"Trace"},{"source":"/CZ1104-Lecture-7.2","target":"/Determinant","text":"Determinant"}],"/CZ1104-Lecture-8.1":[{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Singular-Values","text":"Singular Values"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"},{"source":"/CZ1104-Lecture-8.1","target":"/Singular","text":"Singular"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"},{"source":"/CZ1104-Lecture-8.1","target":"/Spectrum","text":"Spectrum"},{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space-kernel","text":"Null Space (kernel)"},{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"},{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"},{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space","text":"Null Space"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/CZ1104-Lecture-8.1","target":"/Spectral-Decomposition","text":"Spectral Decomposition"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"}],"/CZ1104-Lecture-8.2":[{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Spectral-Theorem","text":"Spectral Theorem"},{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Similar","text":"Similar"},{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Transform","text":"Similarity Transform"},{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Invariant","text":"Similarity Invariant"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigendecomposition","text":"Eigendecomposition"}],"/CZ1104-Lecture-8.4":[{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.4","target":"/Matrix-Approximation","text":"Matrix Approximation"},{"source":"/CZ1104-Lecture-8.4","target":"/Condition-Number","text":"Condition Number"},{"source":"/CZ1104-Lecture-8.4","target":"/Moore-Penrose-Pseudoinverse","text":"Moore-Penrose Pseudoinverse"},{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Four-Fundamental-Subspaces","text":"Four Fundamental Subspaces"}],"/Catch-the-Tails-of-BERT":[{"source":"/Catch-the-Tails-of-BERT","target":"/Ziyang-Luo","text":"Ziyang Luo"},{"source":"/Catch-the-Tails-of-BERT","target":"/November-26th-2020","text":"November 26th, 2020"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"},{"source":"/Catch-the-Tails-of-BERT","target":"/SST-2","text":"SST-2"},{"source":"/Catch-the-Tails-of-BERT","target":"/Anisotropy","text":"Anisotropy"},{"source":"/Catch-the-Tails-of-BERT","target":"/geometry","text":"geometry"},{"source":"/Catch-the-Tails-of-BERT","target":"/cosine-similarity","text":"cosine similarity"},{"source":"/Catch-the-Tails-of-BERT","target":"/self-similarity","text":"self-similarity"},{"source":"/Catch-the-Tails-of-BERT","target":"/WiC","text":"WiC"}],"/Cheby-Filter":[{"source":"/Cheby-Filter","target":"/Poly-Filter","text":"Poly-Filter"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/Cheby-Filter","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"}],"/Clotho-An-Audio-Captioning-Dataset":[{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Samuel-Lipping","text":"Samuel Lipping"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/February-10th-2021","text":"February 10th 2021"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"}],"/Clotho-dataset":[{"source":"/Clotho-dataset","target":"/https//github.com/audio-captioning/clotho-datasethttps//github.com/audio-captioning/clotho-dataset","text":"github"},{"source":"/Clotho-dataset","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"}],"/Color-Indexing":[{"source":"/Color-Indexing","target":"/September-25th-2020","text":"September 25th, 2020"},{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"},{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"},{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"},{"source":"/Color-Indexing","target":"/Incremental-Intersection","text":"Incremental Intersection"},{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"}],"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control":[{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"}],"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers":[{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Neural-Network","text":"Neural Network"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"}],"/Compositional-Rule-of-Inference":[{"source":"/Compositional-Rule-of-Inference","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Compositional-Rule-of-Inference","target":"/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning","text":"The Concept of a Linguistic Variable and its Application to Approximate Reasoning"},{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-Rule-of-Inference","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-Rule-of-Inference","target":"/Generalized-Modus-Ponens","text":"Generalized [[Modus Ponens"}],"/Compositional-rule-of-inference-as-an-analogical-scheme":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Bernadette-Bouchon-Meunier","text":"Bernadette Bouchon-Meunier"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Radko-Mesiar","text":"Radko Mesiar"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Christophe-Marsala","text":"Christophe Marsala"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Maria-Rifqi","text":"Maria Rifqi"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Fuzzy-Deductive-Reasoning","text":"Fuzzy Deductive Reasoning"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Analogical-Scheme","text":"Analogical Scheme"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"}],"/Connected-Component":[{"source":"/Connected-Component","target":"/Connected-Component","text":"Connected Component"},{"source":"/Connected-Component","target":"/Connected-Graph","text":"Connected Graph"}],"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Liang-Ding","text":"Liang Ding"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Longyue-Wang","text":"Longyue Wang"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Di-Wu","text":"Di Wu"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Dacheng-Tao","text":"Dacheng Tao"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/November-26th-2020","text":"November 26th, 2020"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Local-Entropy","text":"Local Entropy"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"}],"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State":[{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Ana-Peleteiro-Ramallo","text":"Ana Peleteiro Ramallo"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/December-2nd-2020","text":"December 2nd 2020"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Transformer","text":"Transformer"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"}],"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Micha%C3%ABl-Defferrard","text":"Michaël Defferrard"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Xavier-Bresson","text":"Xavier Bresson"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Pierre-Vandergheynst","text":"Pierre Vandergheynst"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/December-15th-2020","text":"December 15th 2020"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Kronecker-Delta","text":"Kronecker Delta"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Lanczos-algorithm","text":"Lanczos algorithm"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/MNIST","text":"MNIST"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/20NEWS","text":"20NEWS"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"}],"/Coreference":[{"source":"/Coreference","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Covid19-politifact":[{"source":"/Covid19-politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"}],"/Covid19-scientific":[{"source":"/Covid19-scientific","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"}],"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jisheng-Bai","text":"Jisheng Bai"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Chen-Chen","text":"Chen Chen"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mou-Wang","text":"Mou Wang"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jiangfeng-Chen","text":"Jiangfeng Chen"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Xiaolei-Zhang","text":"Xiaolei Zhang"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Qingli-Yan","text":"Qingli Yan"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mixup","text":"Mixup"}],"/DailyDialog":[{"source":"/DailyDialog","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"}],"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Yanran-Li","text":"Yanran Li"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Hui-Su","text":"Hui Su"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Xiaoyu-Shen","text":"Xiaoyu Shen"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Wenjie-Li","text":"Wenjie Li"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Ziqiang-Cao","text":"Ziqiang Cao"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Shuzi-Niu","text":"Shuzi Niu"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"}],"/Decoding-and-Diversity-in-Machine-Translation":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Nicholas-Roberts","text":"Nicholas Roberts"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/David-Liang","text":"David Liang"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/January-7th-2021","text":"January 7th 2021"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BERT","text":"BERT"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"}],"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio":[{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/KL-divergence","text":"KL-divergence"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Mixup","text":"Mixup"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Triplet-Loss","text":"Triplet Loss"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Scaffolding","text":"Scaffolding"}],"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification":[{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Alexander-Schindler","text":"Alexander Schindler"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mina-Schutz","text":"Mina Schutz"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Jasmin-Pielorz","text":"Jasmin Pielorz"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Sven-Schlarb","text":"Sven Schlarb"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Ross-King","text":"Ross King"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"}],"/Deep-Learning-On-Graphs-Chapter-1-Introduction":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Deep-Learning-on-Graphs","text":"Deep Learning on Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Machine-Learning","text":"Machine Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/K-means-clustering","text":"K-means clustering"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/skip-gram","text":"skip-gram"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/word2vec","text":"word2vec"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Pooling","text":"Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Scalabilty","text":"Scalabilty"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"}],"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/WIKIHOP-dataset","text":"WIKIHOP dataset"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Entity-GCN","text":"Entity-GCN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GGNN-Filter","text":"GGNN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Simple-Graph","text":"Simple Graph"}],"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree","text":"Degree"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Neighbors","text":"Neighbors"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Walk","text":"Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Trail","text":"Trail"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Path","text":"Path"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Subgraph","text":"Subgraph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Connected-Component","text":"Connected Component"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Shortest-Path","text":"Shortest Path"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Diameter","text":"Diameter"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree-Centrality","text":"Degree Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Katz-Centrality","text":"Katz Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Betweenness-Centrality","text":"Betweenness Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Discrete-Dynamic-Graphs","text":"Discrete Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Node-Classification","text":"Node Classification"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Classification","text":"Graph Classification"}],"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Static","text":"Static"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Undirected","text":"Undirected"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Unsigned","text":"Unsigned"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/node2vec","text":"node2vec"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Large-Scale-Information-Network-Embedding-LINE","text":"Large-Scale Information Network Embedding (LINE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree","text":"Degree"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Structural-Similarity-Measure","text":"Hierarchical Structural Similarity Measure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Biased-Random-Walk","text":"Biased Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree-Centrality","text":"Degree Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Modularity-Maximization","text":"Modularity Maximization"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Network-Embedding-HNE","text":"Heterogeneous Network Embedding (HNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/cross-entropy","text":"cross entropy"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Meta-Path-Schema","text":"Meta-Path Schema"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Network-Embedding-BiNE","text":"Bipartite Network Embedding (BiNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Heterogeneous-Network-Embedding-DHNE","text":"Dynamic Heterogeneous Network Embedding (DHNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Neighbors","text":"Temporal Neighbors"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Random-Walk","text":"Temporal Random Walk"}],"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Activation-Function","text":"Activation Function"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Poly-Filter","text":"Poly-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Cheby-Filter","text":"Cheby-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GAT-Filter","text":"GAT-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/ECC-Filter","text":"ECC-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GGNN-Filter","text":"GGNN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Mo-Filter","text":"Mo-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Flat-Graph-Pooling","text":"Flat Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Hierarchical-Graph-Pooling","text":"Hierarchical Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/gPool","text":"gPool"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/diffpool","text":"diffpool"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/EigenPooling","text":"EigenPooling"}],"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Evasion-Attack","text":"Evasion Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Poisoning-Attack","text":"Poisoning Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PGD-Topology-Attack","text":"PGD Topology Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Integrated-Gradient-Guided-Attack","text":"Integrated Gradient Guided Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Metattack","text":"Metattack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RL-S2V","text":"RL-S2V"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/ReWatt","text":"ReWatt"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/GraphAT","text":"GraphAT"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Purification","text":"Graph Purification"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Jaccard-Similarity","text":"Jaccard Similarity"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Attention","text":"Graph Attention"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RGCN-Filter","text":"RGCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PA-GNN","text":"PA-GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Pro-GNN","text":"Pro-GNN"}],"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Stochastic-Gradient-Descent","text":"Stochastic Gradient Descent"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighborhood Explosion"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Monte-Carlo","text":"Monte Carlo"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighbourhood Expansion"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Importance-Sampling","text":"Importance Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Edge-based-Sampler","text":"Edge-based Sampler"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/RW-based-Sampler","text":"RW-based Sampler"}],"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Meta-Path-Schema","text":"Meta-Path Schema"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Within-Dimension-Neighbor","text":"Within-Dimension Neighbor"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Across-Dimension-Neighbor","text":"Across-Dimension Neighbor"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Balance-Theory","text":"Balance Theory"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/EvolveGCN","text":"EvolveGCN"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"}],"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Auto-Encoders","text":"Graph Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Tree-LSTM","text":"Tree-LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/LSTM","text":"LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-LSTM","text":"Graph-LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"}],"/Deep-Learning-on-Graphs-book":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Yao-Ma","text":"Yao Ma"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Jiliang-Tang","text":"Jiliang Tang"},{"source":"/Deep-Learning-on-Graphs-book","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","text":"Deep Learning On Graphs Chapter 1 - Introduction"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","text":"Deep Learning On Graphs Chapter 2 - Foundations of Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning","text":"Deep Learning On Graphs Chapter 3 - Foundations of Deep Learning"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","text":"Deep Learning On Graphs Chapter 4 - Graph Embedding"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 5 - Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 7 - Scalable Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","text":"Deep Learning On Graphs Chapter 8 - Graph Neural Networks on Complex Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"}],"/DeepWalk":[{"source":"/DeepWalk","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/DeepWalk","target":"/Random-Walk","text":"Random Walk"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Extractor","text":"Extractor"},{"source":"/DeepWalk","target":"/skip-gram","text":"skip-gram"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Reconstructor","text":"Reconstructor"},{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/DeepWalk","target":"/N-grams","text":"N-grams"},{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/DeepWalk","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"},{"source":"/DeepWalk","target":"/Negative-Sampling","text":"Negative Sampling"}],"/Defining-and-Evaluating-Fair-Natural-Language-Generation":[{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Catherine-Yeo","text":"Catherine Yeo"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Alyssa-Chen","text":"Alyssa Chen"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/August-11th-2020","text":"August 11th, 2020"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/GPT-2","text":"GPT-2"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/XLNet","text":"XLNet"}],"/Dependency":[{"source":"/Dependency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Description-Embodied-Knowledge-Representation-Learning":[{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/TransE","text":"TransE"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"}],"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yizhe-Zhang","text":"Yizhe Zhang"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Siqi-Sun","text":"Siqi Sun"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Michel-Galley","text":"Michel Galley"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yen-Chun-Chen","text":"Yen-Chun Chen"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Chris-Brockett","text":"Chris Brockett"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Xiang-Gao","text":"Xiang Gao"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jianfeng-Gao","text":"Jianfeng Gao"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jingjing-Liu","text":"Jingjing Liu"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Bill-Dolan","text":"Bill Dolan"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/July-18th-2020","text":"July 18th, 2020"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/DialoGPT","text":"DialoGPT"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/GPT-2","text":"GPT-2"}],"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features":[{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/Hiroaki-Sugiyama","text":"Hiroaki Sugiyama"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/BERT","text":"BERT"}],"/Diameter":[{"source":"/Diameter","target":"/Connected-Graph","text":"Connected Graph"}],"/Discovering-and-Categorizing-Language-Biases-in-Reddit":[{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/August-12th-2020","text":"August 12th, 2020"},{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/word2vec","text":"word2vec"}],"/Discrete-Dynamic-Graphs":[{"source":"/Discrete-Dynamic-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"}],"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Devendra-Singh-Sachan","text":"Devendra Singh Sachan"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Yuhao-Zhang","text":"Yuhao Zhang"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Peng-Qi","text":"Peng Qi"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/William-Hamilton","text":"William Hamilton"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/January-5th-2021","text":"January 5th 2021"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Transformer","text":"Transformer"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-GNN","text":"Syntax-GNN"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2005-WSJ","text":"CoNLL-2005 WSJ"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2012","text":"CoNLL-2012"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/TACRED","text":"TACRED"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/F1-score","text":"F1 score"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"}],"/Do-Transformers-Need-Deep-Long-Range-Memory":[{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Ali-Razavi","text":"Ali Razavi"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/July-31st-2020","text":"July 31st, 2020"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"}],"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Anurag-Kumar","text":"Anurag Kumar"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Yun-Wang","text":"Yun Wang"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Vamsi-Krishna-Ithapu","text":"Vamsi Krishna Ithapu"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Christian-Fuegen","text":"Christian Fuegen"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/15-Jul-2021","text":"15-Jul-2021"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/TALNet","text":"TALNet"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/WEANet-SUSTAIN","text":"WEANet-SUSTAIN"}],"/Document-Graph-for-Neural-Machine-Translation":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Mingzhou-Xu","text":"Mingzhou Xu"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Liangyou-Li","text":"Liangyou Li"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Qun-Liu","text":"Qun Liu"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/December-12th-2020","text":"December 12th 2020"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Intra-sentential-Relations","text":"Intra-sentential Relations"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Inter-sentential-Relations","text":"Inter-sentential Relations"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Adjacency","text":"Adjacency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Dependency","text":"Dependency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Lexical-Consistency","text":"Lexical Consistency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Coreference","text":"Coreference"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-En-Fr","text":"IWSLT En-Fr"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-Zh-En","text":"IWSLT Zh-En"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/OpenSubtitles2018-En-Ru","text":"OpenSubtitles2018 En-Ru"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/WMT19-En-De","text":"WMT19 En-De"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"}],"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING":[{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Noboru-Harada","text":"Noboru Harada"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Kunio-Kashino","text":"Kunio Kashino"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Multi-task-Learning","text":"Multi-task Learning"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Mixup","text":"Mixup"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Beam-Search","text":"Beam Search"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Image-Captioning","text":"Image Captioning"}],"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION":[{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Ho-Hsiang-Wu","text":"Ho-Hsiang Wu"},{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Magdalena-Fuentes","text":"Magdalena Fuentes"},{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/08-Jun-2021","text":"08-Jun-2021"}],"/Edge-based-Sampler":[{"source":"/Edge-based-Sampler","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"}],"/Effective-Receptive-Field":[{"source":"/Effective-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"}],"/Efficient-Inference-For-Neural-Machine-Translation":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Te-Hsu","text":"Yi-Te Hsu"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Sarthak-Garg","text":"Sarthak Garg"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Hsiu-Liao","text":"Yi-Hsiu Liao"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Ilya-Chatsviorkin","text":"Ilya Chatsviorkin"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/December-3rd-2020","text":"December 3rd 2020"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/self-attention","text":"self-attention"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Average-Attention-Network-AAN","text":"Average Attention Network (AAN)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simple-Recurrent-Unit-SRU","text":"Simple Recurrent Unit (SRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/L0-regularization","text":"L0 regularization"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Hard-Concrete-Distribution","text":"Hard Concrete Distribution"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"}],"/EigenPooling":[{"source":"/EigenPooling","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/EigenPooling","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"}],"/Eigenvector-Centrality":[{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Eigenvector-Centrality","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Eigenvector-Centrality","target":"/PerronFrobenius-Theorem","text":"Perron–Frobenius Theorem"},{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"}],"/Entity-GCN":[{"source":"/Entity-GCN","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Entity-GCN","target":"/Entity-Graph","text":"Entity Graph"},{"source":"/Entity-GCN","target":"/Softmax","text":"Softmax"}],"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Helin-Wang","text":"Helin Wang"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Yuexian-Zou","text":"Yuexian Zou"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Dading-Chong","text":"Dading Chong"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Convolution","text":"Convolution"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Sigmoid","text":"Sigmoid"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Accuracy","text":"Accuracy"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-10","text":"ESC-10"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-50","text":"ESC-50"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/UrbanSound8k","text":"UrbanSound8k"}],"/Equivariant-Functions":[{"source":"/Equivariant-Functions","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Equivariant-Functions","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Equivariant-Functions","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"}],"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Information-Retrieval","text":"Information Retrieval"}],"/FNet-Mixing-Tokens-with-Fourier-Transforms":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/James-Lee-Thorp","text":"James Lee-Thorp"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Joshua-Ainslie","text":"Joshua Ainslie"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Ilya-Eckstein","text":"Ilya Eckstein"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Santiago-Ontanon","text":"Santiago Ontanon"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/transformer","text":"transformer"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/FNet","text":"FNet"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"}],"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Ahmad-Rashid","text":"Ahmad Rashid"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Alan-Do-Omri","text":"Alan Do-Omri"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Qun-Liu","text":"Qun Liu"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Mehdi-Rezagholizadeh","text":"Mehdi Rezagholizadeh"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/November-27th-2020","text":"November 27th, 2020"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture","text":"Bilingual Adversarial Text Generator (B-GAN) (Architecture)"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Cross-Domain-Loss","text":"Cross-Domain Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Adversarial-Loss","text":"Adversarial Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Multi30k","text":"Multi30k"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-English","text":"News Crawl 2007 English"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-French","text":"News Crawl 2007 French"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-English","text":"News Crawl 2010 English"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-French","text":"News Crawl 2010 French"}],"/Face-Recognition-Using-Eigenfaces":[{"source":"/Face-Recognition-Using-Eigenfaces","target":"/September-25th-2020","text":"September 25th, 2020"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Euclidean-Distance","text":"Euclidean Distance"}],"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ciprian-Chelba","text":"Ciprian Chelba"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Mia-Chen","text":"Mia Chen"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ankur-Bapna","text":"Ankur Bapna"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Noam-Shazeer","text":"Noam Shazeer"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/May-26th-2020","text":"May 26th, 2020"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT18-En-De","text":"WMT18 En-De"}],"/Filter-Damping":[{"source":"/Filter-Damping","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"}],"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Junliang-Guo","text":"Junliang Guo"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Xu-Tan","text":"Xu Tan"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Linli-Xu","text":"Linli Xu"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tao-Qin","text":"Tao Qin"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Enhong-Chen","text":"Enhong Chen"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"}],"/Flat-Graph-Pooling":[{"source":"/Flat-Graph-Pooling","target":"/Max-Pooling","text":"Max Pooling"},{"source":"/Flat-Graph-Pooling","target":"/Average-Pooling","text":"Average Pooling"},{"source":"/Flat-Graph-Pooling","target":"/Neural-Network","text":"Neural Network"}],"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xuezhe-Ma","text":"Xuezhe Ma"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Chunting-Zhou","text":"Chunting Zhou"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xian-Li","text":"Xian Li"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Eduard-Hovy","text":"Eduard Hovy"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Determinant","text":"Determinant"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Transformer","text":"Transformer"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Importance-Weighted-Decoding","text":"Importance Weighted Decoding"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"}],"/Frontiers-in-Machine-Learning":[{"source":"/Frontiers-in-Machine-Learning","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Frontiers-in-Machine-Learning","target":"/July-23rd-2020","text":"July 23rd, 2020"},{"source":"/Frontiers-in-Machine-Learning","target":"/Chris-Bishop","text":"Chris Bishop"},{"source":"/Frontiers-in-Machine-Learning","target":"/Peter-Lee","text":"Peter Lee"},{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Conversations","text":"Machine Learning Conversations"},{"source":"/Frontiers-in-Machine-Learning","target":"/Accelerating-Machine-Learning-with-Confidential-Computing","text":"Accelerating Machine Learning with Confidential Computing"},{"source":"/Frontiers-in-Machine-Learning","target":"/Security-and-Machine-Learning","text":"Security and Machine Learning"},{"source":"/Frontiers-in-Machine-Learning","target":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","text":"Beyond Fairness - Pushing ML Frontiers for Social Equity"},{"source":"/Frontiers-in-Machine-Learning","target":"/Big-Ideas-in-Causality-and-Machine-Learning","text":"Big Ideas in Causality and Machine Learning"},{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Reliability-and-Robustness","text":"Machine Learning Reliability and Robustness"},{"source":"/Frontiers-in-Machine-Learning","target":"/Saving-Lives-with-Interpretable-ML","text":"Saving Lives with Interpretable ML"}],"/Fuzzy-Set":[{"source":"/Fuzzy-Set","target":"/T-norm","text":"T-norm"},{"source":"/Fuzzy-Set","target":"/T-conorm","text":"T-conorm"}],"/Fuzzy-Sets-1965":[{"source":"/Fuzzy-Sets-1965","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Fuzzy-Sets-1965","target":"/September-29th-2020","text":"September 29th, 2020"},{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Logic","text":"Fuzzy Logic"},{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Set","text":"Fuzzy Set"},{"source":"/Fuzzy-Sets-1965","target":"/De-Morgans-Law","text":"De Morgan's Law"},{"source":"/Fuzzy-Sets-1965","target":"/Distributive-Law","text":"Distributive Law"}],"/GAT-Filter":[{"source":"/GAT-Filter","target":"/self-attention","text":"self-attention"},{"source":"/GAT-Filter","target":"/LeakyReLU","text":"LeakyReLU"}],"/GCN-Filter":[{"source":"/GCN-Filter","target":"/Cheby-Filter","text":"Cheby-Filter"},{"source":"/GCN-Filter","target":"/Laplacian-Matrix","text":"Laplacian Matrix"}],"/GGNN-Filter":[{"source":"/GGNN-Filter","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"}],"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lihua-Qian","text":"Lihua Qian"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hao-Zhou","text":"Hao Zhou"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yu-Bao","text":"Yu Bao"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Mingxuan-Wang","text":"Mingxuan Wang"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lin-Qiu","text":"Lin Qiu"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Weinan-Zhang","text":"Weinan Zhang"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yong-Yu","text":"Yong Yu"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lei-Li","text":"Lei Li"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hamming-Distance","text":"Hamming Distance"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"}],"/GRAPH-ATTENTION-NETWORKS-Paper":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Petar-Veli%C4%8Dkovi%C4%87","text":"Petar Veličković"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Guillem-Cucurull","text":"Guillem Cucurull"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Arantxa-Casanova","text":"Arantxa Casanova"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Adriana-Romero","text":"Adriana Romero"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pietro-Li%C3%B2","text":"Pietro Liò"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Yoshua-Bengio","text":"Yoshua Bengio"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/December-22nd-2020","text":"December 22nd 2020"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Spectral-Graph-Convolutions","text":"Spectral Graph Convolutions"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Cora","text":"Cora"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Citeseer","text":"Citeseer"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pubmed","text":"Pubmed"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Protein-Protein-Interaction-data","text":"Protein-Protein Interaction data"}],"/GRaph-Aware-Transformer":[{"source":"/GRaph-Aware-Transformer","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"},{"source":"/GRaph-Aware-Transformer","target":"/Transformer","text":"Transformer"},{"source":"/GRaph-Aware-Transformer","target":"/Feed-forward","text":"Feed-forward"}],"/Generalizing-CMAC-Architecture-and-Training":[{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Antonio-Art%C3%A9s-Rodr%C3%ADguez","text":"Antonio Artés Rodríguez"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"}],"/Generative-Pretraining-from-Pixels":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Mark-Chen","text":"Mark Chen"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Alec-Radford","text":"Alec Radford"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Rewon-Child","text":"Rewon Child"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Jeffrey-Wu","text":"Jeffrey Wu"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Heewoo-Jun","text":"Heewoo Jun"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"},{"source":"/Generative-Pretraining-from-Pixels","target":"/David-Luan","text":"David Luan"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Ilya-Sutskever","text":"Ilya Sutskever"},{"source":"/Generative-Pretraining-from-Pixels","target":"/October-19th-2020","text":"October 19th, 2020"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Unsupervised","text":"Unsupervised"},{"source":"/Generative-Pretraining-from-Pixels","target":"/GPT-2","text":"GPT-2"},{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"}],"/GloVe-Twitter-200d":[{"source":"/GloVe-Twitter-200d","target":"/GloVe","text":"GloVe"}],"/Graph-Adversarial-Learning":[{"source":"/Graph-Adversarial-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"}],"/Graph-Attention":[{"source":"/Graph-Attention","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"},{"source":"/Graph-Attention","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Attention","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"},{"source":"/Graph-Attention","target":"/self-attention","text":"self-attention"},{"source":"/Graph-Attention","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Attention","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/Graph-Attention","target":"/Activation-Function","text":"Activation Function"}],"/Graph-Auto-Encoders":[{"source":"/Graph-Auto-Encoders","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Auto-Encoders","target":"/Neural-Network","text":"Neural Network"},{"source":"/Graph-Auto-Encoders","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Sanghyun-Yoo","text":"Sanghyun Yoo"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Seok-Kim","text":"Young-Seok Kim"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kang-Hyun-Lee","text":"Kang Hyun Lee"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kuhwan-Jeong","text":"Kuhwan Jeong"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Junhwi-Choi","text":"Junhwi Choi"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Hoshik-Lee","text":"Hoshik Lee"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Sang-Choi","text":"Young Sang Choi"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/December-20th-2020","text":"December 20th 2020"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRaph-Aware Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRAT"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/BERT","text":"BERT"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Node-and-Edge-Modelling","text":"Masked Node and Edge Modelling"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Graph-Property-Prediction","text":"Graph Property Prediction"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/QM9","text":"QM9"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Message-Passing-Networks","text":"Message-Passing Networks"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/DimeNet","text":"DimeNet"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/USPTO","text":"USPTO"}],"/Graph-Convolutional-Network":[{"source":"/Graph-Convolutional-Network","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"},{"source":"/Graph-Convolutional-Network","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Convolutional-Network","target":"/Undirected","text":"Undirected"},{"source":"/Graph-Convolutional-Network","target":"/Activation-Function","text":"Activation Function"},{"source":"/Graph-Convolutional-Network","target":"/Complexity","text":"Complexity"}],"/Graph-Fourier-Transform":[{"source":"/Graph-Fourier-Transform","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/Graph-Fourier-Transform","target":"/Laplacian-Matrix","text":"Laplacian Matrix"}],"/Graph-Isomorphism":[{"source":"/Graph-Isomorphism","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism","target":"/Isomorphism","text":"Isomorphism"},{"source":"/Graph-Isomorphism","target":"/NP-Intermediate","text":"NP-Intermediate"},{"source":"/Graph-Isomorphism","target":"/Weisfieler-Lehman-test","text":"Weisfieler-Lehman test"}],"/Graph-Isomorphism-Networks":[{"source":"/Graph-Isomorphism-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism-Networks","target":"/Graph-Isomorphism","text":"Graph Isomorphism"},{"source":"/Graph-Isomorphism-Networks","target":"/Injective","text":"Injective"},{"source":"/Graph-Isomorphism-Networks","target":"/Aggregator-Functions","text":"aggregator"},{"source":"/Graph-Isomorphism-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Isomorphism-Networks","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"}],"/Graph-LSTM":[{"source":"/Graph-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-LSTM","target":"/Tree-LSTM","text":"Tree-LSTM"},{"source":"/Graph-LSTM","target":"/Breadth-First-Search","text":"Breadth-First Search"},{"source":"/Graph-LSTM","target":"/Depth-First-Search","text":"Depth-First Search"}],"/Graph-Neural-Networks":[{"source":"/Graph-Neural-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Neural-Networks","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Graph-Neural-Networks","target":"/NP-Hard","text":"NP-Hard"},{"source":"/Graph-Neural-Networks","target":"/Polynomial-time","text":"Polynomial-time"},{"source":"/Graph-Neural-Networks","target":"/Aggregator-Functions","text":"Aggregator Functions"},{"source":"/Graph-Neural-Networks","target":"/Over-Squashing","text":"Over-Squashing"},{"source":"/Graph-Neural-Networks","target":"/Fully-Connected-Graph","text":"Fully Connected Graph"},{"source":"/Graph-Neural-Networks","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"}],"/Graph-Pooling":[{"source":"/Graph-Pooling","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Graph-Pooling","target":"/Pooling","text":"Pooling"},{"source":"/Graph-Pooling","target":"/Graclus","text":"Graclus"},{"source":"/Graph-Pooling","target":"/Binary-Tree","text":"Binary Tree"}],"/Graph-Positional-Encodings":[{"source":"/Graph-Positional-Encodings","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Positional-Encodings","target":"/Index-Positional-Encoding","text":"Index Positional Encoding"},{"source":"/Graph-Positional-Encodings","target":"/Structural-Message-Passing-Networks","text":"Structural Message-Passing Networks"},{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Positional-Encodings","text":"Laplacian Positional Encodings"},{"source":"/Graph-Positional-Encodings","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Graph-Positional-Encodings","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Graph-Positional-Encodings","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Positional-Encodings","target":"/Positional-Encodings","text":"Positional Encodings"}],"/Graph-Purification":[{"source":"/Graph-Purification","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"}],"/Graph-Reordering":[{"source":"/Graph-Reordering","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"}],"/Graph-Structure-Learning":[{"source":"/Graph-Structure-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"}],"/Graph-Substructure-Networks":[{"source":"/Graph-Substructure-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Substructure-Networks","target":"/Cycles","text":"Cycles"},{"source":"/Graph-Substructure-Networks","target":"/Cliques","text":"Cliques"},{"source":"/Graph-Substructure-Networks","target":"/Clusters","text":"Clusters"},{"source":"/Graph-Substructure-Networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graph-Substructure-Networks","target":"/Isomorphism","text":"Isomorphism"}],"/Graph-Transformer":[{"source":"/Graph-Transformer","target":"/Graph-to-Sequence-Neural-Machine-Translation","text":"Graph-to-Sequence Neural Machine Translation"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Feed-forward","text":"Feed-forward"}],"/Graph-to-Sequence-Neural-Machine-Translation":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Sufeng-Duan","text":"Sufeng Duan"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Hai-Zhao","text":"Hai Zhao"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Rui-Wang","text":"Rui Wang"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/January-4th-2021","text":"January 4th 2021"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Graph-Transformer","text":"Graph-Transformer"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"}],"/GraphAT":[{"source":"/GraphAT","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"}],"/GraphSAGE-Filter":[{"source":"/GraphSAGE-Filter","target":"/LSTM","text":"LSTM"},{"source":"/GraphSAGE-Filter","target":"/Pooling","text":"Pooling"}],"/Graphite":[{"source":"/Graphite","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"},{"source":"/Graphite","target":"/Probabilistic-Modeling","text":"Probabilistic Modeling"},{"source":"/Graphite","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Associative","text":"Associative"},{"source":"/Graphite","target":"/Graphite-VAE","text":"Graphite-VAE"},{"source":"/Graphite","target":"/Graphite-AE","text":"Graphite-AE"}],"/Graphite-AE":[{"source":"/Graphite-AE","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Graphite-AE","target":"/Graphite","text":"Graphite"}],"/Graphite-Iterative-Generative-Modeling-of-Graphs":[{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aditya-Grover","text":"Aditya Grover"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aaron-Zweig","text":"Aaron Zweig"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Stefano-Ermon","text":"Stefano Ermon"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/December-22nd-2020","text":"December 22nd 2020"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Unsupervised","text":"Unsupervised"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Cora","text":"Cora"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Citeseer","text":"Citeseer"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Pubmed","text":"Pubmed"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"}],"/Graphite-VAE":[{"source":"/Graphite-VAE","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-VAE","target":"/Graphite","text":"Graphite"}],"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Qiu-Ran","text":"Qiu Ran"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Yankai-Lin","text":"Yankai Lin"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Peng-Li","text":"Peng Li"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/May-23rd-2020","text":"May 23rd, 2020"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST02","text":"NIST02"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST03","text":"NIST03"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST04","text":"NIST04"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST06","text":"NIST06"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST08","text":"NIST08"}],"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES":[{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Nguyen-Cat-Ho","text":"Nguyen Cat Ho"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Wolfgang-Wechler","text":"Wolfgang Wechler"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Linguistic-Hedges","text":"Linguistic Hedges"}],"/Hierarchical-Softmax":[{"source":"/Hierarchical-Softmax","target":"/Binary-Tree","text":"Binary Tree"}],"/Hierarchical-Structural-Similarity-Measure":[{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Structural-Role","text":"Structural Role"},{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Dynamic-Time-Warping-DTW","text":"Dynamic Time Warping (DTW)"}],"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Sintiani-Teddy","text":"Sintiani Teddy"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchical-Clustering","text":"Hierarchical Clustering"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Agglomerative-Hierarchical-Clustering","text":"Agglomerative Hierarchical Clustering"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Widrow-Hoff","text":"Widrow-Hoff"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"}],"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Kawin-Ethayarajh","text":"Kawin Ethayarajh"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/October-11th-2019","text":"October 11th, 2019"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Isotropy","text":"Isotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"Anisotropy"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Elmo","text":"Elmo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GloVe","text":"GloVe"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/FastText","text":"FastText"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"}],"/Hypergraphs":[{"source":"/Hypergraphs","target":"/Incidence-Matrix","text":"Incidence Matrix"}],"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING":[{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Turab-Iqbal","text":"Turab Iqbal"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Yin-Cao","text":"Yin Cao"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"}],"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING":[{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/May-3rd-2021","text":"May 3rd 2021"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Acoustic-Scene-Classification","text":"Acoustic Scene Classification"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/AudioCaps","text":"AudioCaps"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Clotho-dataset","text":"Clotho dataset"}],"/Image-Quilting-for-Texture-Synthesis-and-Transfer":[{"source":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","target":"/October-10th-2020","text":"October 10th, 2020"}],"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990":[{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Neural-Network","text":"Neural Network"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"}],"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output":[{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Kai-Keng-Ang","text":"Kai Keng Ang"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"}],"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data":[{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Jiawei-Zhou","text":"Jiawei Zhou"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Phillip-Keung","text":"Phillip Keung"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/May-25th-2020","text":"May 25th, 2020"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-De-En","text":"WMT14 De-En"}],"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/William-Chan","text":"William Chan"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Chitwan-Saharia","text":"Chitwan Saharia"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Navdeep-Jaitly","text":"Navdeep Jaitly"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/August-15th-2020","text":"August 15th, 2020"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imitation-Learning","text":"Imitation Learning"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Wall-Street-Journal","text":"Wall Street Journal"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Character-Error-Rate-CER","text":"Character Error Rate (CER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"}],"/Inductive-Biases":[{"source":"/Inductive-Biases","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"}],"/Information-Theoretic-Probing":[{"source":"/Information-Theoretic-Probing","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"}],"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mitchell-Stern","text":"Mitchell Stern"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/William-Chan","text":"William Chan"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jamie-Kiros","text":"Jamie Kiros"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/self-attention","text":"self-attention"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mixture-of-Softmaxes","text":"Mixture of Softmaxes"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Softmax","text":"Softmax"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2014-En-De","text":"newstest2014 En-De"}],"/Integrated-Gradient-Guided-Attack":[{"source":"/Integrated-Gradient-Guided-Attack","target":"/Fast-Gradient-Sign-Method","text":"Fast Gradient Sign Method"}],"/Inter-sentential-Relations":[{"source":"/Inter-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Inter-sentential-Relations","target":"/Lexical-Consistency","text":"Lexical Consistency"},{"source":"/Inter-sentential-Relations","target":"/Coreference","text":"Coreference"}],"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Jorge-Casillas","text":"Jorge Casillas"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Oscar-Cordon","text":"Oscar Cordon"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Francisco-Herrera","text":"Francisco Herrera"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Luis-Magdalena","text":"Luis Magdalena"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/September-29th-2020","text":"September 29th, 2020"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Interpretability","text":"Interpretability"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Accuracy","text":"Accuracy"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Principle-of-Incompatibility","text":"Principle of Incompatibility"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs","text":"Takagi-Sugeno-Kang-type Fuzzy Rule-Based Systems (TSK-type FRBSs)"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Orthogonality","text":"orthogonal"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR","text":"Singular value decomposition and QR with column pivoting methods (SVD-QR)"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singleton-Fuzzy-Rule-Based-Systems","text":"Singleton Fuzzy Rule-Based Systems"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Fuzzy-Rule-Based-Classification-System","text":"Fuzzy Rule-Based Classification System"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Approximate-Rule-Based-Systems","text":"Approximate Rule-Based Systems"}],"/Intra-sentential-Relations":[{"source":"/Intra-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Intra-sentential-Relations","target":"/Adjacency","text":"Adjacency"},{"source":"/Intra-sentential-Relations","target":"/Dependency","text":"Dependency"}],"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Martin-Schmitt","text":"Martin Schmitt"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Hinrich-Sch%C3%BCtze","text":"Hinrich Schütze"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Iryna-Gurevych","text":"Iryna Gurevych"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/January-6th-2021","text":"January 6th 2021"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/BART","text":"BART"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AGENDA","text":"AGENDA"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/language-model","text":"language model"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Alessandra-Cervone","text":"Alessandra Cervone"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Giuseppe-Riccardi","text":"Giuseppe Riccardi"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/SwitchBoard","text":"SwitchBoard"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Weighted-Kappa-Agreement","text":"Weighted Kappa Agreement"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Multiple-Regression-Analysis","text":"Multiple Regression Analysis"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"}],"/Isotropy":[{"source":"/Isotropy","target":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","text":"How Contextual are Contextualized Word Representations - Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"},{"source":"/Isotropy","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"}],"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jason-Lee","text":"Jason Lee"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Raphael-Shu","text":"Raphael Shu"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Kyunghyun-Cho","text":"Kyunghyun Cho"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/September-18th-2020","text":"September 18th, 2020"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"}],"/July-3rd-2020":[{"source":"/July-3rd-2020","target":"/Takeaways","text":"Takeaway(s)"},{"source":"/July-3rd-2020","target":"/Zhou-Yu","text":"Zhou Yu"},{"source":"/July-3rd-2020","target":"/JSALT2020","text":"JSALT2020"}],"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences":[{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/William-Chan","text":"William Chan"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Nikita-Kitaev","text":"Nikita Kitaev"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kelvin-Guu","text":"Kelvin Guu"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Mitchell-Stern","text":"Mitchell Stern"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/August-20th-2020","text":"August 20th, 2020"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-De-En","text":"WMT14 De-En"}],"/Katz-Centrality":[{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Invertibility","text":"Invertibility"}],"/Kernel-CMAC-With-Improved-Capability":[{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/G%C3%A1bor-Horv%C3%A1th","text":"Gábor Horváth"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Tam%C3%A1s-Szab%C3%B3","text":"Tamás Szabó"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/November-9th-2020","text":"November 9th, 2020"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Kernel-CMAC-Architecture","text":"Kernel CMAC (Architecture)"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"}],"/Knowledge-Graph-Embeddings-and-Explainable-AI":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Federico-Bianchi","text":"Federico Bianchi"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Gaetano-Rossiello","text":"Gaetano Rossiello"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Luca-Constabello","text":"Luca Constabello"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Matteo-Palmonari","text":"Matteo Palmonari"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Pasquale-Minervini","text":"Pasquale Minervini"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/December-28th-2020","text":"December 28th 2020"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Translational-Models","text":"Translational Models#Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Bilinear-Models","text":"Bilinear Models#Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Path","text":"Path"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/word2vec","text":"word2vec"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Mean-Reciprocal-Rank","text":"Mean Reciprocal Rank"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Explainability","text":"Explainability"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"}],"/Knowledge-Graphs":[{"source":"/Knowledge-Graphs","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs","target":"/Ontology","text":"Ontology"},{"source":"/Knowledge-Graphs","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Knowledge-Graphs-Embeddings":[{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Link-Prediction","text":"Link Prediction"}],"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Mahdi-Namazifar","text":"Mahdi Namazifar"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Alexandros-Papangelis","text":"Alexandros Papangelis"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Gokhan-Tur","text":"Gokhan Tur"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Dilek-Hakkani-T%C3%BCr","text":"Dilek Hakkani-Tür"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Natural-Langauge-Understanding","text":"Natural Langauge Understanding"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Slot-Detection","text":"Slot Detection"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Intent-Detection","text":"Intent Detection"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Text-To-Text-Transfer-Transformer","text":"Text-To-Text Transfer Transformer"}],"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Chenguang-Wang","text":"Chenguang Wang"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Xiao-Liu","text":"Xiao Liu"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/December-21st-2020","text":"December 21st 2020"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/language-model","text":"language model"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Unsupervised","text":"Unsupervised"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"Match and Map"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/TAC-Knowledge-Base-Population","text":"TAC Knowledge Base Population"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"MaMa"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Named-Entity-Recognition","text":"Named Entity Recognition"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/spaCy","text":"spaCy"}],"/LIAR-Politifact":[{"source":"/LIAR-Politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"}],"/Language-Models-are-Few-Shot-Learners":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Mann","text":"Benjamin Mann"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Nick-Ryder","text":"Nick Ryder"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Melanie-Subbiah","text":"Melanie Subbiah"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jared-Kaplan","text":"Jared Kaplan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Arvind-Neelakantan","text":"Arvind Neelakantan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Pranav-Shyam","text":"Pranav Shyam"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Girish-Sastry","text":"Girish Sastry"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Amanda-Askell","text":"Amanda Askell"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sandhini-Agarwal","text":"Sandhini Agarwal"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ariel-Herbert-Voss","text":"Ariel Herbert-Voss"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Gretchen-Krueger","text":"Gretchen Krueger"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Tom-Henighan","text":"Tom Henighan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Rewon-Child","text":"Rewon Child"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Aditya-Ramesh","text":"Aditya Ramesh"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jeffrey-Wu","text":"Jeffrey Wu"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Clemens-Winter","text":"Clemens Winter"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Hesse","text":"Christopher Hesse"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mark-Chen","text":"Mark Chen"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Eric-Sigler","text":"Eric Sigler"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mateusz-Litwin","text":"Mateusz Litwin"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Scott-Gray","text":"Scott Gray"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Chess","text":"Benjamin Chess"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jack-Clark","text":"Jack Clark"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Berner","text":"Christopher Berner"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sam-McCandlish","text":"Sam McCandlish"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Alec-Radford","text":"Alec Radford"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ilya-Sutskever","text":"Ilya Sutskever"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Dario-Amodei","text":"Dario Amodei"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/June-3rd-2020","text":"June 3rd, 2020"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/LAMBADA","text":"LAMBADA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/TriviaQA","text":"TriviaQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winograd","text":"Winograd"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/PIQA","text":"PIQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ARC","text":"ARC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/CoQA","text":"CoQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/DROP","text":"DROP"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/QuAC","text":"QuAC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SQuADv2","text":"SQuADv2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/RACE","text":"RACE"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SuperGLUE-Benchmark","text":"SuperGLUE Benchmark"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WiC","text":"WiC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ANLI","text":"ANLI"}],"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Su-Lin-Blodgett","text":"Su Lin Blodgett"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Solon-Barocas","text":"Solon Barocas"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hal-Daum%C3%A9-III","text":"Hal Daumé III"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hanna-Wallach","text":"Hanna Wallach"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/May-30th-2020","text":"May 30th, 2020"}],"/Laplacian-Filter":[{"source":"/Laplacian-Filter","target":"/Laplace-operator","text":"Laplace operator"}],"/Laplacian-Matrix":[{"source":"/Laplacian-Matrix","target":"/Spanning-Tree","text":"Spanning Tree"},{"source":"/Laplacian-Matrix","target":"/Machine-Learning","text":"Machine Learning"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Symmetric","text":"Symmetric"},{"source":"/Laplacian-Matrix","target":"/Degree","text":"Degree"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Connected-Component","text":"Connected Component"}],"/Laplacian-of-Gaussian-Filter":[{"source":"/Laplacian-of-Gaussian-Filter","target":"/Laplace-operator","text":"Laplace operator"}],"/Large-Scale-Information-Network-Embedding-LINE":[{"source":"/Large-Scale-Information-Network-Embedding-LINE","target":"/node2vec","text":"node2vec"}],"/Learning-Convergence-of-CMAC-Technique":[{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Chun-Shin-Lin","text":"Chun-Shin Lin"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Ching-Tsan-Chiang","text":"Ching-Tsan Chiang"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/November-8th-2020","text":"November 8th, 2020"}],"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Gurunath-Reddy-Madhumani","text":"Gurunath Reddy Madhumani"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sanket-Shah","text":"Sanket Shah"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Basil-Abraham","text":"Basil Abraham"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Vikas-Joshi","text":"Vikas Joshi"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sunayana-Sitaram","text":"Sunayana Sitaram"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/June-17th-2020","text":"June 17th, 2020"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Learning-Without-Forgetting","text":"Learning Without Forgetting"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Code-Mixing-Index-CMI","text":"Code Mixing Index (CMI)"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"}],"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Qiu-Ran","text":"Qiu Ran"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yankai-Lin","text":"Yankai Lin"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Peng-Li","text":"Peng Li"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/June-15th-2020","text":"June 15th, 2020"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Sequence-Refinement","text":"Sequence Refinement"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"}],"/Lecture-1":[{"source":"/Lecture-1","target":"/August-12th-2020","text":"August 12th, 2020"}],"/Lexical-Consistency":[{"source":"/Lexical-Consistency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Linearized-Graph":[{"source":"/Linearized-Graph","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"}],"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Pan-Yaozhang","text":"Pan Yaozhang"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Jane-Shen","text":"Jane Shen"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Laurence-Liew","text":"Laurence Liew"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Yap-Kim-Hui","text":"Yap Kim Hui"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Sim-Kai","text":"Sim Kai"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/October-12th-2020","text":"October 12th, 2020"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"}],"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING":[{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Emre-Cakir","text":"Emre Cakir"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/SPIDEr","text":"SPIDEr"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Clotho-dataset","text":"Clotho dataset"}],"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION":[{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Le-Nguyen","text":"Huy Le Nguyen"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/31-May-2021","text":"31-May-2021"}],"/Machine-Learning-Conversations":[{"source":"/Machine-Learning-Conversations","target":"/Susan-Dumais","text":"Susan Dumais"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/MineRL-competition","text":"MineRL competition"},{"source":"/Machine-Learning-Conversations","target":"/Meta-Reinforcement-Learning","text":"Meta Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Variational-Deep-Reinforcement-Learning-VariBad","text":"Variational Deep Reinforcement Learning (VariBad)"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Representation-learning","text":"Representation learning"},{"source":"/Machine-Learning-Conversations","target":"/Homer","text":"Homer"},{"source":"/Machine-Learning-Conversations","target":"/FLAMBE","text":"FLAMBE"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Conditional-Language-Modelling","text":"Conditional Language Modelling"},{"source":"/Machine-Learning-Conversations","target":"/exposure-bias","text":"exposure bias"},{"source":"/Machine-Learning-Conversations","target":"/bottleneck-issues","text":"bottleneck issues"},{"source":"/Machine-Learning-Conversations","target":"/cross-entropy","text":"cross entropy"},{"source":"/Machine-Learning-Conversations","target":"/BLEU","text":"BLEU"},{"source":"/Machine-Learning-Conversations","target":"/ROUGE","text":"ROUGE"},{"source":"/Machine-Learning-Conversations","target":"/GPT-2","text":"GPT-2"},{"source":"/Machine-Learning-Conversations","target":"/Casual-Language-Modelling","text":"Casual Language Modelling"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/cross-validation","text":"cross validation"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"}],"/Machine-Learning-Reliability-and-Robustness":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Besmira-Nushi","text":"Besmira Nushi"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/July-22nd-2020","text":"July 22nd, 2020"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Computer-Vision","text":"Computer Vision"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Transportability","text":"Transportability"}],"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Marjan-Ghazvininejad","text":"Marjan Ghazvininejad"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Omer-Levy","text":"Omer Levy"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Yinhan-Liu","text":"Yinhan Liu"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Luke-Zettlemoyer","text":"Luke Zettlemoyer"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/August-22nd-2020","text":"August 22nd, 2020"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Transformer","text":"Transformer"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-En-Zh","text":"WMT17 En-Zh"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/BERT","text":"BERT"}],"/Masked-Graph-Modelling":[{"source":"/Masked-Graph-Modelling","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"}],"/Match-and-Map":[{"source":"/Match-and-Map","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"},{"source":"/Match-and-Map","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Match-and-Map","target":"/Wikidata","text":"Wikidata"},{"source":"/Match-and-Map","target":"/Beam-Search","text":"Beam Search"}],"/Maximum-Receptive-Field":[{"source":"/Maximum-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"}],"/Mean-Shift-Analysis-and-Applications":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Dorin-Comaniciu","text":"Dorin Comaniciu"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Peter-Meer","text":"Peter Meer"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Estimate","text":"Mean Shift Estimate"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"}],"/Meta-Reinforcement-Learning":[{"source":"/Meta-Reinforcement-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Meta-Reinforcement-Learning","target":"/meta-learning","text":"meta-learning"}],"/Metattack":[{"source":"/Metattack","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Metattack","target":"/Poisoning-Attack","text":"Poisoning Attack"},{"source":"/Metattack","target":"/bi-level-optimization","text":"bi-level optimization"},{"source":"/Metattack","target":"/Meta-Gradients","text":"Meta-Gradients"},{"source":"/Metattack","target":"/meta-learning","text":"meta-learning"}],"/Misinformation-has-High-Perplexity":[{"source":"/Misinformation-has-High-Perplexity","target":"/Nayeon-Lee","text":"Nayeon Lee"},{"source":"/Misinformation-has-High-Perplexity","target":"/Yejin-Bang","text":"Yejin Bang"},{"source":"/Misinformation-has-High-Perplexity","target":"/Andrea-Madotto","text":"Andrea Madotto"},{"source":"/Misinformation-has-High-Perplexity","target":"/Pascale-Fung","text":"Pascale Fung"},{"source":"/Misinformation-has-High-Perplexity","target":"/June-16th-2020","text":"June 16th, 2020"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/FEVER","text":"FEVER"},{"source":"/Misinformation-has-High-Perplexity","target":"/BERT","text":"BERT"},{"source":"/Misinformation-has-High-Perplexity","target":"/LIAR-Politifact","text":"LIAR-Politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/GPT-2","text":"GPT-2"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"}],"/Mixup":[{"source":"/Mixup","target":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","text":"mixup - BEYOND EMPIRICAL RISK MINIMIZATION"}],"/Mo-Filter":[{"source":"/Mo-Filter","target":"/Mixture-Model-Network-MoNet","text":"Mixture Model Network (MoNet)"},{"source":"/Mo-Filter","target":"/Degree","text":"Degree"},{"source":"/Mo-Filter","target":"/Gaussian-Kernel","text":"Gaussian Kernel"},{"source":"/Mo-Filter","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Mo-Filter","target":"/Convolution","text":"Convolution"}],"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Shu-wen-Yang","text":"Shu-wen Yang"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-Han-Chi","text":"Po-Han Chi"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-chun-Hsu","text":"Po-chun Hsu"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Hung-yi-Lee","text":"Hung-yi Lee"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Mockingjay","text":"Mockingjay"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Acoustic-Modelling","text":"Masked Acoustic Modelling"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Manhattan-Distance","text":"L1 norm"}],"/Modeling-Local-Coherence-An-Entity-Based-Approach":[{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Regina-Barzilay","text":"Regina Barzilay"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Mirella-Lapata","text":"Mirella Lapata"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Entity-Grid","text":"Entity Grid"}],"/Multi-dimensional-Graphs":[{"source":"/Multi-dimensional-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Multi30k":[{"source":"/Multi30k","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"}],"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Pawe%C5%82-Budzianowski","text":"Paweł Budzianowski"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Tsung-Hsien-Wen","text":"Tsung-Hsien Wen"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Bo-Hsiang-Tseng","text":"Bo-Hsiang Tseng"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/I%C3%B1igo-Casanueva","text":"Iñigo Casanueva"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Stefan-Ultes","text":"Stefan Ultes"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Osman-Ramadan","text":"Osman Ramadan"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/June-18th-2020","text":"June 18th, 2020"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Dialogue-Modelling","text":"Dialogue Modelling"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/SFX-restaurant","text":"SFX restaurant"}],"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative":[{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Harris-Chan","text":"Harris Chan"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Jamie-Kiros","text":"Jamie Kiros"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/William-Chan","text":"William Chan"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/August-21st-2020","text":"August 21st, 2020"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/BLEU","text":"BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Non-Autoregressive","text":"Non-Autoregressive"}],"/Multisystem-fusion-model-based-on-tag-relationship":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Zhuangzhuang-Liu","text":"Zhuangzhuang Liu"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Junyan-Fang","text":"Junyan Fang"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Xiaofeng-Hong","text":"Xiaofeng Hong"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Gang-Liu","text":"Gang Liu"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"}],"/MusCaps-Generating-Captions-for-Music-Audio":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Ilaria-Manco","text":"Ilaria Manco"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Emmanouil-Benetos","text":"Emmanouil Benetos"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Elio-Quinton","text":"Elio Quinton"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Gyorgy-Fazekas","text":"Gyorgy Fazekas"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/May-10th-2021","text":"May 10th 2021"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Music-Captioning","text":"Music Captioning"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/GloVe","text":"GloVe"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Soft-Attention","text":"Soft Attention"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"}],"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Detlef-Nauck","text":"Detlef Nauck"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Rudolf-Kruse","text":"Rudolf Kruse"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/October-31st-2020","text":"October 31st, 2020"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Fuzzy-Perceptron","text":"Fuzzy Perceptron"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/IRIS-dataset","text":"IRIS dataset"}],"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/James-Bradbury","text":"James Bradbury"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Caiming-Xiong","text":"Caiming Xiong"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Richard-Socher","text":"Richard Socher"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/BLEU","text":"BLEU"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"}],"/NTU-AI+X-Symposium-AI-for-Social-Good":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bo-An","text":"Bo An"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/November-17th-2020","text":"November 17th, 2020"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Telecoupling","text":"Telecoupling"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/CART","text":"CART"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Random-Forest","text":"Random Forest"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bayesian-Belief-Networks","text":"Bayesian Belief Networks"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"}],"/Negative-Sampling":[{"source":"/Negative-Sampling","target":"/Noise-Contrasitive-Estimation-NCE","text":"Noise Contrasitive Estimation (NCE)"},{"source":"/Negative-Sampling","target":"/Softmax","text":"Softmax"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Negative-Sampling","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"}],"/Neighborhood-Explosion":[{"source":"/Neighborhood-Explosion","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"}],"/Nettack":[{"source":"/Nettack","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Nettack","target":"/GCN-Filter","text":"GCN-Filter"}],"/Neural-Machine-Translation-without-Embeddings":[{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Uri-Shaham","text":"Uri Shaham"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Omer-Levy","text":"Omer Levy"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/September-19th-2020","text":"September 19th, 2020"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/IWSLT","text":"IWSLT"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"orthogonal"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"Orthogonality"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Non-Autoregressive","text":"Non-Autoregressive"}],"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Longteng-Guo","text":"Longteng Guo"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jing-Liu","text":"Jing Liu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/XinXin-Zhu","text":"XinXin Zhu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Xingjian-He","text":"Xingjian He"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jie-Jiang","text":"Jie Jiang"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Hanqing-Lu","text":"Hanqing Lu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactuals-Critical-MultiAgent-Learning-CMAL","text":"Counterfactuals-Critical MultiAgent Learning (CMAL)"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Multi-Agent","text":"Multi-Agent"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/REINFORCE","text":"REINFORCE"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactual","text":"Counterfactual"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/MSCOCO","text":"MSCOCO"}],"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments":[{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Chitwan-Saharia","text":"Chitwan Saharia"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/William-Chan","text":"William Chan"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Saurabh-Saxena","text":"Saurabh Saxena"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/BLEU","text":"BLEU"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Speech-Recognition","text":"Speech Recognition"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"}],"/Non-Autoregressive-Transformer-by-Position-Learning":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Yu-Bao","text":"Yu Bao"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Hao-Zhou","text":"Hao Zhou"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiangtao-Feng","text":"Jiangtao Feng"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Mingxuan-Wang","text":"Mingxuan Wang"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Shujian-Huang","text":"Shujian Huang"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiajun-Chen","text":"Jiajun Chen"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Lei-Li","text":"Lei Li"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Monte-Carlo","text":"Monte Carlo"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Quora-Question-Pairs","text":"Quora Question Pairs"}],"/Ontology":[{"source":"/Ontology","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"}],"/Optimized-Product-Quantization":[{"source":"/Optimized-Product-Quantization","target":"/Tiezheng-Ge","text":"Tiezheng Ge"},{"source":"/Optimized-Product-Quantization","target":"/Kaiming-He","text":"Kaiming He"},{"source":"/Optimized-Product-Quantization","target":"/Qifa-Ke","text":"Qifa Ke"},{"source":"/Optimized-Product-Quantization","target":"/Jian-Sun","text":"Jian Sun"},{"source":"/Optimized-Product-Quantization","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/Optimized-Product-Quantization","target":"/Vector-Quantization","text":"Vector Quantization"}],"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Bayan-Abu-Shawar","text":"Bayan Abu Shawar"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Jo%C3%A3o-Sedoc","text":"João Sedoc"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Mean-Squared-Error","text":"Mean Squared Error"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/datasets","text":"datasets"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/IRIS-dialogue-system","text":"IRIS dialogue system"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/BERT","text":"BERT"}],"/Overview-of-the-dialogue-breakdown-detection-challenge-3":[{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Nobuhiro-Kaji","text":"Nobuhiro Kaji"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"}],"/PENMAN":[{"source":"/PENMAN","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"}],"/PGD-Topology-Attack":[{"source":"/PGD-Topology-Attack","target":"/Carlili-Wagner-Loss","text":"CW loss"}],"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture":[{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Sintiani-Teddy","text":"Sintiani Teddy"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/November-9th-2020","text":"November 9th, 2020"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Widrow-Hoff","text":"Widrow-Hoff"}],"/Paper-Levenshtein-Transformer":[{"source":"/Paper-Levenshtein-Transformer","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/Paper-Levenshtein-Transformer","target":"/Changhan-Wang","text":"Changhan Wang"},{"source":"/Paper-Levenshtein-Transformer","target":"/Jake-Zhao-Junbo","text":"Jake Zhao Junbo"},{"source":"/Paper-Levenshtein-Transformer","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/Paper-Levenshtein-Transformer","target":"/Imitation-Learning","text":"Imitation Learning"},{"source":"/Paper-Levenshtein-Transformer","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/Paper-Levenshtein-Transformer","target":"/Roll-in-Policy","text":"Roll-in Policy"},{"source":"/Paper-Levenshtein-Transformer","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Paper-Levenshtein-Transformer","target":"/WAT2017-Small-NMT-En-Ja","text":"WAT2017 Small-NMT En-Ja"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT17-Automatic-Post-Editing-APE-Task-En-De","text":"WMT17 Automatic Post-Editing (APE) Task En-De"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"}],"/Path":[{"source":"/Path","target":"/Walk","text":"Walk"}],"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Saizheng-Zhang","text":"Saizheng Zhang"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Emily-Dinan","text":"Emily Dinan"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jack-Urbanek","text":"Jack Urbanek"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Arthur-Szlam","text":"Arthur Szlam"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Douwe-Kiela","text":"Douwe Kiela"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/PersonaChat","text":"PersonaChat"}],"/Principal-Neighbourhood-Aggregation":[{"source":"/Principal-Neighbourhood-Aggregation","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"}],"/Pro-GNN":[{"source":"/Pro-GNN","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Probing-Neural-Dialog-Models-for-Conversational-Understanding":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Abdelrhman-Saleh","text":"Abdelrhman Saleh"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Tovly-Deutsch","text":"Tovly Deutsch"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stephen-Casper","text":"Stephen Casper"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Yonatan-Belinkov","text":"Yonatan Belinkov"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stuart-Shieber","text":"Stuart Shieber"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/June-16th-2020","text":"June 16th, 2020"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ParlAI","text":"ParlAI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Transformer","text":"Transformer"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/WikiText-103","text":"WikiText-103"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/GloVe","text":"GloVe"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/TREC","text":"TREC"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DialogueNLI","text":"DialogueNLI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Schema-Guided-Dialog-SGD","text":"Schema-Guided Dialog (SGD)"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Winograd-NLI","text":"Winograd NLI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/SNIPS","text":"SNIPS"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ScenarioSA","text":"ScenarioSA"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"}],"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Alexander-Hoyle","text":"Alexander Hoyle"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Ana-Marasovi%C4%87","text":"Ana Marasović"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Noah-Smith","text":"Noah Smith"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/January-7th-2021","text":"January 7th 2021"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Resource-Description-Framework","text":"Resource Description Framework"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Abstract-Meaning-Representations","text":"Abstract Meaning Representations"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/language-model","text":"language model"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Spanning-Tree","text":"Spanning Tree"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/PENMAN","text":"PENMAN"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Permutation-Invariant","text":"Permutation Invariance"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Graph-Reordering","text":"Graph Reordering"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Scaffolding","text":"Scaffolding"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"}],"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yu-Yan","text":"Yu Yan"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Weizhen-Qi","text":"Weizhen Qi"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yeyun-Gong","text":"Yeyun Gong"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Dayiheng-Liu","text":"Dayiheng Liu"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Nan-Duan","text":"Nan Duan"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Jiusheng-Chen","text":"Jiusheng Chen"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ruofei-Zhang","text":"Ruofei Zhang"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ming-Zhou","text":"Ming Zhou"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/June-2nd-2020","text":"June 2nd, 2020"}],"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization":[{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Saurabh-Garg","text":"Saurabh Garg"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Sivaraman-Balakrishnan","text":"Sivaraman Balakrishnan"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"Randomly Assign, Train and Track"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"RATT"}],"/RGCN-Filter":[{"source":"/RGCN-Filter","target":"/GCN-Filter","text":"GCN-Filter"}],"/RL-S2V":[{"source":"/RL-S2V","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/RL-S2V","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/RL-S2V","target":"/Markov-Decision-Process","text":"Markov Decision Process"}],"/RW-based-Sampler":[{"source":"/RW-based-Sampler","target":"/Random-Walk","text":"Random Walk"}],"/Random-Walk":[{"source":"/Random-Walk","target":"/Degree","text":"Degree"}],"/ReWatt":[{"source":"/ReWatt","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/ReWatt","target":"/Rewiring","text":"Rewiring"}],"/Reading-List":[{"source":"/Reading-List","target":"/Alan-Turing-The-Enigma","text":"Alan Turing - The Enigma"},{"source":"/Reading-List","target":"/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence","text":"Prediction Machines - The Simple Economics of Artificial Intelligence"},{"source":"/Reading-List","target":"/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid","text":"Gödel, Escher, Bach - an Eternal Golden Braid"},{"source":"/Reading-List","target":"/The-Book-of-Why-The-New-Science-of-Cause-and-Effect","text":"The Book of Why - The New Science of Cause and Effect"}],"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Khaled-Koutini","text":"Khaled Koutini"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Hamid-Eghbal-zadeh","text":"Hamid Eghbal-zadeh"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Gerhard-Widmer","text":"Gerhard Widmer"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Computer-Vision","text":"Computer Vision"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/TAU-Urban-Acoustic-Scenes-2018","text":"TAU Urban Acoustic Scenes 2018"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"}],"/Recipes-for-building-an-open-domain-chatbot-Generative-BST":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Stephen-Roller","text":"Stephen Roller"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Emily-Dinan","text":"Emily Dinan"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Naman-Goyal","text":"Naman Goyal"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Da-Ju","text":"Da Ju"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Mary-Williamson","text":"Mary Williamson"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Yinhan-Liu","text":"Yinhan Liu"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jing-Xu","text":"Jing Xu"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Myle-Ott","text":"Myle Ott"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Kurt-Shuster","text":"Kurt Shuster"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/June-23rd-2020","text":"June 23rd, 2020"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Transformer","text":"Transformer"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Fairseq","text":"Fairseq"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ParlAI","text":"ParlAI"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adafactor","text":"Adafactor"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adam","text":"Adam"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Meena","text":"Meena"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"}],"/Recursive-Graph-to-Graph-Transformer":[{"source":"/Recursive-Graph-to-Graph-Transformer","target":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","text":"Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency Parsing with Iterative Refinement"}],"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Alireza-Mohammadshahi","text":"Alireza Mohammadshahi"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/James-Henderson","text":"James Henderson"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/January-13th-2021","text":"January 13th 2021"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Recursive-Graph-to-Graph-Transformer","text":"Recursive Graph-to-Graph Transformer"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Dependency-Parsing","text":"Dependency Parsing"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Universal-Dependency-Treebanks","text":"Universal Dependency Treebanks"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Penn-Treebank","text":"Penn Treebank"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/German-CoNLL-2009-Treebank","text":"German CoNLL 2009 Treebank"}],"/Relation-Extraction":[{"source":"/Relation-Extraction","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"}],"/Relational-inductive-biases-deep-learning-and-graph-networks":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victor-Bapst","text":"Victor Bapst"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Alvaro-Sanchez-Gonzalez","text":"Alvaro Sanchez-Gonzalez"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Vinicius-Zambaldi","text":"Vinicius Zambaldi"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Mateusz-Malinowski","text":"Mateusz Malinowski"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrea-Tacchetti","text":"Andrea Tacchetti"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/David-Raposo","text":"David Raposo"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Adam-Santoro","text":"Adam Santoro"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ryan-Faulkner","text":"Ryan Faulkner"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Caglar-Gulcehre","text":"Caglar Gulcehre"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Francis-Song","text":"Francis Song"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrew-Ballard","text":"Andrew Ballard"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Justin-Gilmer","text":"Justin Gilmer"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/George-Dahl","text":"George Dahl"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ashish-Vaswani","text":"Ashish Vaswani"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Kelsey-Allen","text":"Kelsey Allen"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Charles-Nash","text":"Charles Nash"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victoria-Langston","text":"Victoria Langston"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Chris-Dyer","text":"Chris Dyer"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Nicolas-Heess","text":"Nicolas Heess"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Daan-Wierstra","text":"Daan Wierstra"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Pushmeet-Kohli","text":"Pushmeet Kohli"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Matt-Botvinick","text":"Matt Botvinick"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Oriol-Vinyals","text":"Oriol Vinyals"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Yujia-Li","text":"Yujia Li"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Razvan-Pascanu","text":"Razvan Pascanu"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/December-16th-2020","text":"December 16th 2020"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Convolution-Neural-Network","text":"Convolutional Layers"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Locality-Invariant","text":"Locality Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Translation-Invariant","text":"Translation Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Recurrent-Neural-Networks","text":"Recurrent layers"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Temporal-Invariant","text":"Temporal Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks#Impossibility Results and Bottlenecks"}],"/Research-Ideas":[{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/Research-Ideas","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Byte-Pair-Encoding","text":"Byte Pair Encoding"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Mode-Collapse","text":"Mode Collapse"},{"source":"/Research-Ideas","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"},{"source":"/Research-Ideas","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Question-Answering","text":"Question Answering"},{"source":"/Research-Ideas","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Research-Ideas","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/Research-Ideas","target":"/Isotropy","text":"Isotropy"},{"source":"/Research-Ideas","target":"/Anisotropy","text":"Anisotropy"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"},{"source":"/Research-Ideas","target":"/JSALT2020","text":"JSALT2020"},{"source":"/Research-Ideas","target":"/Evaluation-Metric","text":"Evaluation Metric"},{"source":"/Research-Ideas","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Research-Ideas","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Research-Ideas","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Research-Ideas","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Research-Ideas","target":"/PCA","text":"PCA"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/BERT","text":"BERT"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Research-Ideas","target":"/FED-metric","text":"FED metric"}],"/Rethinking-the-Value-of-Transformer-Components":[{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Wenxuan-Wang","text":"Wenxuan Wang"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/November-27th-2020","text":"November 27th, 2020"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/ablation","text":"ablation"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Contribution-in-Information-Flow","text":"Contribution in Information Flow"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/BLEU","text":"BLEU"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Criticality-in-Representation-Generalization","text":"Criticality in Representation Generalization"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Transformer","text":"Transformer"}],"/Rewinding":[{"source":"/Rewinding","target":"/Lottery-Ticket-Hypothesis","text":"Lottery Ticket Hypothesis"}],"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS":[{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Max-Welling","text":"Max Welling"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/December-14th-2020","text":"December 14th 2020"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Neural-Network","text":"Neural Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Semi-Supervised","text":"Semi-Supervised"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"layers"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^41aec7"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^e0c9b8"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"GCN"}],"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES":[{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Dat-Ngo","text":"Dat Ngo"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Hao-Hoang","text":"Hao Hoang"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Anh-Nguyen","text":"Anh Nguyen"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Tien-Ly","text":"Tien Ly"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/31-May-2021","text":"31-May-2021"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Mel-Spectrograms","text":"Mel Spectrograms"}],"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Hyundong-Cho","text":"Hyundong Cho"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Jonathan-May","text":"Jonathan May"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Cornell-Movie","text":"Cornell Movie"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Nucleus-Sampling","text":"Nucleus Sampling"}],"/Saving-Lives-with-Interpretable-ML":[{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Ankur-Teredesai","text":"Ankur Teredesai"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Marzyeh-Ghassemi","text":"Marzyeh Ghassemi"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/July-22nd-2020","text":"July 22nd, 2020"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"}],"/Security-and-Machine-Learning":[{"source":"/Security-and-Machine-Learning","target":"/Emre-Kiciman","text":"Emre Kiciman"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/ImageNet","text":"ImageNet"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Security-and-Machine-Learning","target":"/Duet","text":"Duet"},{"source":"/Security-and-Machine-Learning","target":"/noisy-gradient-descent","text":"noisy gradient descent"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/quantum-entropy-regularization","text":"quantum entropy regularization"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"}],"/Semantic-Role-Labeling":[{"source":"/Semantic-Role-Labeling","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"}],"/Semi-Autoregressive-Neural-Machine-Translation":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Chunqi-Wang","text":"Chunqi Wang"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Ji-Zhang","text":"Ji Zhang"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Haiqing-Chen","text":"Haiqing Chen"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST02","text":"NIST02"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST03","text":"NIST03"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST04","text":"NIST04"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST05","text":"NIST05"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2002E18","text":"LDC2002E18"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2003E14","text":"LDC2003E14"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2004T08","text":"LDC2004T08"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2005T0","text":"LDC2005T0"}],"/Sepformer":[{"source":"/Sepformer","target":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","text":"ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION"},{"source":"/Sepformer","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"}],"/Shallow-to-Deep-Training-for-Neural-Machine-Translation":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Bei-Li","text":"Bei Li"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Ziyang-Wang","text":"Ziyang Wang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Hui-Liu","text":"Hui Liu"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Yufan-Jiang","text":"Yufan Jiang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Quan-Du","text":"Quan Du"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Tong-Xiao","text":"Tong Xiao"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Huizhen-Wang","text":"Huizhen Wang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Jingbo-Zhu","text":"Jingbo Zhu"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/December-1st-2020","text":"December 1st, 2020"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Learning-Rate","text":"Learning Rate"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"}],"/Signed-Graphs":[{"source":"/Signed-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Simple-Graph":[{"source":"/Simple-Graph","target":"/Degree","text":"Degree"},{"source":"/Simple-Graph","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification":[{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Maarten-De-Vos","text":"Maarten De Vos"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"}],"/Speaker-Sensitive-Response-Evaluation-Model-SSREM":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/JinYeong-Bak","text":"JinYeong Bak"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Alice-Oh","text":"Alice Oh"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/June-15th-2020","text":"June 15th, 2020"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/GloVe-Twitter-200d","text":"GloVe Twitter 200d"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Twitter-Conversation-Corpus-Bak-and-Oh-2019","text":"Twitter Conversation Corpus (Bak and Oh, 2019)"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/BLEU","text":"BLEU"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/ROUGE","text":"ROUGE"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/EMB","text":"EMB"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/RUBER","text":"RUBER"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011","text":"Movie Scripts (Danescu-Niculescu-Mizil and Lee, 2011)"}],"/Spectral-Graph-Convolutions":[{"source":"/Spectral-Graph-Convolutions","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Spectral-Graph-Convolutions","target":"/Spectral-Graph","text":"Spectral Graph"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolution","text":"Convolution"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Convolutions","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Spectral-Graph-Convolutions","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Spectral-Graph-Convolutions","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigendecomposition","text":"Eigendecomposition"}],"/Spectral-Graph-Theory":[{"source":"/Spectral-Graph-Theory","target":"/Spectral-Theorem","text":"Spectral Theorem"},{"source":"/Spectral-Graph-Theory","target":"/Linear-Algebra","text":"Linear Algebra"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Theory","target":"/Laplacian-Matrix","text":"Laplacian Matrix"}],"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Xingchen-Song","text":"Xingchen Song"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Guangsen-Wang","text":"Guangsen Wang"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Yiheng-Huang","text":"Yiheng Huang"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Zhiyong-Wu","text":"Zhiyong Wu"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Dan-Su","text":"Dan Su"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Helen-Meng","text":"Helen Meng"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Speech-XLNet","text":"Speech-XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Huber-Loss","text":"Huber Loss"}],"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Mathew-Monfort","text":"Mathew Monfort"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/SouYong-Jin","text":"SouYong Jin"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Alexander-Liu","text":"Alexander Liu"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/David-Harwath","text":"David Harwath"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Rogerio-Feris","text":"Rogerio Feris"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/James-Glass","text":"James Glass"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Aude-Oliva","text":"Aude Oliva"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/May-18th-2021","text":"May 18th 2021"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Spoken-Moments-dataset","text":"Spoken Moments dataset"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Adaptive-Mean-Margin","text":"Adaptive Mean Margin"}],"/Spoken-Moments-dataset":[{"source":"/Spoken-Moments-dataset","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"},{"source":"/Spoken-Moments-dataset","target":"/Multi-Moments-in-Time","text":"Multi-Moments in Time"}],"/Subgraph-wise-Sampling":[{"source":"/Subgraph-wise-Sampling","target":"/Subgraph","text":"Subgraph"}],"/Survey-on-Evaluation-Methods-for-Dialogue-Systems":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Jan-Deriu","text":"Jan Deriu"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alvaro-Rodrigo","text":"Alvaro Rodrigo"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Arantxa-Otegi","text":"Arantxa Otegi"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Guillermo-Echegoyen","text":"Guillermo Echegoyen"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Sophie-Rosset","text":"Sophie Rosset"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Eneko-Agirre","text":"Eneko Agirre"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Mark-Cieliebak","text":"Mark Cieliebak"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/June-19th-2020","text":"June 19th, 2020"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Hidden-Markov-Models","text":"Hidden Markov Models"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conditional-Random-Fields","text":"Conditional Random Fields"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dynamic-Bayesian-Network","text":"Dynamic Bayesian Network"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialogue-Efficiency","text":"Dialogue Efficiency"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Kappa-coefficient","text":"Kappa coefficient"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/PARAdigm-for-DIalog-System-Evaluation","text":"PARAdigm for DIalog System Evaluation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Interaction-Quality","text":"Interaction Quality"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Neural-User-Simulator","text":"Neural User Simulator"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MeMo-workbench","text":"MeMo workbench"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Concept-Error-Rates","text":"Concept Error Rates"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/BLEU","text":"BLEU"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Next-Utterance-Selection","text":"Next Utterance Selection"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Voted-Appropriateness","text":"Voted Appropriateness"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/F-scores","text":"F-scores"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/datasets","text":"datasets"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Ubuntu-Dialogue-Corpus","text":"Ubuntu Dialogue Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MSDialog","text":"MSDialog"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ibAbI","text":"ibAbI"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/bAbI","text":"bAbI"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/QuAC","text":"QuAC"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/CoQA","text":"CoQA"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SwitchBoard","text":"SwitchBoard"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/British-National-Corpus","text":"British National Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SubTle-Corpus","text":"SubTle Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/OpenSubtitles","text":"OpenSubtitles"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Cornell-Movie","text":"Cornell Movie"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialog-State-Tracking-Challenge","text":"Dialog State Tracking Challenge"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alexa-Prize","text":"Alexa Prize"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Lifelong-Learning","text":"Lifelong Learning"}],"/Syntax-GNN":[{"source":"/Syntax-GNN","target":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","text":"Do Syntax Trees Help Pre-trained Transformers Extract Information"},{"source":"/Syntax-GNN","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Syntax-GNN","target":"/Transformer","text":"Transformer"},{"source":"/Syntax-GNN","target":"/Graph-Attention","text":"Graph Attention"}],"/T-norm":[{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/G%C3%B6del-T-norm","text":"Gödel T-norm"},{"source":"/T-norm","target":"/Product-T-norm","text":"Product T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/%C5%81ukasiewicz-T-norm","text":"Łukasiewicz T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/Drastic-T-norm","text":"Drastic T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/Nilpotent-Minimum","text":"Nilpotent Minimum"},{"source":"/T-norm","target":"/Hamacher-Product","text":"Hamacher Product"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"}],"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS":[{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Kai-Yu","text":"Kai Yu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/May-3rd-2021","text":"May 3rd 2021"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"}],"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Shawn-Hershey","text":"Shawn Hershey"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Daniel-P-W-Ellis","text":"Daniel P W Ellis"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Eduardo-Fonseca","text":"Eduardo Fonseca"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Aren-Jansen","text":"Aren Jansen"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Caroline-Liu","text":"Caroline Liu"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/R-Channing-Moore","text":"R Channing Moore"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Manoj-Plakal","text":"Manoj Plakal"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"}],"/TRACKE":[{"source":"/TRACKE","target":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","text":"A Transformer-based Audio Captioning Model with Keyword Estimation"},{"source":"/TRACKE","target":"/VGGish","text":"VGGish"},{"source":"/TRACKE","target":"/FastText","text":"FastText"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"}],"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Nitika-Mathur","text":"Nitika Mathur"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Timothy-Baldwin","text":"Timothy Baldwin"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Trevor-Cohn","text":"Trevor Cohn"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/June-17th-2020","text":"June 17th, 2020"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-I-Errors","text":"Type I Errors"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-II-Errors","text":"Type II Errors"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/WMT","text":"WMT"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/sacreBLEU","text":"sacreBLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BERT","text":"BERT"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-2","text":"YiSi-2"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"}],"/Temporal-Random-Walk":[{"source":"/Temporal-Random-Walk","target":"/Random-Walk","text":"Random Walk"}],"/Texture-Synthesis-Using-Convolutional-Neural-Networks":[{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Matthias-Bethge","text":"Matthias Bethge"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/October-20th-2020","text":"October 20th, 2020"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/VGG19-Architecture","text":"VGG19 (Architecture)"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Gram-matrix","text":"Gram-matrix"}],"/Texture-Synthesis-by-Non-parametric-Sampling":[{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Markov-Random-Field","text":"Markov Random Field"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Image-Inpainting","text":"Image Inpainting"}],"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics":[{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Yuka-Kobayashi","text":"Yuka Kobayashi"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Accuracy","text":"Accuracy"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Precision","text":"Precision"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Recall","text":"Recall"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/F-scores","text":"F-scores"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Jensen-Shannon-Divergence","text":"Jensen-Shannon Divergence"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Mean-Squared-Error","text":"Mean Squared Error"}],"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Tianlong-Chen","text":"Tianlong Chen"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Jonathan-Frankle","text":"Jonathan Frankle"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Shiyu-Chang","text":"Shiyu Chang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Sijia-Liu","text":"Sijia Liu"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Yang-Zhang","text":"Yang Zhang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Zhangyang-Wang","text":"Zhangyang Wang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Michael-Carbin","text":"Michael Carbin"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/July-30th-2020","text":"July 30th, 2020"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/BERT","text":"BERT"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/DistilBERT","text":"DistilBERT"}],"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models":[{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Marzieh-Fadaee","text":"Marzieh Fadaee"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Christof-Monz","text":"Christof Monz"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/May-27th-2020","text":"May 27th, 2020"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Levenshtein-Distance","text":"Levenshtein Distance"}],"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset":[{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Hannah-Rashkin","text":"Hannah Rashkin"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Margaret-Li","text":"Margaret Li"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"}],"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols":[{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/BLEU","text":"BLEU"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/ROUGE","text":"ROUGE"}],"/Towards-a-Human-like-Open-Domain-Chatbot":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Daniel-Adiwardana","text":"Daniel Adiwardana"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Minh-Thang-Luong","text":"Minh-Thang Luong"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Jamie-Hall","text":"Jamie Hall"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Noah-Fiedel","text":"Noah Fiedel"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Romal-Thoppilan","text":"Romal Thoppilan"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Zi-Yang","text":"Zi Yang"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Apoorv-Kulshreshtha","text":"Apoorv Kulshreshtha"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Gaurav-Nemade","text":"Gaurav Nemade"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Yifeng-Lu","text":"Yifeng Lu"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/June-25th-2020","text":"June 25th, 2020"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/embed","text":"embed"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mini-Turning-Benchmark-MTB","text":"Mini-Turning Benchmark (MTB)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/transformer","text":"Transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Transformer","text":"Transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/GPT-2","text":"GPT-2"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/DialogGPT","text":"DialogGPT"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mitsuku","text":"Mitsuku"}],"/Trail":[{"source":"/Trail","target":"/Walk","text":"Walk"}],"/TransE":[{"source":"/TransE","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/TransE","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/TransE","target":"/Manhattan-Distance","text":"Manhattan Distance"},{"source":"/TransE","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/TransE","target":"/KBGAN","text":"KBGAN"},{"source":"/TransE","target":"/Adversarial-Learning","text":"Adversarial Learning"}],"/Translational-Models":[{"source":"/Translational-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Translational-Models","target":"/RotatE","text":"RotatE"},{"source":"/Translational-Models","target":"/Hierarchy-Aware-Knowledge-Graph-Embedding","text":"Hierarchy-Aware Knowledge Graph Embedding"}],"/Tree-LSTM":[{"source":"/Tree-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Tree-LSTM","target":"/LSTM","text":"LSTM"}],"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Chunting-Zhou","text":"Chunting Zhou"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/August-13th-2020","text":"August 13th, 2020"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Europarl","text":"Europarl"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/KL-divergence","text":"KL-divergence"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/FlowSeq","text":"FlowSeq"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/iNAT","text":"iNAT"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Born-Again-Networks","text":"Born-Again Networks"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mixture-of-Experts","text":"Mixture of Experts"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Sequence-Level-Interpolation","text":"Sequence-Level Interpolation"}],"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Sascha-Hornauer","text":"Sascha Hornauer"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Ke-Li","text":"Ke Li"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Shabnam-Ghaffarzadegan","text":"Shabnam Ghaffarzadegan"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Liu-Ren","text":"Liu Ren"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Unsupervised-Discriminative-Learning-of-Sounds","text":"Unsupervised Discriminative Learning of Sounds"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-10","text":"ESC-10"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-50","text":"ESC-50"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/UrbanSound8k","text":"UrbanSound8k"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ImageNet","text":"ImageNet"}],"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE":[{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Itxasne-Diez-Gaspon","text":"Itxasne Diez Gaspon"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Peio-Gonzalez","text":"Peio Gonzalez"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Ibon-Saratxaga","text":"Ibon Saratxaga"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Multisystem-fusion-model-based-on-tag-relationship","text":"Multisystem fusion model based on tag relationship"}],"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS":[{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Jaehun-Kim","text":"Jaehun Kim"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"Harmonic Percussive Source Separation"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"HPSS"}],"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases":[{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Huang-Xie","text":"Huang Xie"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Okko-R%C3%A4s%C3%A4nen","text":"Okko Räsänen"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/05-Jan-2022","text":"05-Jan-2022"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Convolutional-Recurrent-Neural-Network","text":"CRNN"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/word2vec","text":"word2vec"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/skip-gram","text":"skip-gram"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Automated-Audio-Captioning","text":"AAC"}],"/Unsupervised-Discriminative-Learning-of-Sounds":[{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","text":"UNSUPERVISED DISCRIMINATIVE LEARNING OF SOUNDS FOR AUDIO EVENT CLASSIFICATION"},{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"}],"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT":[{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Shikib-Mehri","text":"Shikib Mehri"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Maxine-Eskenazi","text":"Maxine Eskenazi"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/June-25th-2020","text":"June 25th, 2020"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Partial-Scoring","text":"Partial Scoring"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Meena","text":"Meena"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Mitsuku","text":"Mitsuku"}],"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Alexei-Baevski","text":"Alexei Baevski"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Steffen-Schneider","text":"Steffen Schneider"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Michael-Auli","text":"Michael Auli"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/April-30th-2021","text":"April 30th 2021"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/K-means-clustering","text":"K-means clustering"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/BERT","text":"BERT"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Letter-Error-Rate","text":"Letter Error Rate"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"}],"/Visualizing-Data-using-t-SNE":[{"source":"/Visualizing-Data-using-t-SNE","target":"/Laurens-van-der-Maaten","text":"Laurens van der Maaten"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"},{"source":"/Visualizing-Data-using-t-SNE","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/SNE","text":"SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Crowding-Problem","text":"Crowding Problem"},{"source":"/Visualizing-Data-using-t-SNE","target":"/UNI-SNE","text":"UNI-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Isomap","text":"Isomap"},{"source":"/Visualizing-Data-using-t-SNE","target":"/LLE","text":"LLE"}],"/WIKIHOP-dataset":[{"source":"/WIKIHOP-dataset","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"}],"/WMT":[{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/WMT","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/WMT","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/WMT","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/WMT","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/WMT","target":"/WMT18-En-De","text":"WMT18 En-De"}],"/WaveTransformer":[{"source":"/WaveTransformer","target":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","text":"WaveTransformer - A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/WaveNet","text":"WaveNet"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/WaveTransformer","target":"/Transformer","text":"Transformer"}],"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information":[{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/An-Tran","text":"An Tran"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/WaveTransformer","text":"WaveTransformer"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Transformer","text":"Transformer"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/cross-entropy","text":"cross entropy"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/BLEU","text":"BLEU"}],"/Week-Summary-010620-210620":[{"source":"/Week-Summary-010620-210620","target":"/June-1st-2020","text":"June 1st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","text":"Is this Dialogue Coherent - Learning from Dialogue Acts and Entities"},{"source":"/Week-Summary-010620-210620","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","text":"Learning not to Discriminate - Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition"},{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","text":"ProphetNet - Predicting Future N-gram for Sequence-to-Sequence Pre-training"},{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"},{"source":"/Week-Summary-010620-210620","target":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","text":"Evaluating dialogue breakdown detection in chat-oriented dialogue systems"},{"source":"/Week-Summary-010620-210620","target":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","text":"Dialogue breakdown detection using BERT with traditional dialogue features"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","text":"Survey on Evaluation Methods for Dialogue Systems"},{"source":"/Week-Summary-010620-210620","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"},{"source":"/Week-Summary-010620-210620","target":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","text":"YiSi - a Unified Semantic MT Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources"},{"source":"/Week-Summary-010620-210620","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Week-Summary-010620-210620","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/Week-Summary-010620-210620","target":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","text":"Speaker Sensitive Response Evaluation Model (SSREM)"},{"source":"/Week-Summary-010620-210620","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"},{"source":"/Week-Summary-010620-210620","target":"/OpenAI","text":"OpenAI"},{"source":"/Week-Summary-010620-210620","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/BLEU","text":"BLEU"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"}],"/Week-Summary-021120-221120":[{"source":"/Week-Summary-021120-221120","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","text":"PSECMAC - A Novel Self-Organizing Multiresolution Associative Memory Architecture"},{"source":"/Week-Summary-021120-221120","target":"/Kernel-CMAC-With-Improved-Capability","text":"Kernel CMAC With Improved Capability"},{"source":"/Week-Summary-021120-221120","target":"/Learning-Convergence-of-CMAC-Technique","text":"Learning Convergence of CMAC Technique"},{"source":"/Week-Summary-021120-221120","target":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","text":"Improved MCMAC with Momentum, Neighborhood, and Averaged Trapezoidal Output"},{"source":"/Week-Summary-021120-221120","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","text":"Hierarchically Clustered Adaptive Quantization CMAC and Its Learning Convergence"},{"source":"/Week-Summary-021120-221120","target":"/Generalizing-CMAC-Architecture-and-Training","text":"Generalizing CMAC Architecture and Training"},{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","text":"Comparison of Convergence Properties of CMAC Neural Network and Traditional Adaptive Controllers"},{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","text":"Comparison of CMAC Architectures for Neural Network Based Control"}],"/Week-Summary-030820-160820":[{"source":"/Week-Summary-030820-160820","target":"/August-3rd-2020","text":"August 3rd, 2020"},{"source":"/Week-Summary-030820-160820","target":"/August-16th-2020","text":"August 16th, 2020"},{"source":"/Week-Summary-030820-160820","target":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","text":"Imputer - Sequence Modelling via Imputation and Dynamic Programming"},{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","text":"Non-Autoregressive Machine Translation with Latent Alignments"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"},{"source":"/Week-Summary-030820-160820","target":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","text":"NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","text":"Discovering and Categorizing Language Biases in Reddit"},{"source":"/Week-Summary-030820-160820","target":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","text":"Defining and Evaluating Fair Natural Language Generation"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"}],"/Week-Summary-060720-190720":[{"source":"/Week-Summary-060720-190720","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","text":"Personalizing Dialogue Agents - I have a dog, do you have pets too"},{"source":"/Week-Summary-060720-190720","target":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","text":"DialoGPT - Large-Scale Generative Pre-training for Conversational Response Generation"},{"source":"/Week-Summary-060720-190720","target":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","text":"Towards Empathetic Open-domain Conversation Models - a New Benchmark and Dataset"},{"source":"/Week-Summary-060720-190720","target":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","text":"DailyDialog - A Manually Labelled Multi-turn Dialogue Dataset"},{"source":"/Week-Summary-060720-190720","target":"/Modeling-Local-Coherence-An-Entity-Based-Approach","text":"Modeling Local Coherence - An Entity-Based Approach"},{"source":"/Week-Summary-060720-190720","target":"/Visualizing-Data-using-t-SNE","text":"Visualizing Data using t-SNE"}],"/Week-Summary-071220-131220":[{"source":"/Week-Summary-071220-131220","target":"/December-7th-2020","text":"December 7th 2020"},{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"},{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"},{"source":"/Week-Summary-071220-131220","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Week-Summary-141220-271220":[{"source":"/Week-Summary-141220-271220","target":"/December-14th-2020","text":"December 14th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"},{"source":"/Week-Summary-141220-271220","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"},{"source":"/Week-Summary-141220-271220","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"},{"source":"/Week-Summary-141220-271220","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"},{"source":"/Week-Summary-141220-271220","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Neural-Networks","text":"GNN"}],"/Week-Summary-170820-230820":[{"source":"/Week-Summary-170820-230820","target":"/August-17th-2020","text":"August 17th, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/Paper-Levenshtein-Transformer","text":"(Paper) Levenshtein Transformer"},{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","text":"Mask-Predict - Parallel Decoding of Conditional Masked Language Models"},{"source":"/Week-Summary-170820-230820","target":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","text":"Multilingual KERMIT - It’s Not Easy Being Generative"},{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"},{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","text":"Insertion Transformer - Flexible Sequence Generation via Insertion Operations"},{"source":"/Week-Summary-170820-230820","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"}],"/Week-Summary-180520-240520":[{"source":"/Week-Summary-180520-240520","target":"/May-18th-2020","text":"May 18th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"},{"source":"/Week-Summary-180520-240520","target":"/Poor-Mans-BERT-Smaller-and-Faster-Transformer-Models","text":"Poor Man's BERT - Smaller and Faster Transformer Models"},{"source":"/Week-Summary-180520-240520","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-180520-240520","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"},{"source":"/Week-Summary-180520-240520","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-180520-240520","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"},{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"},{"source":"/Week-Summary-180520-240520","target":"/Softmax","text":"Softmax"}],"/Week-Summary-200720-020820":[{"source":"/Week-Summary-200720-020820","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"},{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"},{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"},{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"source":"/Week-Summary-200720-020820","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-200720-020820","target":"/BERT","text":"BERT"},{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"},{"source":"/Week-Summary-200720-020820","target":"/Transformer-XL","text":"Transformer-XL"}],"/Week-Summary-210920-011120":[{"source":"/Week-Summary-210920-011120","target":"/September-21st-2020","text":"September 21st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","text":"NEFCLASS - A Neuro-Fuzzy approach for the classification of data (Paper)"},{"source":"/Week-Summary-210920-011120","target":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","text":"Interpretability Improvements to Find the Balance Interpretability-Accuracy in Fuzzy Modeling - An Overview (2003)"},{"source":"/Week-Summary-210920-011120","target":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","text":"HEDGE ALGEBRAS - AN ALGEBRAIC APPROACH TO STRUCTURE OF SETS OF LINGUISTIC TRUTH VALUES"},{"source":"/Week-Summary-210920-011120","target":"/Generative-Pretraining-from-Pixels","text":"Generative Pretraining from Pixels"},{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","text":"Texture Synthesis Using Convolutional Neural Networks"},{"source":"/Week-Summary-210920-011120","target":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","text":"Image Quilting for Texture Synthesis and Transfer"},{"source":"/Week-Summary-210920-011120","target":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","text":"Implementing fuzzy logic controllers using a neural network framework (1990)"},{"source":"/Week-Summary-210920-011120","target":"/Fuzzy-Sets-1965","text":"Fuzzy Sets (1965)"},{"source":"/Week-Summary-210920-011120","target":"/Color-Indexing","text":"Color Indexing"},{"source":"/Week-Summary-210920-011120","target":"/Face-Recognition-Using-Eigenfaces","text":"Face Recognition Using Eigenfaces"},{"source":"/Week-Summary-210920-011120","target":"/Mean-Shift-Analysis-and-Applications","text":"Mean Shift Analysis and Applications"},{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-by-Non-parametric-Sampling","text":"Texture Synthesis by Non-parametric Sampling"},{"source":"/Week-Summary-210920-011120","target":"/Compositional-rule-of-inference-as-an-analogical-scheme","text":"Compositional rule of inference as an analogical scheme"}],"/Week-Summary-220620-050720":[{"source":"/Week-Summary-220620-050720","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"},{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"},{"source":"/Week-Summary-220620-050720","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Week-Summary-220620-050720","target":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","text":"Towards Unified Dialogue System Evaluation - A Comprehensive Analysis of Current Evaluation Protocols"},{"source":"/Week-Summary-220620-050720","target":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","text":"Unsupervised Evaluation of Interactive Dialog with DialoGPT"},{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"},{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"},{"source":"/Week-Summary-220620-050720","target":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","text":"Overview of the dialogue breakdown detection challenge 3"},{"source":"/Week-Summary-220620-050720","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"},{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"},{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"}],"/Week-Summary-231120-291120":[{"source":"/Week-Summary-231120-291120","target":"/November-23rd-2020","text":"November 23rd, 2020"},{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/Week-Summary-231120-291120","target":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","text":"What Can We Do to Improve Peer Review in NLP"},{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"},{"source":"/Week-Summary-231120-291120","target":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","text":"FROM UNSUPERVISED MACHINE TRANSLATION TO ADVERSARIAL TEXT GENERATION"},{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"},{"source":"/Week-Summary-231120-291120","target":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","text":"Context-Aware Cross-Attention for Non-Autoregressive Translation"},{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"},{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"}],"/Week-Summary-240820-300820":[{"source":"/Week-Summary-240820-300820","target":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","text":"GLAT - Glancing Transformer for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","text":"FlowSeq - Non-Autoregressive Conditional Sequence Generation with Generative Flow"},{"source":"/Week-Summary-240820-300820","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"},{"source":"/Week-Summary-240820-300820","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"},{"source":"/Week-Summary-240820-300820","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"},{"source":"/Week-Summary-240820-300820","target":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","text":"Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning"},{"source":"/Week-Summary-240820-300820","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"}],"/Week-Summary-250520-310520":[{"source":"/Week-Summary-250520-310520","target":"/May-25th-2020","text":"May 25th, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"},{"source":"/Week-Summary-250520-310520","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"},{"source":"/Week-Summary-250520-310520","target":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","text":"Faster Transformer Decoding - N-gram Masked Self-Attention"},{"source":"/Week-Summary-250520-310520","target":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","text":"The Unreasonable Volatility of Neural Machine Translation Models"},{"source":"/Week-Summary-250520-310520","target":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","text":"Are Transformers universal approximators of sequence-to-sequence functions"},{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"},{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"},{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"},{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"}],"/Week-Summary-301120-061220":[{"source":"/Week-Summary-301120-061220","target":"/November-30th-2020","text":"November 30th, 2020"},{"source":"/Week-Summary-301120-061220","target":"/December-6th-2020","text":"December 6th 2020"},{"source":"/Week-Summary-301120-061220","target":"/December-7th-2020","text":"December 7th 2020"},{"source":"/Week-Summary-301120-061220","target":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","text":"LANGUAGE MODEL IS ALL YOU NEED - NATURAL LANGUAGE UNDERSTANDING AS QUESTION ANSWERING"},{"source":"/Week-Summary-301120-061220","target":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","text":"Shallow-to-Deep Training for Neural Machine Translation"},{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"},{"source":"/Week-Summary-301120-061220","target":"/Efficient-Inference-For-Neural-Machine-Translation","text":"Efficient Inference For Neural Machine Translation"},{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"}],"/Week-Summary-310820-200920":[{"source":"/Week-Summary-310820-200920","target":"/August-30th-2020","text":"August 30th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"},{"source":"/Week-Summary-310820-200920","target":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","text":"Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation"}],"/Weight-Poisoning-Attacks-on-Pre-trained-Model":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Keita-Kurita","text":"Keita Kurita"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Paul-Michel","text":"Paul Michel"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/June-1st-2020","text":"June 1st, 2020"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/RIPPLe","text":"RIPPLe"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/bi-level-optimization","text":"bi-level optimization"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Label-Flip-Rate","text":"Label Flip Rate"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/SST-2","text":"SST-2"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/OffenseEval","text":"OffenseEval"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Enron","text":"Enron"}],"/Weisfieler-Lehman-test":[{"source":"/Weisfieler-Lehman-test","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Weisfieler-Lehman-test","target":"/Injective","text":"Injective"},{"source":"/Weisfieler-Lehman-test","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"}],"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP":[{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Anna-Rogers","text":"Anna Rogers"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Isabelle-Augenstein","text":"Isabelle Augenstein"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Peer-Review","text":"Peer Review"}],"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Shucong-Zhang","text":"Shucong Zhang"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Erfan-Loweimi","text":"Erfan Loweimi"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Peter-Bell","text":"Peter Bell"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Steve-Renals","text":"Steve Renals"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/May-29th-2020","text":"May 29th, 2020"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/WSJ","text":"WSJ"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/eval-2000-SWBD","text":"eval 2000 SWBD"}],"/WikiText-103":[{"source":"/WikiText-103","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"}],"/Winograd-NLI":[{"source":"/Winograd-NLI","target":"/Winograd","text":"Winograd"},{"source":"/Winograd-NLI","target":"/Winogrande","text":"Winogrande"},{"source":"/Winograd-NLI","target":"/GLUE-Benchmark","text":"GLUE Benchmark"}],"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources":[{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Chi-kiu-Lo","text":"Chi-kiu Lo"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/June-18th-2020","text":"June 18th, 2020"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/BERT","text":"BERT"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/GloVe","text":"GloVe"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/word2vec","text":"word2vec"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/MATE","text":"MATE"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/chrF","text":"chrF"}],"/datasets":[{"source":"/datasets","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"}],"/diffpool":[{"source":"/diffpool","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/diffpool","target":"/Softmax","text":"Softmax"}],"/gPool":[{"source":"/gPool","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"},{"source":"/gPool","target":"/GCN-Filter","text":"GCN-Filter"}],"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Hongyi-Zhang","text":"Hongyi Zhang"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Moustapha-Cisse","text":"Moustapha Cisse"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/David-Lopez-Paz","text":"David Lopez-Paz"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Classification","text":"Classification"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"Empirical Risk Minimization"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"EMR"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Vicinal-Risk-Minimization","text":"Vicinal Risk Minimization"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Generative-Adversarial-Network","text":"GAN"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Occams-Razor","text":"Occam's Razor"}],"/node2vec":[{"source":"/node2vec","target":"/DeepWalk","text":"DeepWalk"},{"source":"/node2vec","target":"/Random-Walk","text":"Random Walk"}],"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Alexei-Baevski","text":"Alexei Baevski"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Henry-Zhou","text":"Henry Zhou"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Abdelrahman-Mohamed","text":"Abdelrahman Mohamed"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Michael-Auli","text":"Michael Auli"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Positional-Encodings","text":"Positional Encodings"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriVox","text":"LibriVox"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Phoneme-Recoginition","text":"Phoneme Recoginition"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/TIMIT-dataset","text":"TIMIT dataset"}]},"backlinks":{"/%C5%81ukasiewicz-T-norm":[{"source":"/T-norm","target":"/%C5%81ukasiewicz-T-norm","text":"Łukasiewicz T-norm"}],"/%C5%81ukasz-Kaiser":[{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"}],"/01-Jun-2021":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"}],"/05-Feb-2022":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/05-Feb-2022","text":"05-Feb-2022"}],"/05-Jan-2022":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/05-Jan-2022","text":"05-Jan-2022"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/05-Jan-2022","text":"05-Jan-2022"}],"/07-Jun-2021":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"}],"/08-Jun-2021":[{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/08-Jun-2021","text":"08-Jun-2021"}],"/15-Jul-2021":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/15-Jul-2021","text":"15-Jul-2021"}],"/20NEWS":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/20NEWS","text":"20NEWS"}],"/31-May-2021":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/31-May-2021","text":"31-May-2021"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/31-May-2021","text":"31-May-2021"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/31-May-2021","text":"31-May-2021"}],"/3D-Point-Cloud-Estimation":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/3D-Point-Cloud-Estimation","text":"3D Point Cloud Estimation"}],"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation":[{"source":"/Multi30k","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"},{"source":"/Week-Summary-141220-271220","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"}],"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works":[{"source":"/Amnesic-Probing","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"},{"source":"/Isotropy","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"}],"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation":[{"source":"/Week-Summary-180520-240520","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"},{"source":"/Week-Summary-240820-300820","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"}],"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation":[{"source":"/TRACKE","target":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","text":"A Transformer-based Audio Captioning Model with Keyword Estimation"}],"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Week-Summary-220620-050720","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"}],"/AGENDA":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AGENDA","text":"AGENDA"}],"/AMR17":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"}],"/ANLI":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ANLI","text":"ANLI"}],"/ARC":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ARC","text":"ARC"}],"/ATIS":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"}],"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION":[{"source":"/Sepformer","target":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","text":"ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION"}],"/Aaron-Zweig":[{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aaron-Zweig","text":"Aaron Zweig"}],"/Abdelrahman-Mohamed":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Abdelrahman-Mohamed","text":"Abdelrahman Mohamed"}],"/Abdelrhman-Saleh":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Abdelrhman-Saleh","text":"Abdelrhman Saleh"}],"/Abstract-Meaning-Representations":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Abstract-Meaning-Representations","text":"Abstract Meaning Representations"}],"/Abstractive-Summarization":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Abstractive-Summarization","text":"Abstractive Summarization"}],"/Accelerating-Machine-Learning-with-Confidential-Computing":[{"source":"/Frontiers-in-Machine-Learning","target":"/Accelerating-Machine-Learning-with-Confidential-Computing","text":"Accelerating Machine Learning with Confidential Computing"}],"/Accuracy":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Accuracy","text":"Accuracy"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Accuracy","text":"Accuracy"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Accuracy","text":"Accuracy"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Accuracy","text":"Accuracy"}],"/Acoustic-Scene-Classification":[{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Acoustic-Scene-Classification","text":"Acoustic Scene Classification"}],"/Across-Dimension-Neighbor":[{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Across-Dimension-Neighbor","text":"Across-Dimension Neighbor"}],"/Activation-Function":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Activation-Function","text":"Activation Function"},{"source":"/Graph-Attention","target":"/Activation-Function","text":"Activation Function"},{"source":"/Graph-Convolutional-Network","target":"/Activation-Function","text":"Activation Function"}],"/Adafactor":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adafactor","text":"Adafactor"}],"/Adam":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adam","text":"Adam"}],"/Adam-Santoro":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Adam-Santoro","text":"Adam Santoro"}],"/Adaptive-Character-of-Thought-ACT-Memory-Model":[{"source":"/CE7429-Lecture-13","target":"/Adaptive-Character-of-Thought-ACT-Memory-Model","text":"Adaptive Character of Thought (ACT) Memory Model"}],"/Adaptive-Mean-Margin":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Adaptive-Mean-Margin","text":"Adaptive Mean Margin"}],"/Aditya-Grover":[{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aditya-Grover","text":"Aditya Grover"}],"/Aditya-Ramesh":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Aditya-Ramesh","text":"Aditya Ramesh"}],"/Adjacency":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Adjacency","text":"Adjacency"},{"source":"/Intra-sentential-Relations","target":"/Adjacency","text":"Adjacency"}],"/Adjacency-Matrix":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/EigenPooling","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Eigenvector-Centrality","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Convolutional-Network","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Knowledge-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Multi-dimensional-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Pro-GNN","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Signed-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Simple-Graph","target":"/Adjacency-Matrix","text":"Adjacency Matrix"}],"/Adriana-Romero":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Adriana-Romero","text":"Adriana Romero"}],"/Adversarial-Learning":[{"source":"/TransE","target":"/Adversarial-Learning","text":"Adversarial Learning"}],"/Adversarial-Loss":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Adversarial-Loss","text":"Adversarial Loss"}],"/Agenda-based-User-Simulation":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"}],"/Agglomerative-Hierarchical-Clustering":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Agglomerative-Hierarchical-Clustering","text":"Agglomerative Hierarchical Clustering"}],"/Aggregator-Functions":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Aggregator-Functions","text":"Aggregator Functions"},{"source":"/Graph-Isomorphism-Networks","target":"/Aggregator-Functions","text":"aggregator"},{"source":"/Graph-Neural-Networks","target":"/Aggregator-Functions","text":"Aggregator Functions"}],"/Ahmad-Rashid":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Ahmad-Rashid","text":"Ahmad Rashid"}],"/Akshay-Krishnamurthy":[{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"}],"/Alan-Do-Omri":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Alan-Do-Omri","text":"Alan Do-Omri"}],"/Alan-Turing-The-Enigma":[{"source":"/Reading-List","target":"/Alan-Turing-The-Enigma","text":"Alan Turing - The Enigma"}],"/Alec-Radford":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Alec-Radford","text":"Alec Radford"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Alec-Radford","text":"Alec Radford"}],"/Aleksander-Madry":[{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"}],"/Alessandra-Cervone":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Alessandra-Cervone","text":"Alessandra Cervone"}],"/Alex-Shamis":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Alex-Shamis","text":"Alex Shamis"}],"/Alexa-Prize":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alexa-Prize","text":"Alexa Prize"}],"/Alexander-Hoyle":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Alexander-Hoyle","text":"Alexander Hoyle"}],"/Alexander-Liu":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Alexander-Liu","text":"Alexander Liu"}],"/Alexander-Schindler":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Alexander-Schindler","text":"Alexander Schindler"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Alexander-Schindler","text":"Alexander Schindler"}],"/Alexandros-Papangelis":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Alexandros-Papangelis","text":"Alexandros Papangelis"}],"/Alexei-Baevski":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Alexei-Baevski","text":"Alexei Baevski"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Alexei-Baevski","text":"Alexei Baevski"}],"/Alfred-Mertins":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Alfred-Mertins","text":"Alfred Mertins"}],"/Algebraic-Multiplicity":[{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.2","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"}],"/Ali-Razavi":[{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Ali-Razavi","text":"Ali Razavi"}],"/Alice-Oh":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Alice-Oh","text":"Alice Oh"}],"/Alireza-Mohammadshahi":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Alireza-Mohammadshahi","text":"Alireza Mohammadshahi"}],"/Alvaro-Rodrigo":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alvaro-Rodrigo","text":"Alvaro Rodrigo"}],"/Alvaro-Sanchez-Gonzalez":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Alvaro-Sanchez-Gonzalez","text":"Alvaro Sanchez-Gonzalez"}],"/Alyssa-Chen":[{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Alyssa-Chen","text":"Alyssa Chen"}],"/Amanda-Askell":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Amanda-Askell","text":"Amanda Askell"}],"/Amazon-Mechanical-Turk":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"}],"/Amit-Sharma":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"}],"/Amnesic-Probing":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"}],"/Amr-Ahmed":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Amr-Ahmed","text":"Amr Ahmed"}],"/An-Tran":[{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/An-Tran","text":"An Tran"}],"/Ana-Marasovi%C4%87":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Ana-Marasovi%C4%87","text":"Ana Marasović"}],"/Ana-Peleteiro-Ramallo":[{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Ana-Peleteiro-Ramallo","text":"Ana Peleteiro Ramallo"}],"/Analogical-Scheme":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Analogical-Scheme","text":"Analogical Scheme"}],"/Andrea-Madotto":[{"source":"/Misinformation-has-High-Perplexity","target":"/Andrea-Madotto","text":"Andrea Madotto"}],"/Andrea-Tacchetti":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrea-Tacchetti","text":"Andrea Tacchetti"}],"/Andrew-Ballard":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrew-Ballard","text":"Andrew Ballard"}],"/Andrew-Hodges":[{"source":"/Alan-Turing-The-Enigma","target":"/Andrew-Hodges","text":"Andrew Hodges"}],"/Andrew-Ng":[{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"}],"/Andrew-Prahl":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"}],"/Anh-Nguyen":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Anh-Nguyen","text":"Anh Nguyen"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Anh-Nguyen","text":"Anh Nguyen"}],"/Anirudh-Ravula":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Anirudh-Ravula","text":"Anirudh Ravula"}],"/Anisotropy":[{"source":"/Catch-the-Tails-of-BERT","target":"/Anisotropy","text":"Anisotropy"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"Anisotropy"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/Research-Ideas","target":"/Anisotropy","text":"Anisotropy"}],"/Ankit-Singh-Rawat":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Ankit-Singh-Rawat","text":"Ankit Singh Rawat"}],"/Ankur-Bapna":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ankur-Bapna","text":"Ankur Bapna"}],"/Ankur-Teredesai":[{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Ankur-Teredesai","text":"Ankur Teredesai"}],"/Anna-Rogers":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rogers","text":"Anna Rogers"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Anna-Rogers","text":"Anna Rogers"}],"/Anna-Rumshisky":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rumshisky","text":"Anna Rumshisky"}],"/Antoine-Delignat-Lavaud":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"}],"/Antonio-Art%C3%A9s-Rodr%C3%ADguez":[{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Antonio-Art%C3%A9s-Rodr%C3%ADguez","text":"Antonio Artés Rodríguez"}],"/Anurag-Kumar":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Anurag-Kumar","text":"Anurag Kumar"}],"/Apoorv-Kulshreshtha":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Apoorv-Kulshreshtha","text":"Apoorv Kulshreshtha"}],"/Approximate-Rule-Based-Systems":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Approximate-Rule-Based-Systems","text":"Approximate Rule-Based Systems"}],"/April-27th-2021":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/April-27th-2021","text":"April 27th 2021"}],"/April-30th-2021":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/April-30th-2021","text":"April 30th 2021"}],"/Arantxa-Casanova":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Arantxa-Casanova","text":"Arantxa Casanova"}],"/Arantxa-Otegi":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Arantxa-Otegi","text":"Arantxa Otegi"}],"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions":[{"source":"/Week-Summary-250520-310520","target":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","text":"Are Transformers universal approximators of sequence-to-sequence functions"}],"/Aren-Jansen":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Aren-Jansen","text":"Aren Jansen"}],"/Ariel-Herbert-Voss":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ariel-Herbert-Voss","text":"Ariel Herbert-Voss"}],"/Arthur-Szlam":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Arthur-Szlam","text":"Arthur Szlam"}],"/Arvind-Neelakantan":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Arvind-Neelakantan","text":"Arvind Neelakantan"}],"/Ashish-Vaswani":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ashish-Vaswani","text":"Ashish Vaswani"}],"/Asli-Celikyilmaz":[{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"}],"/Associative":[{"source":"/Graphite","target":"/Associative","text":"Associative"}],"/Attraction-Force-Field":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"}],"/Aude-Oliva":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Aude-Oliva","text":"Aude Oliva"}],"/Audio-Grounding-dataset":[{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"}],"/Audio-Tagging":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/Research-Ideas","target":"/Audio-Tagging","text":"Audio Tagging"}],"/AudioCaps":[{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/AudioCaps","text":"AudioCaps"}],"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild":[{"source":"/AudioCaps","target":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","text":"AudioCaps - Generating Captions for Audios in The Wild"}],"/AudioSet":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/AudioSet","text":"AudioSet"},{"source":"/Audio-Grounding-dataset","target":"/AudioSet","text":"AudioSet"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioSet","text":"AudioSet"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"}],"/Augmented-Reality":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Augmented-Reality","text":"Augmented Reality"}],"/August-11th-2020":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/August-11th-2020","text":"August 11th, 2020"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/August-11th-2020","text":"August 11th, 2020"}],"/August-12th-2020":[{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/August-12th-2020","text":"August 12th, 2020"},{"source":"/Lecture-1","target":"/August-12th-2020","text":"August 12th, 2020"}],"/August-13th-2020":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/August-13th-2020","text":"August 13th, 2020"}],"/August-14th-2020":[{"source":"/CE7429-Lecture-2","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/CE7429-Lecture-3","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/August-14th-2020","text":"August 14th, 2020"}],"/August-15th-2020":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/August-15th-2020","text":"August 15th, 2020"}],"/August-16th-2020":[{"source":"/Week-Summary-030820-160820","target":"/August-16th-2020","text":"August 16th, 2020"}],"/August-17th-2020":[{"source":"/Week-Summary-170820-230820","target":"/August-17th-2020","text":"August 17th, 2020"}],"/August-18th-2020":[{"source":"/CE7429-Lecture-12","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/CE7429-Lecture-4","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/August-18th-2020","text":"August 18th, 2020"}],"/August-19th-2020":[{"source":"/CE7491-Lecture-2","target":"/August-19th-2020","text":"August 19th, 2020"}],"/August-20th-2020":[{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/August-20th-2020","text":"August 20th, 2020"}],"/August-21st-2020":[{"source":"/CE7429-Lecture-5","target":"/August-21st-2020","text":"August 21st, 2020"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/August-21st-2020","text":"August 21st, 2020"}],"/August-22nd-2020":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/August-22nd-2020","text":"August 22nd, 2020"}],"/August-23rd-2020":[{"source":"/Paper-Levenshtein-Transformer","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"}],"/August-24th-2020":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/August-24th-2020","text":"August 24th, 2020"}],"/August-25th-2020":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/CE7429-Lecture-6","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"}],"/August-26th-2020":[{"source":"/CE7491-Lecture-3","target":"/August-26th-2020","text":"August 26th, 2020"}],"/August-28th-2020":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/August-28th-2020","text":"August 28th, 2020"},{"source":"/CE7429-Lecture-7","target":"/August-28th-2020","text":"August 28th, 2020"}],"/August-2nd-2020":[{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"},{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"}],"/August-30th-2020":[{"source":"/Week-Summary-310820-200920","target":"/August-30th-2020","text":"August 30th, 2020"}],"/August-3rd-2020":[{"source":"/Week-Summary-030820-160820","target":"/August-3rd-2020","text":"August 3rd, 2020"}],"/Augustin-Arnault":[{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Augustin-Arnault","text":"Augustin Arnault"}],"/Augustin-Chaintreau":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"}],"/Auto-Encoders":[{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Graphite-AE","target":"/Auto-Encoders","text":"Auto-Encoders"}],"/Automated-Audio-Captioning":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Clotho-dataset","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Research-Ideas","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"}],"/Average-Attention-Network-AAN":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Average-Attention-Network-AAN","text":"Average Attention Network (AAN)"}],"/Average-Pooling":[{"source":"/Flat-Graph-Pooling","target":"/Average-Pooling","text":"Average Pooling"}],"/Averaging-Filter":[{"source":"/CE7491-Lecture-2","target":"/Averaging-Filter","text":"Averaging Filter"}],"/Avinava-Dubey":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Avinava-Dubey","text":"Avinava Dubey"}],"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"}],"/BART":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/BART","text":"BART"}],"/BC":[{"source":"/CZ1104-Lecture-7.2","target":"/BC","text":"A"}],"/BERT":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BERT","text":"BERT"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/BERT","text":"BERT"},{"source":"/Misinformation-has-High-Perplexity","target":"/BERT","text":"BERT"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/BERT","text":"BERT"},{"source":"/Research-Ideas","target":"/BERT","text":"BERT"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BERT","text":"BERT"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/BERT","text":"BERT"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/BERT","text":"BERT"},{"source":"/Week-Summary-200720-020820","target":"/BERT","text":"BERT"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/BERT","text":"BERT"}],"/BLEU":[{"source":"/10-things-you-should-know-about-dialogue","target":"/BLEU","text":"BLEU"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BLEU","text":"BLEU"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/BLEU","text":"BLEU"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Machine-Learning-Conversations","target":"/BLEU","text":"BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/BLEU","text":"BLEU"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/BLEU","text":"BLEU"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/BLEU","text":"BLEU"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/BLEU","text":"BLEU"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/BLEU","text":"BLEU"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/BLEU","text":"BLEU"},{"source":"/Week-Summary-010620-210620","target":"/BLEU","text":"BLEU"}],"/Bag-of-Features":[{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Bag-of-Features","text":"Bag of Features"}],"/Balance-Theory":[{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Balance-Theory","text":"Balance Theory"}],"/Basil-Abraham":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Basil-Abraham","text":"Basil Abraham"}],"/Batch-Normalization":[{"source":"/CE7491-Lecture-5","target":"/Batch-Normalization","text":"Batch Normalization"}],"/Bayan-Abu-Shawar":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Bayan-Abu-Shawar","text":"Bayan Abu Shawar"}],"/Bayes-Network":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Bayes-Network","text":"Bayes Network"}],"/Bayes-Theorem":[{"source":"/CE7429-Lecture-3","target":"/Bayes-Theorem","text":"Bayes Theorem"}],"/Bayesian-Belief-Networks":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bayesian-Belief-Networks","text":"Bayesian Belief Networks"}],"/Beam-Search":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Beam-Search","text":"Beam Search"},{"source":"/Match-and-Map","target":"/Beam-Search","text":"Beam Search"}],"/Bei-Li":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Bei-Li","text":"Bei Li"}],"/Ben-Poole":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Ben-Poole","text":"Ben Poole"}],"/Benjamin-Chess":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Chess","text":"Benjamin Chess"}],"/Benjamin-Mann":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Mann","text":"Benjamin Mann"}],"/Bernadette-Bouchon-Meunier":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Bernadette-Bouchon-Meunier","text":"Bernadette Bouchon-Meunier"}],"/Bernado-Avila-Pires":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bernado-Avila-Pires","text":"Bernado Avila Pires"}],"/BertScore":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BertScore","text":"BertScore"}],"/Besmira-Nushi":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Besmira-Nushi","text":"Besmira Nushi"}],"/Best-Approximation-Theorem":[{"source":"/CZ1104-Lecture-6.2","target":"/Best-Approximation-Theorem","text":"Best Approximation Theorem"}],"/Betweenness-Centrality":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Betweenness-Centrality","text":"Betweenness Centrality"}],"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity":[{"source":"/Frontiers-in-Machine-Learning","target":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","text":"Beyond Fairness - Pushing ML Frontiers for Social Equity"}],"/BiLSTM":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/BiLSTM","text":"BiLSTM"}],"/Biased-Random-Walk":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Biased-Random-Walk","text":"Biased Random Walk"}],"/Big-Bird-Transformers-for-Longer-Sequences":[{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"},{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"}],"/Big-Ideas-in-Causality-and-Machine-Learning":[{"source":"/Frontiers-in-Machine-Learning","target":"/Big-Ideas-in-Causality-and-Machine-Learning","text":"Big Ideas in Causality and Machine Learning"}],"/BigBird":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/BigBird","text":"BigBird"}],"/Bilal-Piot":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bilal-Piot","text":"Bilal Piot"}],"/Bilateral-Filtering":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"}],"/Bilinear-Models":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Bilinear-Models","text":"Bilinear Models#Knowledge Graph Embeddings and Explainable AI"}],"/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture","text":"Bilingual Adversarial Text Generator (B-GAN) (Architecture)"}],"/Bill-Dolan":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Bill-Dolan","text":"Bill Dolan"}],"/Binary-Matrix-Operations":[{"source":"/CZ1104-Lecture-7.2","target":"/Binary-Matrix-Operations","text":"Binary Matrix Operations"}],"/Binary-Tree":[{"source":"/Graph-Pooling","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Hierarchical-Softmax","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Binary-Tree","text":"Binary Tree"}],"/Bipartite-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"}],"/Bipartite-Network-Embedding-BiNE":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Network-Embedding-BiNE","text":"Bipartite Network Embedding (BiNE)"}],"/Black-box-attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/RL-S2V","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/ReWatt","target":"/Black-box-attack","text":"Black-box attack"}],"/Blended-Skill-Talk":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"}],"/Bo-An":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bo-An","text":"Bo An"}],"/Bo-Hsiang-Tseng":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Bo-Hsiang-Tseng","text":"Bo-Hsiang Tseng"}],"/Bootstrap-Your-Own-Latent":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"}],"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning":[{"source":"/Bootstrap-Your-Own-Latent","target":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","text":"Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning"}],"/Born-Again-Networks":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Born-Again-Networks","text":"Born-Again Networks"}],"/Breadth-First-Search":[{"source":"/Graph-LSTM","target":"/Breadth-First-Search","text":"Breadth-First Search"}],"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model":[{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"},{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"}],"/British-National-Corpus":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/British-National-Corpus","text":"British National Corpus"}],"/Byeongchang-Kim":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Byeongchang-Kim","text":"Byeongchang Kim"}],"/Byte-Pair-Encoding":[{"source":"/Research-Ideas","target":"/Byte-Pair-Encoding","text":"Byte Pair Encoding"}],"/CART":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/CART","text":"CART"}],"/CE7429-Lecture-10":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-10","text":"CE7429 - Lecture 10"}],"/CE7429-Lecture-11":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-11","text":"CE7429 - Lecture 11"}],"/CE7429-Lecture-12":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-12","text":"CE7429 - Lecture 12"}],"/CE7429-Lecture-13":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-13","text":"CE7429 - Lecture 13"}],"/CE7429-Lecture-2":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-2","text":"CE7429 - Lecture 2"}],"/CE7429-Lecture-3":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-3","text":"CE7429 - Lecture 3"}],"/CE7429-Lecture-4":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-4","text":"CE7429 - Lecture 4"}],"/CE7429-Lecture-5":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-5","text":"CE7429 - Lecture 5"}],"/CE7429-Lecture-6":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-6","text":"CE7429 - Lecture 6"}],"/CE7429-Lecture-7":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-7","text":"CE7429 - Lecture 7"}],"/CE7429-Lecture-8":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-8","text":"CE7429 - Lecture 8"}],"/CE7429-Lecture-9":[{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-9","text":"CE7429 - Lecture 9"}],"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures":[{"source":"/Equivariant-Functions","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Neural-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Positional-Encodings","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Substructure-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Principal-Neighbourhood-Aggregation","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Weisfieler-Lehman-test","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"}],"/CE7491-Lecture-1":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-1","text":"CE7491 Lecture 1"}],"/CE7491-Lecture-2":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-2","text":"CE7491 Lecture 2"}],"/CE7491-Lecture-3":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-3","text":"CE7491 Lecture 3"}],"/CE7491-Lecture-4":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-4","text":"CE7491 Lecture 4"}],"/CE7491-Lecture-5":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-5","text":"CE7491 Lecture 5"}],"/CE7491-Lecture-6":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-6","text":"CE7491 Lecture 6"}],"/CE7491-Lecture-7":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-7","text":"CE7491 Lecture 7"}],"/CE7491-Lecture-8":[{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-8","text":"CE7491 Lecture 8"}],"/CIDEr":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"}],"/Caglar-Gulcehre":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Caglar-Gulcehre","text":"Caglar Gulcehre"}],"/Caiming-Xiong":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Caiming-Xiong","text":"Caiming Xiong"}],"/Canny-Edge-Detector":[{"source":"/CE7491-Lecture-3","target":"/Canny-Edge-Detector","text":"Canny Edge Detector"}],"/Carl-Doersch":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Carl-Doersch","text":"Carl Doersch"}],"/Carlili-Wagner-Loss":[{"source":"/PGD-Topology-Attack","target":"/Carlili-Wagner-Loss","text":"CW loss"}],"/Caroline-Liu":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Caroline-Liu","text":"Caroline Liu"}],"/Casual-Language-Modelling":[{"source":"/Machine-Learning-Conversations","target":"/Casual-Language-Modelling","text":"Casual Language Modelling"}],"/Catastrophic-Forgetting":[{"source":"/CE7429-Lecture-13","target":"/Catastrophic-Forgetting","text":"Catastrophic Forgetting"}],"/Catch-the-Tails-of-BERT":[{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"},{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"}],"/Catherine-Yeo":[{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Catherine-Yeo","text":"Catherine Yeo"}],"/Cauchy-Schwarz-Inequality":[{"source":"/CZ1104-Lecture-6.1","target":"/Cauchy-Schwarz-Inequality","text":"Cauchy-Schwarz Inequality"}],"/Cem-Subakan":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Cem-Subakan","text":"Cem Subakan"}],"/Cerebellar-Model-Articulation-Controller-CMAC":[{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"}],"/Chai-Quek":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Chai-Quek","text":"Chai Quek"}],"/Changhan-Wang":[{"source":"/Paper-Levenshtein-Transformer","target":"/Changhan-Wang","text":"Changhan Wang"}],"/Character-Error-Rate-CER":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Character-Error-Rate-CER","text":"Character Error Rate (CER)"}],"/Characteristic-Equation":[{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"},{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"}],"/Charles-Nash":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Charles-Nash","text":"Charles Nash"}],"/Cheby-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Cheby-Filter","text":"Cheby-Filter"},{"source":"/GCN-Filter","target":"/Cheby-Filter","text":"Cheby-Filter"}],"/Chebyshev-Polynomial":[{"source":"/Cheby-Filter","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Spectral-Graph-Convolutions","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"}],"/Chen-Chen":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Chen-Chen","text":"Chen Chen"}],"/Cheng-Zhang":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"}],"/Chenguang-Wang":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Chenguang-Wang","text":"Chenguang Wang"}],"/Chernoff-Faces":[{"source":"/CE7429-Lecture-5","target":"/Chernoff-Faces","text":"Chernoff Faces"}],"/Chi-kiu-Lo":[{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Chi-kiu-Lo","text":"Chi-kiu Lo"}],"/Ching-Tsan-Chiang":[{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Ching-Tsan-Chiang","text":"Ching-Tsan Chiang"}],"/Chitwan-Saharia":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Chitwan-Saharia","text":"Chitwan Saharia"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Chitwan-Saharia","text":"Chitwan Saharia"}],"/Chris-Alberti":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Chris-Alberti","text":"Chris Alberti"}],"/Chris-Baume":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Chris-Baume","text":"Chris Baume"}],"/Chris-Bishop":[{"source":"/Frontiers-in-Machine-Learning","target":"/Chris-Bishop","text":"Chris Bishop"}],"/Chris-Brockett":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Chris-Brockett","text":"Chris Brockett"}],"/Chris-Dongjoo-Kim":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Chris-Dongjoo-Kim","text":"Chris Dongjoo Kim"}],"/Chris-Dyer":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Chris-Dyer","text":"Chris Dyer"}],"/Christian-Fuegen":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Christian-Fuegen","text":"Christian Fuegen"}],"/Christof-Monz":[{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Christof-Monz","text":"Christof Monz"}],"/Christophe-Marsala":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Christophe-Marsala","text":"Christophe Marsala"}],"/Christopher-Berner":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Berner","text":"Christopher Berner"}],"/Christopher-Hesse":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Hesse","text":"Christopher Hesse"}],"/Chromaticity":[{"source":"/CE7491-Lecture-3","target":"/Chromaticity","text":"Chromaticity"}],"/Chulhee-Yun":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Chulhee-Yun","text":"Chulhee Yun"}],"/Chulun-Zhou":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Chulun-Zhou","text":"Chulun Zhou"}],"/Chun-Shin-Lin":[{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Chun-Shin-Lin","text":"Chun-Shin Lin"}],"/Chunking":[{"source":"/CE7429-Lecture-13","target":"/Chunking","text":"Chunking"}],"/Chunqi-Wang":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Chunqi-Wang","text":"Chunqi Wang"}],"/Chunting-Zhou":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Chunting-Zhou","text":"Chunting Zhou"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Chunting-Zhou","text":"Chunting Zhou"}],"/Ciprian-Chelba":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ciprian-Chelba","text":"Ciprian Chelba"}],"/Citeseer":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Citeseer","text":"Citeseer"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Citeseer","text":"Citeseer"}],"/Classification":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Classification","text":"Classification"}],"/Clemens-Winter":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Clemens-Winter","text":"Clemens Winter"}],"/Cliques":[{"source":"/Graph-Substructure-Networks","target":"/Cliques","text":"Cliques"}],"/Clotho-dataset":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Clotho-dataset","text":"Clotho dataset"}],"/Cloze-Task":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Cloze-Task","text":"Cloze Task"}],"/Clusters":[{"source":"/Graph-Substructure-Networks","target":"/Clusters","text":"Clusters"}],"/CoNLL-2005-WSJ":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2005-WSJ","text":"CoNLL-2005 WSJ"}],"/CoNLL-2012":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2012","text":"CoNLL-2012"}],"/CoQA":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/CoQA","text":"CoQA"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/CoQA","text":"CoQA"}],"/Code-Mixing-Index-CMI":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Code-Mixing-Index-CMI","text":"Code Mixing Index (CMI)"}],"/Color-Indexing":[{"source":"/Week-Summary-210920-011120","target":"/Color-Indexing","text":"Color Indexing"}],"/Community-Structure":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"}],"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control":[{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","text":"Comparison of CMAC Architectures for Neural Network Based Control"}],"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers":[{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","text":"Comparison of Convergence Properties of CMAC Neural Network and Traditional Adaptive Controllers"}],"/Complexity":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Complexity","text":"Complexity"},{"source":"/Graph-Convolutional-Network","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"}],"/Compositional-Rule-of-Inference":[{"source":"/Compositional-Rule-of-Inference","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"}],"/Compositional-rule-of-inference-as-an-analogical-scheme":[{"source":"/Week-Summary-210920-011120","target":"/Compositional-rule-of-inference-as-an-analogical-scheme","text":"Compositional rule of inference as an analogical scheme"}],"/Computational-Intelligence":[{"source":"/CE7429-Lecture-2","target":"/Computational-Intelligence","text":"Computational Intelligence"}],"/Computer-Vision":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Computer-Vision","text":"Computer Vision"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Computer-Vision","text":"Computer Vision"}],"/Concept-Error-Rates":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Concept-Error-Rates","text":"Concept Error Rates"}],"/Condition-Number":[{"source":"/CZ1104-Lecture-8.4","target":"/Condition-Number","text":"Condition Number"}],"/Conditional-Language-Modelling":[{"source":"/Machine-Learning-Conversations","target":"/Conditional-Language-Modelling","text":"Conditional Language Modelling"}],"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"}],"/Conditional-Random-Fields":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conditional-Random-Fields","text":"Conditional Random Fields"}],"/Confusion-Matrix":[{"source":"/CE7429-Lecture-9","target":"/Confusion-Matrix","text":"Confusion Matrix"}],"/Connected-Component":[{"source":"/Connected-Component","target":"/Connected-Component","text":"Connected Component"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Connected-Component","text":"Connected Component"},{"source":"/Laplacian-Matrix","target":"/Connected-Component","text":"Connected Component"}],"/Connected-Graph":[{"source":"/Connected-Component","target":"/Connected-Graph","text":"Connected Graph"},{"source":"/Diameter","target":"/Connected-Graph","text":"Connected Graph"}],"/Connectionist-Temporal-Classification-CTC":[{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"}],"/Consistency-in-a-System-of-Equations":[{"source":"/CZ1104-Lecture-7.1","target":"/Consistency-in-a-System-of-Equations","text":"Consistency in a System of Equations"}],"/Constant-Q-transform":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Constant-Q-transform","text":"Constant-Q-transform"}],"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation":[{"source":"/Week-Summary-231120-291120","target":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","text":"Context-Aware Cross-Attention for Non-Autoregressive Translation"}],"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State":[{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"},{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"}],"/Contrast-Stretching":[{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"},{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"}],"/Contrastive-Loss":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Contrastive-Loss","text":"Contrastive Loss"}],"/Contribution-in-Information-Flow":[{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Contribution-in-Information-Flow","text":"Contribution in Information Flow"}],"/Conversational-Dialogue-Systems":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Research-Ideas","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"}],"/Conversational-Intelligence-Challenge-2":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"}],"/Convolution":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Convolution","text":"Convolution"},{"source":"/Mo-Filter","target":"/Convolution","text":"Convolution"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolution","text":"Convolution"}],"/Convolution-Neural-Network":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Convolution-Neural-Network","text":"Convolutional Layers"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"}],"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering":[{"source":"/Graph-Pooling","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"}],"/Convolutional-Recurrent-Neural-Network":[{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Convolutional-Recurrent-Neural-Network","text":"CRNN"}],"/Cora":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Cora","text":"Cora"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Cora","text":"Cora"}],"/Coreference":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Coreference","text":"Coreference"},{"source":"/Inter-sentential-Relations","target":"/Coreference","text":"Coreference"}],"/Corentin-Tallec":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Corentin-Tallec","text":"Corentin Tallec"}],"/Cornell-Movie":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Cornell-Movie","text":"Cornell Movie"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Cornell-Movie","text":"Cornell Movie"}],"/Counterfactual":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactual","text":"Counterfactual"}],"/Counterfactuals-Critical-MultiAgent-Learning-CMAL":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactuals-Critical-MultiAgent-Learning-CMAL","text":"Counterfactuals-Critical MultiAgent Learning (CMAL)"}],"/Covid19":[{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"}],"/Covid19-politifact":[{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"}],"/Covid19-scientific":[{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"}],"/Criticality-in-Representation-Generalization":[{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Criticality-in-Representation-Generalization","text":"Criticality in Representation Generalization"}],"/Cross-Domain-Loss":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Cross-Domain-Loss","text":"Cross-Domain Loss"}],"/Crowding-Problem":[{"source":"/Visualizing-Data-using-t-SNE","target":"/Crowding-Problem","text":"Crowding Problem"}],"/Curriculum-Learning":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"}],"/Curse-of-Dimensionality":[{"source":"/CE7429-Lecture-9","target":"/Curse-of-Dimensionality","text":"Curse of Dimensionality"}],"/Cycles":[{"source":"/Graph-Substructure-Networks","target":"/Cycles","text":"Cycles"}],"/DROP":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/DROP","text":"DROP"}],"/Da-Ju":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Da-Ju","text":"Da Ju"}],"/Daan-Wierstra":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Daan-Wierstra","text":"Daan Wierstra"}],"/Dacheng-Tao":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Dacheng-Tao","text":"Dacheng Tao"}],"/Dading-Chong":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Dading-Chong","text":"Dading Chong"}],"/Daiki-Takeuchi":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"}],"/DailyDialog":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"}],"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset":[{"source":"/Week-Summary-060720-190720","target":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","text":"DailyDialog - A Manually Labelled Multi-turn Dialogue Dataset"}],"/Daisuke-Niizumi":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daisuke-Niizumi","text":"Daisuke Niizumi"}],"/Dan-Klein":[{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"}],"/Dan-Su":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Dan-Su","text":"Dan Su"}],"/Daniel-Adiwardana":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Daniel-Adiwardana","text":"Daniel Adiwardana"}],"/Daniel-P-W-Ellis":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Daniel-P-W-Ellis","text":"Daniel P W Ellis"}],"/Dario-Amodei":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Dario-Amodei","text":"Dario Amodei"}],"/Dat-Ngo":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dat-Ngo","text":"Dat Ngo"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Dat-Ngo","text":"Dat Ngo"}],"/David-Harwath":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/David-Harwath","text":"David Harwath"}],"/David-Liang":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/David-Liang","text":"David Liang"}],"/David-Lopez-Paz":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/David-Lopez-Paz","text":"David Lopez-Paz"}],"/David-Luan":[{"source":"/Generative-Pretraining-from-Pixels","target":"/David-Luan","text":"David Luan"}],"/David-Raposo":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/David-Raposo","text":"David Raposo"}],"/Dawn-Song":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"}],"/Dayiheng-Liu":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Dayiheng-Liu","text":"Dayiheng Liu"}],"/De-Morgans-Law":[{"source":"/Fuzzy-Sets-1965","target":"/De-Morgans-Law","text":"De Morgan's Law"}],"/December-12th-2020":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/December-12th-2020","text":"December 12th 2020"}],"/December-13th-2020":[{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"},{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"}],"/December-14th-2020":[{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/December-14th-2020","text":"December 14th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-14th-2020","text":"December 14th 2020"}],"/December-15th-2020":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/December-15th-2020","text":"December 15th 2020"}],"/December-16th-2020":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/December-16th-2020","text":"December 16th 2020"}],"/December-1st-2020":[{"source":"/Deep-Learning-on-Graphs-book","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/December-1st-2020","text":"December 1st, 2020"}],"/December-20th-2020":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/December-20th-2020","text":"December 20th 2020"}],"/December-21st-2020":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/December-21st-2020","text":"December 21st 2020"}],"/December-22nd-2020":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/December-22nd-2020","text":"December 22nd 2020"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/December-22nd-2020","text":"December 22nd 2020"}],"/December-23rd-2020":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/December-23rd-2020","text":"December 23rd 2020"}],"/December-27th-2020":[{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"}],"/December-28th-2020":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/December-28th-2020","text":"December 28th 2020"}],"/December-2nd-2020":[{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/December-2nd-2020","text":"December 2nd 2020"}],"/December-3rd-2020":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/December-3rd-2020","text":"December 3rd 2020"}],"/December-6th-2020":[{"source":"/Week-Summary-301120-061220","target":"/December-6th-2020","text":"December 6th 2020"}],"/December-7th-2020":[{"source":"/Week-Summary-071220-131220","target":"/December-7th-2020","text":"December 7th 2020"},{"source":"/Week-Summary-301120-061220","target":"/December-7th-2020","text":"December 7th 2020"}],"/Decision-Trees":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Decision-Trees","text":"Decision Trees"}],"/Deconvolution-Transposed-Convolution":[{"source":"/CE7491-Lecture-6","target":"/Deconvolution-Transposed-Convolution","text":"Deconvolution (Transposed Convolution)"}],"/Deep-Causal-Manipulation-Augmented-Model":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Deep-Causal-Manipulation-Augmented-Model","text":"Deep Causal Manipulation Augmented Model"}],"/Deep-Fakes":[{"source":"/CE7491-Lecture-8","target":"/Deep-Fakes","text":"Deep Fakes"}],"/Deep-Learning-On-Graphs-Chapter-1-Introduction":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","text":"Deep Learning On Graphs Chapter 1 - Introduction"}],"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Entity-GCN","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Relation-Extraction","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Semantic-Role-Labeling","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/WIKIHOP-dataset","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"}],"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","text":"Deep Learning On Graphs Chapter 2 - Foundations of Graphs"}],"/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning","text":"Deep Learning On Graphs Chapter 3 - Foundations of Deep Learning"}],"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","text":"Deep Learning On Graphs Chapter 4 - Graph Embedding"}],"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 5 - Graph Neural Networks"}],"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"},{"source":"/Graph-Attention","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"}],"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 7 - Scalable Graph Neural Networks"}],"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","text":"Deep Learning On Graphs Chapter 8 - Graph Neural Networks on Complex Graphs"}],"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-Auto-Encoders","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Tree-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"}],"/Deep-Learning-on-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Deep-Learning-on-Graphs","text":"Deep Learning on Graphs"}],"/DeepWalk":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Negative-Sampling","target":"/DeepWalk","text":"DeepWalk"},{"source":"/node2vec","target":"/DeepWalk","text":"DeepWalk"}],"/Defining-and-Evaluating-Fair-Natural-Language-Generation":[{"source":"/Week-Summary-030820-160820","target":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","text":"Defining and Evaluating Fair Natural Language Generation"}],"/Degree":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree","text":"Degree"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree","text":"Degree"},{"source":"/Laplacian-Matrix","target":"/Degree","text":"Degree"},{"source":"/Mo-Filter","target":"/Degree","text":"Degree"},{"source":"/Random-Walk","target":"/Degree","text":"Degree"},{"source":"/Simple-Graph","target":"/Degree","text":"Degree"}],"/Degree-Centrality":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree-Centrality","text":"Degree Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree-Centrality","text":"Degree Centrality"}],"/Denoising":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Denoising","text":"Denoising"}],"/Dependency":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Dependency","text":"Dependency"},{"source":"/Intra-sentential-Relations","target":"/Dependency","text":"Dependency"}],"/Dependency-Parsing":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Dependency-Parsing","text":"Dependency Parsing"}],"/Depth-First-Search":[{"source":"/Graph-LSTM","target":"/Depth-First-Search","text":"Depth-First Search"}],"/Depth-of-Field":[{"source":"/CE7491-Lecture-1","target":"/Depth-of-Field","text":"Depth of Field"}],"/Determinant":[{"source":"/CZ1104-Lecture-7.2","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Determinant","text":"Determinant"}],"/Detlef-Nauck":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Detlef-Nauck","text":"Detlef Nauck"}],"/Devendra-Singh-Sachan":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Devendra-Singh-Sachan","text":"Devendra Singh Sachan"}],"/Di-Wu":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Di-Wu","text":"Di Wu"}],"/Diagonalisable":[{"source":"/CZ1104-Lecture-8.1","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"}],"/DialoGPT":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Research-Ideas","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/DialoGPT","text":"DialoGPT"}],"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation":[{"source":"/Week-Summary-060720-190720","target":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","text":"DialoGPT - Large-Scale Generative Pre-training for Conversational Response Generation"}],"/Dialog-State-Tracking-Challenge":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialog-State-Tracking-Challenge","text":"Dialog State Tracking Challenge"}],"/DialogGPT":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/DialogGPT","text":"DialogGPT"}],"/Dialogue-Act":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Act","text":"Dialogue Act"}],"/Dialogue-Efficiency":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialogue-Efficiency","text":"Dialogue Efficiency"}],"/Dialogue-Modelling":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Modelling","text":"Dialogue Modelling"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Dialogue-Modelling","text":"Dialogue Modelling"}],"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features":[{"source":"/Week-Summary-010620-210620","target":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","text":"Dialogue breakdown detection using BERT with traditional dialogue features"}],"/DialogueNLI":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DialogueNLI","text":"DialogueNLI"}],"/Diameter":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Diameter","text":"Diameter"}],"/Dilek-Hakkani-T%C3%BCr":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Dilek-Hakkani-T%C3%BCr","text":"Dilek Hakkani-Tür"}],"/DimeNet":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/DimeNet","text":"DimeNet"}],"/Discovering-and-Categorizing-Language-Biases-in-Reddit":[{"source":"/Week-Summary-030820-160820","target":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","text":"Discovering and Categorizing Language Biases in Reddit"}],"/Discrete-Dynamic-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Discrete-Dynamic-Graphs","text":"Discrete Dynamic Graphs"}],"/Discriminant-Component-Analysis":[{"source":"/CE7429-Lecture-6","target":"/Discriminant-Component-Analysis","text":"Discriminant Component Analysis"}],"/DistilBERT":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/DistilBERT","text":"DistilBERT"}],"/Distributive-Law":[{"source":"/Fuzzy-Sets-1965","target":"/Distributive-Law","text":"Distributive Law"}],"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information":[{"source":"/Syntax-GNN","target":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","text":"Do Syntax Trees Help Pre-trained Transformers Extract Information"}],"/Do-Transformers-Need-Deep-Long-Range-Memory":[{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"},{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"}],"/Document-Graph-for-Neural-Machine-Translation":[{"source":"/Adjacency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Coreference","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Dependency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Inter-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Intra-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Lexical-Consistency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Week-Summary-071220-131220","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"}],"/Dorin-Comaniciu":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Dorin-Comaniciu","text":"Dorin Comaniciu"}],"/Dot-Product":[{"source":"/CZ1104-Lecture-6.1","target":"/Dot-Product","text":"Dot Product"}],"/Douwe-Kiela":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Douwe-Kiela","text":"Douwe Kiela"}],"/Downsampling-based-Pooling":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"},{"source":"/gPool","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"}],"/Dragan-Gasevic":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Dragan-Gasevic","text":"Dragan Gasevic"}],"/Drastic-T-norm":[{"source":"/T-norm","target":"/Drastic-T-norm","text":"Drastic T-norm"}],"/Dropout":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dropout","text":"Dropout"}],"/Duet":[{"source":"/Security-and-Machine-Learning","target":"/Duet","text":"Duet"}],"/Dynamic-Bayesian-Network":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dynamic-Bayesian-Network","text":"Dynamic Bayesian Network"}],"/Dynamic-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Discrete-Dynamic-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"}],"/Dynamic-Heterogeneous-Network-Embedding-DHNE":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Heterogeneous-Network-Embedding-DHNE","text":"Dynamic Heterogeneous Network Embedding (DHNE)"}],"/Dynamic-Programming":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"}],"/Dynamic-Time-Warping-DTW":[{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Dynamic-Time-Warping-DTW","text":"Dynamic Time Warping (DTW)"}],"/ECC-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/ECC-Filter","text":"ECC-Filter"}],"/ELMo":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"}],"/ELU":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"}],"/EMB":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/EMB","text":"EMB"}],"/ESC-10":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-10","text":"ESC-10"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-10","text":"ESC-10"}],"/ESC-50":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-50","text":"ESC-50"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-50","text":"ESC-50"}],"/ESIM":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"}],"/Ece-Kamar":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"}],"/Edge-Flow-Propagation":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"}],"/Edge-based-Sampler":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Edge-based-Sampler","text":"Edge-based Sampler"}],"/Edmun-M-K-Lai":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"}],"/Eduard-Hovy":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Eduard-Hovy","text":"Eduard Hovy"}],"/Eduardo-Fonseca":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Eduardo-Fonseca","text":"Eduardo Fonseca"}],"/Effective-Receptive-Field":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"}],"/Efficient-Inference-For-Neural-Machine-Translation":[{"source":"/Week-Summary-301120-061220","target":"/Efficient-Inference-For-Neural-Machine-Translation","text":"Efficient Inference For Neural Machine Translation"}],"/EfficientNet":[{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"}],"/Eigen-Space":[{"source":"/CZ1104-Lecture-8.1","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"}],"/EigenPooling":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/EigenPooling","text":"EigenPooling"}],"/Eigendecomposition":[{"source":"/CZ1104-Lecture-8.1","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigendecomposition","text":"Eigendecomposition"}],"/Eigenvalue":[{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvalue","text":"Eigenvalue"}],"/Eigenvector":[{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Graph-Positional-Encodings","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvector","text":"Eigenvector"}],"/Eigenvector-Centrality":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"}],"/Elena-Buchatskaya":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Elena-Buchatskaya","text":"Elena Buchatskaya"}],"/Elias-Bareinboim":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"}],"/Elio-Quinton":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Elio-Quinton","text":"Elio Quinton"}],"/Elmo":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Elmo","text":"Elmo"}],"/Embeddings":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Embeddings","text":"Embeddings"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"}],"/Emily-Dinan":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Emily-Dinan","text":"Emily Dinan"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Emily-Dinan","text":"Emily Dinan"}],"/Emmanouil-Benetos":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Emmanouil-Benetos","text":"Emmanouil Benetos"}],"/Emmett-Witchel":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"}],"/Empathetic-Dialogues":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"}],"/Empirical-Risk-Minimization":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"Empirical Risk Minimization"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"EMR"}],"/Emre-Cakir":[{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Emre-Cakir","text":"Emre Cakir"}],"/Emre-Kiciman":[{"source":"/Security-and-Machine-Learning","target":"/Emre-Kiciman","text":"Emre Kiciman"}],"/Eneko-Agirre":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Eneko-Agirre","text":"Eneko Agirre"}],"/Energy":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"}],"/Enhong-Chen":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Enhong-Chen","text":"Enhong Chen"}],"/Enron":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Enron","text":"Enron"}],"/Entity-GCN":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Entity-GCN","text":"Entity-GCN"}],"/Entity-Graph":[{"source":"/Entity-GCN","target":"/Entity-Graph","text":"Entity Graph"}],"/Entity-Grid":[{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Entity-Grid","text":"Entity Grid"}],"/Entropy":[{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"},{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"}],"/Equivariant":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Equivariant","text":"Equivariance"}],"/Erd%C5%91s-R%C3%A9nyi-model":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Erd%C5%91s-R%C3%A9nyi-model","text":"Erdős-Rényi model"}],"/Erfan-Loweimi":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Erfan-Loweimi","text":"Erfan Loweimi"}],"/Eric-Jang":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Eric-Jang","text":"Eric Jang"}],"/Eric-Michael-Smith":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"}],"/Eric-Sigler":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Eric-Sigler","text":"Eric Sigler"}],"/Euclidean-Distance":[{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/TransE","target":"/Euclidean-Distance","text":"Euclidean Distance"}],"/Europarl":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Europarl","text":"Europarl"}],"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems":[{"source":"/Week-Summary-010620-210620","target":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","text":"Evaluating dialogue breakdown detection in chat-oriented dialogue systems"}],"/Evaluation-Metric":[{"source":"/Research-Ideas","target":"/Evaluation-Metric","text":"Evaluation Metric"}],"/Evasion-Attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Evasion-Attack","text":"Evasion Attack"}],"/EvolveGCN":[{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/EvolveGCN","text":"EvolveGCN"}],"/Expectation-Mean":[{"source":"/CE7429-Lecture-7","target":"/Expectation-Mean","text":"Expectation (Mean)"}],"/Explainability":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Explainability","text":"Explainability"}],"/Exploratory-Data-Analysis":[{"source":"/CE7429-Lecture-3","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"},{"source":"/CE7429-Lecture-5","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"}],"/Extractor":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/DeepWalk","target":"/Extractor","text":"Extractor"}],"/F-scores":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/F-scores","text":"F-scores"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/F-scores","text":"F-scores"}],"/F1-score":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/F1-score","text":"F1 score"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/F1-score","text":"F1 score"}],"/FED-dataset":[{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"}],"/FED-metric":[{"source":"/Research-Ideas","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"}],"/FEVER":[{"source":"/Misinformation-has-High-Perplexity","target":"/FEVER","text":"FEVER"}],"/FLAMBE":[{"source":"/Machine-Learning-Conversations","target":"/FLAMBE","text":"FLAMBE"}],"/FNet":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/FNet","text":"FNet"}],"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION":[{"source":"/Week-Summary-231120-291120","target":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","text":"FROM UNSUPERVISED MACHINE TRANSLATION TO ADVERSARIAL TEXT GENERATION"}],"/Face-Recognition-Using-Eigenfaces":[{"source":"/Week-Summary-210920-011120","target":"/Face-Recognition-Using-Eigenfaces","text":"Face Recognition Using Eigenfaces"}],"/Facial-Recognition":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Facial-Recognition","text":"Facial Recognition"}],"/Fairseq":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Fairseq","text":"Fairseq"}],"/Faithfulness":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"}],"/Fandong-Meng":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Fandong-Meng","text":"Fandong Meng"}],"/Fast-Gradient-Sign-Method":[{"source":"/Integrated-Gradient-Guided-Attack","target":"/Fast-Gradient-Sign-Method","text":"Fast Gradient Sign Method"}],"/FastText":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/FastText","text":"FastText"},{"source":"/TRACKE","target":"/FastText","text":"FastText"}],"/Faster-R-CNN":[{"source":"/CE7491-Lecture-6","target":"/Faster-R-CNN","text":"Faster R-CNN"}],"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention":[{"source":"/Week-Summary-250520-310520","target":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","text":"Faster Transformer Decoding - N-gram Masked Self-Attention"}],"/February-10th-2021":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/February-10th-2021","text":"February 10th 2021"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/February-10th-2021","text":"February 10th 2021"}],"/February-14th-2021":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/February-14th-2021","text":"February 14th 2021"}],"/February-9th-2021":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/February-9th-2021","text":"February 9th 2021"}],"/Federico-Bianchi":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Federico-Bianchi","text":"Federico Bianchi"}],"/Feed-forward":[{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Feed-forward","text":"Feed-forward"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Feed-forward","text":"Feed-forward"},{"source":"/GRaph-Aware-Transformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Auto-Encoders","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Isomorphism-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Transformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Mo-Filter","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/WaveTransformer","target":"/Feed-forward","text":"Feed-forward"}],"/Field-of-View":[{"source":"/CE7491-Lecture-1","target":"/Field-of-View","text":"Field of View"}],"/Filter-Damping":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"}],"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Week-Summary-180520-240520","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"}],"/Fishers-Discriminant-Analysis":[{"source":"/CE7429-Lecture-6","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"}],"/Flat-Graph-Pooling":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Flat-Graph-Pooling","text":"Flat Graph Pooling"}],"/Florent-Altche":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florent-Altche","text":"Florent Altche"}],"/Florian-Strub":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florian-Strub","text":"Florian Strub"}],"/FlowSeq":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/FlowSeq","text":"FlowSeq"}],"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow":[{"source":"/Week-Summary-240820-300820","target":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","text":"FlowSeq - Non-Autoregressive Conditional Sequence Generation with Generative Flow"}],"/Fluency-ENhanced-Sentence-bert-Evaluation":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Fluency-ENhanced-Sentence-bert-Evaluation","text":"FENSE"}],"/Four-Fundamental-Subspaces":[{"source":"/CZ1104-Lecture-8.4","target":"/Four-Fundamental-Subspaces","text":"Four Fundamental Subspaces"}],"/Fourier-Transform":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/Graph-Fourier-Transform","target":"/Fourier-Transform","text":"Fourier Transform"}],"/Francis-Song":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Francis-Song","text":"Francis Song"}],"/Francisco-Herrera":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Francisco-Herrera","text":"Francisco Herrera"}],"/Fudong-Nian":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Fudong-Nian","text":"Fudong Nian"}],"/Fully-Connected-Graph":[{"source":"/Graph-Neural-Networks","target":"/Fully-Connected-Graph","text":"Fully Connected Graph"}],"/Fuzzy-Deductive-Reasoning":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Fuzzy-Deductive-Reasoning","text":"Fuzzy Deductive Reasoning"}],"/Fuzzy-Logic":[{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Logic","text":"Fuzzy Logic"}],"/Fuzzy-Logic-Controllers":[{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"}],"/Fuzzy-Perceptron":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Fuzzy-Perceptron","text":"Fuzzy Perceptron"}],"/Fuzzy-Rule-Based-Classification-System":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Fuzzy-Rule-Based-Classification-System","text":"Fuzzy Rule-Based Classification System"}],"/Fuzzy-Set":[{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Set","text":"Fuzzy Set"}],"/Fuzzy-Sets-1965":[{"source":"/Week-Summary-210920-011120","target":"/Fuzzy-Sets-1965","text":"Fuzzy Sets (1965)"}],"/G%C3%A1bor-Horv%C3%A1th":[{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/G%C3%A1bor-Horv%C3%A1th","text":"Gábor Horváth"}],"/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid":[{"source":"/Reading-List","target":"/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid","text":"Gödel, Escher, Bach - an Eternal Golden Braid"}],"/G%C3%B6del-T-norm":[{"source":"/T-norm","target":"/G%C3%B6del-T-norm","text":"Gödel T-norm"}],"/GAN-Inversion":[{"source":"/CE7491-Lecture-7","target":"/GAN-Inversion","text":"GAN-Inversion"}],"/GAT-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GAT-Filter","text":"GAT-Filter"}],"/GCN-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Graph-Auto-Encoders","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Nettack","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/RGCN-Filter","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/diffpool","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/gPool","target":"/GCN-Filter","text":"GCN-Filter"}],"/GELU":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"}],"/GGNN-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GGNN-Filter","text":"GGNN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GGNN-Filter","text":"GGNN-Filter"}],"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Week-Summary-240820-300820","target":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","text":"GLAT - Glancing Transformer for Non-Autoregressive Neural Machine Translation"}],"/GLUE-Benchmark":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/Winograd-NLI","target":"/GLUE-Benchmark","text":"GLUE Benchmark"}],"/GPT-2":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/GPT-2","text":"GPT-2"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-2","text":"GPT-2"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/GPT-2","text":"GPT-2"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/GPT-2","text":"GPT-2"},{"source":"/Generative-Pretraining-from-Pixels","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Machine-Learning-Conversations","target":"/GPT-2","text":"GPT-2"},{"source":"/Misinformation-has-High-Perplexity","target":"/GPT-2","text":"GPT-2"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/GPT-2","text":"GPT-2"}],"/GPT-3":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GPT-3","text":"GPT-3"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"}],"/GRAPH-ATTENTION-NETWORKS-Paper":[{"source":"/Graph-Attention","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"},{"source":"/Week-Summary-141220-271220","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"}],"/GRaph-Aware-Transformer":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRaph-Aware Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRAT"}],"/Gaetano-Rossiello":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Gaetano-Rossiello","text":"Gaetano Rossiello"}],"/Gammatone":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Gammatone","text":"Gammatone"}],"/Gang-Liu":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Gang-Liu","text":"Gang Liu"}],"/Gated-Recurrent-Unit":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/GGNN-Filter","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"}],"/Gaurav-Nemade":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Gaurav-Nemade","text":"Gaurav Nemade"}],"/Gaussian-Kernel":[{"source":"/Mo-Filter","target":"/Gaussian-Kernel","text":"Gaussian Kernel"}],"/Generalized-CMAC-GCMAC":[{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"}],"/Generalized-Modus-Ponens":[{"source":"/Compositional-Rule-of-Inference","target":"/Generalized-Modus-Ponens","text":"Generalized [[Modus Ponens"}],"/Generalizing-CMAC-Architecture-and-Training":[{"source":"/Week-Summary-021120-221120","target":"/Generalizing-CMAC-Architecture-and-Training","text":"Generalizing CMAC Architecture and Training"}],"/Generative-Adversarial-Network":[{"source":"/CE7491-Lecture-6","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-7","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-8","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Generative-Adversarial-Network","text":"GAN"}],"/Generative-Flow":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"}],"/Generative-Pretraining-from-Pixels":[{"source":"/Week-Summary-210920-011120","target":"/Generative-Pretraining-from-Pixels","text":"Generative Pretraining from Pixels"}],"/Geoffrey-Hinton":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"}],"/Geometric-Multiplicity":[{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"}],"/George-Dahl":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/George-Dahl","text":"George Dahl"}],"/Gerard-Goggin":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"}],"/Gerhard-Widmer":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Gerhard-Widmer","text":"Gerhard Widmer"}],"/German-CoNLL-2009-Treebank":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/German-CoNLL-2009-Treebank","text":"German CoNLL 2009 Treebank"}],"/Girish-Sastry":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Girish-Sastry","text":"Girish Sastry"}],"/Giuseppe-Riccardi":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Giuseppe-Riccardi","text":"Giuseppe Riccardi"}],"/Glancing-Transformer-GLAT":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"}],"/GloVe":[{"source":"/GloVe-Twitter-200d","target":"/GloVe","text":"GloVe"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GloVe","text":"GloVe"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/GloVe","text":"GloVe"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/GloVe","text":"GloVe"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/GloVe","text":"GloVe"}],"/GloVe-Twitter-200d":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/GloVe-Twitter-200d","text":"GloVe Twitter 200d"}],"/Gokhan-Tur":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Gokhan-Tur","text":"Gokhan Tur"}],"/Graclus":[{"source":"/Graph-Pooling","target":"/Graclus","text":"Graclus"}],"/Graham-Neubig":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Graham-Neubig","text":"Graham Neubig"}],"/Gram-Schmidt":[{"source":"/CZ1104-Lecture-6.3","target":"/Gram-Schmidt","text":"Gram Schmidt"}],"/Gram-matrix":[{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Gram-matrix","text":"Gram-matrix"}],"/Graph-Adversarial-Defense":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Adversarial-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Attention","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Purification","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Structure-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"}],"/Graph-Adversarial-Learning":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"},{"source":"/GraphAT","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"}],"/Graph-Attention":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Attention","text":"Graph Attention"},{"source":"/Syntax-GNN","target":"/Graph-Attention","text":"Graph Attention"}],"/Graph-Attention-Network":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"}],"/Graph-Auto-Encoders":[{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Auto-Encoders","text":"Graph Auto-Encoders"}],"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need":[{"source":"/GRaph-Aware-Transformer","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"}],"/Graph-Classification":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Classification","text":"Graph Classification"}],"/Graph-Convolutional-Network":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"layers"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^41aec7"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^e0c9b8"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Convolutional-Network","text":"GCN"}],"/Graph-Embbedding":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"}],"/Graph-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"}],"/Graph-Fourier-Transform":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/EigenPooling","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Spectral-Graph-Convolutions","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"}],"/Graph-Isomorphism":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism","text":"Graph Isomorphism"},{"source":"/Graph-Isomorphism-Networks","target":"/Graph-Isomorphism","text":"Graph Isomorphism"}],"/Graph-Isomorphism-Networks":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism-Networks","text":"GINs"}],"/Graph-LSTM":[{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-LSTM","text":"Graph-LSTM"}],"/Graph-Low-Rank-Global-Attention":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Low-Rank-Global-Attention","text":"Graph Low-Rank Global Attention"}],"/Graph-Neural-Networks":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/DeepWalk","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Equivariant-Functions","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Graph-Substructure-Networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Neighborhood-Explosion","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks#Impossibility Results and Bottlenecks"},{"source":"/Research-Ideas","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Weisfieler-Lehman-test","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"}],"/Graph-Pooling":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"}],"/Graph-Property-Prediction":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Graph-Property-Prediction","text":"Graph Property Prediction"}],"/Graph-Purification":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Purification","text":"Graph Purification"}],"/Graph-Reordering":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Graph-Reordering","text":"Graph Reordering"}],"/Graph-Signal":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"}],"/Graph-Structure-Learning":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"},{"source":"/Graphite","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"}],"/Graph-Substructure-Networks":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Substructure-Networks","text":"Graph Substructure Networks"}],"/Graph-Transformer":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Graph-Transformer","text":"Graph-Transformer"}],"/Graph-to-Sequence":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"}],"/Graph-to-Sequence-Neural-Machine-Translation":[{"source":"/Graph-Transformer","target":"/Graph-to-Sequence-Neural-Machine-Translation","text":"Graph-to-Sequence Neural Machine Translation"}],"/GraphAT":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/GraphAT","text":"GraphAT"}],"/GraphSAGE-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"}],"/Graphite":[{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-AE","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-VAE","target":"/Graphite","text":"Graphite"}],"/Graphite-AE":[{"source":"/Graphite","target":"/Graphite-AE","text":"Graphite-AE"}],"/Graphite-Iterative-Generative-Modeling-of-Graphs":[{"source":"/Graphite","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"},{"source":"/Week-Summary-141220-271220","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"}],"/Graphite-VAE":[{"source":"/Graphite","target":"/Graphite-VAE","text":"Graphite-VAE"}],"/Grassmanns-Law":[{"source":"/CE7491-Lecture-3","target":"/Grassmanns-Law","text":"Grassmann's Law"}],"/Gray-Level-Indexing":[{"source":"/CE7491-Lecture-1","target":"/Gray-Level-Indexing","text":"Gray-Level Indexing"}],"/Gray-box-attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Metattack","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Nettack","target":"/Gray-box-attack","text":"Gray-box attack"}],"/Gretchen-Krueger":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Gretchen-Krueger","text":"Gretchen Krueger"}],"/Guangsen-Wang":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Guangsen-Wang","text":"Guangsen Wang"}],"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information":[{"source":"/Week-Summary-180520-240520","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"},{"source":"/Week-Summary-240820-300820","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"}],"/Guillem-Cucurull":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Guillem-Cucurull","text":"Guillem Cucurull"}],"/Guillermo-Echegoyen":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Guillermo-Echegoyen","text":"Guillermo Echegoyen"}],"/Gumbel-Distribution":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Distribution","text":"Gumbel Distribution"}],"/Gumbel-Max-trick":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Max-trick","text":"Gumbel-Max trick"}],"/Gumbel-Softmax":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"}],"/Gunhee-Kim":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Gunhee-Kim","text":"Gunhee Kim"}],"/Guru-Guruganesh":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Guru-Guruganesh","text":"Guru Guruganesh"}],"/Gurunath-Reddy-Madhumani":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Gurunath-Reddy-Madhumani","text":"Gurunath Reddy Madhumani"}],"/Gyorgy-Fazekas":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Gyorgy-Fazekas","text":"Gyorgy Fazekas"}],"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES":[{"source":"/Week-Summary-210920-011120","target":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","text":"HEDGE ALGEBRAS - AN ALGEBRAIC APPROACH TO STRUCTURE OF SETS OF LINGUISTIC TRUTH VALUES"}],"/Hai-Zhao":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Hai-Zhao","text":"Hai Zhao"}],"/Haiqing-Chen":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Haiqing-Chen","text":"Haiqing Chen"}],"/Hal-Daum%C3%A9-III":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hal-Daum%C3%A9-III","text":"Hal Daumé III"}],"/Hamacher-Product":[{"source":"/T-norm","target":"/Hamacher-Product","text":"Hamacher Product"}],"/Hamid-Eghbal-zadeh":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Hamid-Eghbal-zadeh","text":"Hamid Eghbal-zadeh"}],"/Hamming-Distance":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hamming-Distance","text":"Hamming Distance"}],"/Hanna-Wallach":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hanna-Wallach","text":"Hanna Wallach"}],"/Hannah-Rashkin":[{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Hannah-Rashkin","text":"Hannah Rashkin"}],"/Hanqing-Lu":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Hanqing-Lu","text":"Hanqing Lu"}],"/Hao-Hoang":[{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Hao-Hoang","text":"Hao Hoang"}],"/Hao-Zhou":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hao-Zhou","text":"Hao Zhou"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Hao-Zhou","text":"Hao Zhou"}],"/Hard-Concrete-Distribution":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Hard-Concrete-Distribution","text":"Hard Concrete Distribution"}],"/Harmonic-Percussive-Source-Separation":[{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"Harmonic Percussive Source Separation"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"HPSS"}],"/Harris-Chan":[{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Harris-Chan","text":"Harris Chan"}],"/Heewoo-Jun":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Heewoo-Jun","text":"Heewoo Jun"}],"/Heinrich-Dinkel":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"}],"/Helen-Meng":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Helen-Meng","text":"Helen Meng"}],"/Helin-Wang":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Helin-Wang","text":"Helin Wang"}],"/Hengshuang-Zhao":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Hengshuang-Zhao","text":"Hengshuang Zhao"}],"/Henry-Zhou":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Henry-Zhou","text":"Henry Zhou"}],"/Heterogeneous-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"}],"/Heterogeneous-Network-Embedding-HNE":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Network-Embedding-HNE","text":"Heterogeneous Network Embedding (HNE)"}],"/Hidden-Markov-Models":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Hidden-Markov-Models","text":"Hidden Markov Models"}],"/Hierarchical-Clustering":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchical-Clustering","text":"Hierarchical Clustering"}],"/Hierarchical-Graph-Pooling":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Hierarchical-Graph-Pooling","text":"Hierarchical Graph Pooling"}],"/Hierarchical-Softmax":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"},{"source":"/DeepWalk","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"}],"/Hierarchical-Structural-Similarity-Measure":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Structural-Similarity-Measure","text":"Hierarchical Structural Similarity Measure"}],"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"}],"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence":[{"source":"/Week-Summary-021120-221120","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","text":"Hierarchically Clustered Adaptive Quantization CMAC and Its Learning Convergence"}],"/Hierarchy-Aware-Knowledge-Graph-Embedding":[{"source":"/Translational-Models","target":"/Hierarchy-Aware-Knowledge-Graph-Embedding","text":"Hierarchy-Aware Knowledge Graph Embedding"}],"/High-Boost-Filtering":[{"source":"/CE7491-Lecture-2","target":"/High-Boost-Filtering","text":"High Boost Filtering"}],"/Hinrich-Sch%C3%BCtze":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Hinrich-Sch%C3%BCtze","text":"Hinrich Schütze"}],"/Hiroaki-Sugiyama":[{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/Hiroaki-Sugiyama","text":"Hiroaki Sugiyama"}],"/Histogram-Backprojection":[{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"},{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"}],"/Histogram-Equalization":[{"source":"/CE7491-Lecture-2","target":"/Histogram-Equalization","text":"Histogram Equalization"}],"/Histogram-Intersection":[{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"},{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"}],"/Ho-Hsiang-Wu":[{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Ho-Hsiang-Wu","text":"Ho-Hsiang Wu"}],"/Homer":[{"source":"/Machine-Learning-Conversations","target":"/Homer","text":"Homer"}],"/Homogeneous":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Homogeneous","text":"Homogeneous"}],"/Hongyi-Zhang":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Hongyi-Zhang","text":"Hongyi Zhang"}],"/Hoshik-Lee":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Hoshik-Lee","text":"Hoshik Lee"}],"/Hough-Transform":[{"source":"/CE7491-Lecture-3","target":"/Hough-Transform","text":"Hough Transform"}],"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings":[{"source":"/Isotropy","target":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","text":"How Contextual are Contextualized Word Representations - Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"}],"/Huang-Xie":[{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Huang-Xie","text":"Huang Xie"}],"/Huber-Loss":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Huber-Loss","text":"Huber Loss"}],"/Hui-Liu":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Hui-Liu","text":"Hui Liu"}],"/Hui-Su":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Hui-Su","text":"Hui Su"}],"/Huizhen-Wang":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Huizhen-Wang","text":"Huizhen Wang"}],"/Hung-yi-Lee":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Hung-yi-Lee","text":"Hung-yi Lee"}],"/Huy-Le-Nguyen":[{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Le-Nguyen","text":"Huy Le Nguyen"}],"/Huy-Phan":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"}],"/Hypergraphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Hypergraphs","text":"Hypergraphs"}],"/Hysteresis-Thresholding":[{"source":"/CE7491-Lecture-3","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"},{"source":"/Research-Ideas","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"}],"/Hyundong-Cho":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Hyundong-Cho","text":"Hyundong Cho"}],"/Hyunmin-Lee":[{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Hyunmin-Lee","text":"Hyunmin Lee"}],"/I%C3%B1igo-Casanueva":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/I%C3%B1igo-Casanueva","text":"Iñigo Casanueva"}],"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"}],"/IRIS-dataset":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/IRIS-dataset","text":"IRIS dataset"}],"/IRIS-dialogue-system":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/IRIS-dialogue-system","text":"IRIS dialogue system"}],"/IWSLT":[{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/IWSLT","text":"IWSLT"}],"/IWSLT-En-Fr":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-En-Fr","text":"IWSLT En-Fr"}],"/IWSLT-Zh-En":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-Zh-En","text":"IWSLT Zh-En"}],"/IWSLT14-De-En":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"}],"/IWSLT16-De-En":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"}],"/IWSLT16-En-De":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"}],"/Ian-McLoughlin":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"}],"/Ibon-Saratxaga":[{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Ibon-Saratxaga","text":"Ibon Saratxaga"}],"/Ilaria-Manco":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Ilaria-Manco","text":"Ilaria Manco"}],"/Ilya-Chatsviorkin":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Ilya-Chatsviorkin","text":"Ilya Chatsviorkin"}],"/Ilya-Eckstein":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Ilya-Eckstein","text":"Ilya Eckstein"}],"/Ilya-Sutskever":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Ilya-Sutskever","text":"Ilya Sutskever"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ilya-Sutskever","text":"Ilya Sutskever"}],"/Image-Captioning":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Image-Captioning","text":"Image Captioning"}],"/Image-Dithering":[{"source":"/CE7491-Lecture-1","target":"/Image-Dithering","text":"Image Dithering"}],"/Image-Inpainting":[{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Image-Inpainting","text":"Image Inpainting"}],"/Image-Negatives":[{"source":"/CE7491-Lecture-2","target":"/Image-Negatives","text":"Image Negatives"}],"/Image-Quilting-for-Texture-Synthesis-and-Transfer":[{"source":"/Week-Summary-210920-011120","target":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","text":"Image Quilting for Texture Synthesis and Transfer"}],"/Image-Restoration":[{"source":"/CE7491-Lecture-6","target":"/Image-Restoration","text":"Image Restoration"}],"/Image-to-Image-Translation":[{"source":"/CE7491-Lecture-8","target":"/Image-to-Image-Translation","text":"Image-to-Image Translation"}],"/ImageNet":[{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"},{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"},{"source":"/Security-and-Machine-Learning","target":"/ImageNet","text":"ImageNet"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ImageNet","text":"ImageNet"}],"/Imitation-Learning":[{"source":"/Paper-Levenshtein-Transformer","target":"/Imitation-Learning","text":"Imitation Learning"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imitation-Learning","text":"Imitation Learning"}],"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990":[{"source":"/Week-Summary-210920-011120","target":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","text":"Implementing fuzzy logic controllers using a neural network framework (1990)"}],"/Importance-Sampling":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Importance-Sampling","text":"Importance Sampling"}],"/Importance-Weighted-Decoding":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Importance-Weighted-Decoding","text":"Importance Weighted Decoding"}],"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output":[{"source":"/Week-Summary-021120-221120","target":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","text":"Improved MCMAC with Momentum, Neighborhood, and Averaged Trapezoidal Output"}],"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data":[{"source":"/Week-Summary-240820-300820","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"},{"source":"/Week-Summary-250520-310520","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"}],"/Imputer":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"}],"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming":[{"source":"/Week-Summary-030820-160820","target":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","text":"Imputer - Sequence Modelling via Imputation and Dynamic Programming"}],"/Incidence-Matrix":[{"source":"/Hypergraphs","target":"/Incidence-Matrix","text":"Incidence Matrix"}],"/Incremental-Intersection":[{"source":"/Color-Indexing","target":"/Incremental-Intersection","text":"Incremental Intersection"}],"/Independent-Component-Analysis":[{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"}],"/Index-Positional-Encoding":[{"source":"/Graph-Positional-Encodings","target":"/Index-Positional-Encoding","text":"Index Positional Encoding"}],"/Inductive-Biases":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Research-Ideas","target":"/Inductive-Biases","text":"Inductive Biases"}],"/Information-Retrieval":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Information-Retrieval","text":"Information Retrieval"}],"/Information-Theoretic-Probing":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"},{"source":"/Information-Theoretic-Probing","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"}],"/Injective":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Injective","text":"Injective"},{"source":"/Graph-Isomorphism-Networks","target":"/Injective","text":"Injective"},{"source":"/Weisfieler-Lehman-test","target":"/Injective","text":"Injective"}],"/Insertion-Transformer":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer","text":"Insertion Transformer"}],"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations":[{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","text":"Insertion Transformer - Flexible Sequence Generation via Insertion Operations"}],"/Integrated-Gradient-Guided-Attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Integrated-Gradient-Guided-Attack","text":"Integrated Gradient Guided Attack"}],"/Intelligent-Tutoring-Systems-ITS":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Intelligent-Tutoring-Systems-ITS","text":"Intelligent Tutoring Systems (ITS)"}],"/Intent-Detection":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Intent-Detection","text":"Intent Detection"}],"/Inter-sentential-Relations":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Inter-sentential-Relations","text":"Inter-sentential Relations"}],"/Interaction-Quality":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Interaction-Quality","text":"Interaction Quality"}],"/Interpretability":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Interpretability","text":"Interpretability"}],"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003":[{"source":"/Week-Summary-210920-011120","target":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","text":"Interpretability Improvements to Find the Balance Interpretability-Accuracy in Fuzzy Modeling - An Overview (2003)"}],"/Intra-sentential-Relations":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Intra-sentential-Relations","text":"Intra-sentential Relations"}],"/Inverse-Graph-Fourier-Transform":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"}],"/Inverse-Square-Root-Linear-Unit":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"}],"/Invertibility":[{"source":"/CZ1104-Lecture-7.2","target":"/Invertibility","text":"Invertibility"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/Katz-Centrality","target":"/Invertibility","text":"Invertibility"}],"/Irene-Lo":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"}],"/Iryna-Gurevych":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Iryna-Gurevych","text":"Iryna Gurevych"}],"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities":[{"source":"/Week-Summary-010620-210620","target":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","text":"Is this Dialogue Coherent - Learning from Dialogue Acts and Entities"}],"/Isabelle-Augenstein":[{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Isabelle-Augenstein","text":"Isabelle Augenstein"}],"/Isomap":[{"source":"/Visualizing-Data-using-t-SNE","target":"/Isomap","text":"Isomap"}],"/Isomorphism":[{"source":"/Graph-Isomorphism","target":"/Isomorphism","text":"Isomorphism"},{"source":"/Graph-Substructure-Networks","target":"/Isomorphism","text":"Isomorphism"}],"/Isotropy":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Isotropy","text":"Isotropy"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Isotropy","text":"Isotrophic"},{"source":"/Research-Ideas","target":"/Isotropy","text":"Isotropy"}],"/Iterative-Magnitude-Pruning":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"}],"/Iterative-Refinement":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"}],"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Week-Summary-310820-200920","target":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","text":"Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation"}],"/Itxasne-Diez-Gaspon":[{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Itxasne-Diez-Gaspon","text":"Itxasne Diez Gaspon"}],"/JSALT2020":[{"source":"/July-3rd-2020","target":"/JSALT2020","text":"JSALT2020"},{"source":"/Research-Ideas","target":"/JSALT2020","text":"JSALT2020"}],"/Jaccard-Similarity":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Jaccard-Similarity","text":"Jaccard Similarity"}],"/Jack-Clark":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jack-Clark","text":"Jack Clark"}],"/Jack-Urbanek":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jack-Urbanek","text":"Jack Urbanek"}],"/Jaehun-Kim":[{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Jaehun-Kim","text":"Jaehun Kim"}],"/Jake-Zhao-Junbo":[{"source":"/Paper-Levenshtein-Transformer","target":"/Jake-Zhao-Junbo","text":"Jake Zhao Junbo"}],"/Jakob-Uszkoreit":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"}],"/James-Bradbury":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/James-Bradbury","text":"James Bradbury"}],"/James-Glass":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/James-Glass","text":"James Glass"}],"/James-Henderson":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/James-Henderson","text":"James Henderson"}],"/James-Lee-Thorp":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/James-Lee-Thorp","text":"James Lee-Thorp"}],"/Jamie-Hall":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Jamie-Hall","text":"Jamie Hall"}],"/Jamie-Kiros":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jamie-Kiros","text":"Jamie Kiros"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Jamie-Kiros","text":"Jamie Kiros"}],"/Jan-Deriu":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Jan-Deriu","text":"Jan Deriu"}],"/Jane-Shen":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Jane-Shen","text":"Jane Shen"}],"/Janice-Lee-Ser-Huey":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"}],"/January-12th-2021":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/January-12th-2021","text":"January 12th 2021"}],"/January-13th-2021":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/January-13th-2021","text":"January 13th 2021"}],"/January-27th-2021":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/January-27th-2021","text":"January 27th 2021"}],"/January-4th-2021":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/January-4th-2021","text":"January 4th 2021"}],"/January-5th-2021":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/January-5th-2021","text":"January 5th 2021"}],"/January-6th-2021":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/January-6th-2021","text":"January 6th 2021"}],"/January-7th-2021":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/January-7th-2021","text":"January 7th 2021"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/January-7th-2021","text":"January 7th 2021"}],"/Jared-Kaplan":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jared-Kaplan","text":"Jared Kaplan"}],"/Jasmin-Pielorz":[{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Jasmin-Pielorz","text":"Jasmin Pielorz"}],"/Jason-Lee":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jason-Lee","text":"Jason Lee"}],"/Jason-Weston":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jason-Weston","text":"Jason Weston"}],"/Jean-Bastien-Grill":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Jean-Bastien-Grill","text":"Jean-Bastien Grill"}],"/Jeffrey-Wu":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Jeffrey-Wu","text":"Jeffrey Wu"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jeffrey-Wu","text":"Jeffrey Wu"}],"/Jensen-Shannon-Divergence":[{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Jensen-Shannon-Divergence","text":"Jensen-Shannon Divergence"}],"/Jerry-Li":[{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"}],"/Ji-Zhang":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Ji-Zhang","text":"Ji Zhang"}],"/Jiajun-Chen":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiajun-Chen","text":"Jiajun Chen"}],"/Jian-Sun":[{"source":"/Optimized-Product-Quantization","target":"/Jian-Sun","text":"Jian Sun"}],"/Jianfeng-Gao":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jianfeng-Gao","text":"Jianfeng Gao"}],"/Jiangfeng-Chen":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jiangfeng-Chen","text":"Jiangfeng Chen"}],"/Jiangtao-Feng":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiangtao-Feng","text":"Jiangtao Feng"}],"/Jianyuan-Zhong":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Jianyuan-Zhong","text":"Jianyuan Zhong"}],"/Jiatao-Gu":[{"source":"/Paper-Levenshtein-Transformer","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"}],"/Jiawei-Zhou":[{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Jiawei-Zhou","text":"Jiawei Zhou"}],"/Jie-Jiang":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jie-Jiang","text":"Jie Jiang"}],"/Jie-Zhou":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"}],"/Jiebo-Luo":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jiebo-Luo","text":"Jiebo Luo"}],"/Jiliang-Tang":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Jiliang-Tang","text":"Jiliang Tang"}],"/JinYeong-Bak":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/JinYeong-Bak","text":"JinYeong Bak"}],"/Jing-Liu":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jing-Liu","text":"Jing Liu"}],"/Jing-Xu":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jing-Xu","text":"Jing Xu"}],"/Jingbo-Zhu":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Jingbo-Zhu","text":"Jingbo Zhu"}],"/Jingjing-Liu":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jingjing-Liu","text":"Jingjing Liu"}],"/Jinglin-Liu":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Jinglin-Liu","text":"Jinglin Liu"}],"/Jinsong-Su":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jinsong-Su","text":"Jinsong Su"}],"/Jisheng-Bai":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jisheng-Bai","text":"Jisheng Bai"}],"/Jiusheng-Chen":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Jiusheng-Chen","text":"Jiusheng Chen"}],"/Jo%C3%A3o-Sedoc":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Jo%C3%A3o-Sedoc","text":"João Sedoc"}],"/Jonathan-Frankle":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Jonathan-Frankle","text":"Jonathan Frankle"}],"/Jonathan-May":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Jonathan-May","text":"Jonathan May"}],"/Jorge-Casillas":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Jorge-Casillas","text":"Jorge Casillas"}],"/Joshua-Ainslie":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Joshua-Ainslie","text":"Joshua Ainslie"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Joshua-Ainslie","text":"Joshua Ainslie"}],"/July-16th-2020":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"}],"/July-18th-2020":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/July-18th-2020","text":"July 18th, 2020"}],"/July-19th-2020":[{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"}],"/July-20th-2020":[{"source":"/Frontiers-in-Machine-Learning","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Machine-Learning-Conversations","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Week-Summary-200720-020820","target":"/July-20th-2020","text":"July 20th, 2020"}],"/July-21st-2020":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Security-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"}],"/July-22nd-2020":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/July-22nd-2020","text":"July 22nd, 2020"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/July-22nd-2020","text":"July 22nd, 2020"}],"/July-23rd-2020":[{"source":"/Frontiers-in-Machine-Learning","target":"/July-23rd-2020","text":"July 23rd, 2020"}],"/July-24th-2020":[{"source":"/10-things-you-should-know-about-dialogue","target":"/July-24th-2020","text":"July 24th, 2020"}],"/July-30th-2020":[{"source":"/Break-into-Natural-Language-Processing","target":"/July-30th-2020","text":"July 30th, 2020"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/July-30th-2020","text":"July 30th, 2020"}],"/July-31st-2020":[{"source":"/Alan-Turing-The-Enigma","target":"/July-31st-2020","text":"July 31st, 2020"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/July-31st-2020","text":"July 31st, 2020"}],"/July-5th-2020":[{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"},{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"}],"/July-6th-2020":[{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Visualizing-Data-using-t-SNE","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-6th-2020","text":"July 6th, 2020"}],"/June-15th-2020":[{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/June-15th-2020","text":"June 15th, 2020"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/June-15th-2020","text":"June 15th, 2020"}],"/June-16th-2020":[{"source":"/Misinformation-has-High-Perplexity","target":"/June-16th-2020","text":"June 16th, 2020"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/June-16th-2020","text":"June 16th, 2020"}],"/June-17th-2020":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/June-17th-2020","text":"June 17th, 2020"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/June-17th-2020","text":"June 17th, 2020"}],"/June-18th-2020":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/June-18th-2020","text":"June 18th, 2020"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/June-18th-2020","text":"June 18th, 2020"}],"/June-19th-2020":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/June-19th-2020","text":"June 19th, 2020"}],"/June-1st-2020":[{"source":"/Week-Summary-010620-210620","target":"/June-1st-2020","text":"June 1st, 2020"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/June-1st-2020","text":"June 1st, 2020"}],"/June-20th-2020":[{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/June-20th-2020","text":"June 20th, 2020"}],"/June-21st-2020":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"}],"/June-22nd-2020":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Week-Summary-220620-050720","target":"/June-22nd-2020","text":"June 22nd, 2020"}],"/June-23rd-2020":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/June-23rd-2020","text":"June 23rd, 2020"}],"/June-24th-2020":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/June-24th-2020","text":"June 24th, 2020"}],"/June-25th-2020":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/June-25th-2020","text":"June 25th, 2020"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/June-25th-2020","text":"June 25th, 2020"}],"/June-2nd-2020":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/June-2nd-2020","text":"June 2nd, 2020"}],"/June-3rd-2020":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/June-3rd-2020","text":"June 3rd, 2020"}],"/Junhwi-Choi":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Junhwi-Choi","text":"Junhwi Choi"}],"/Junliang-Guo":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Junliang-Guo","text":"Junliang Guo"}],"/Junyan-Fang":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Junyan-Fang","text":"Junyan Fang"}],"/Justin-Gilmer":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Justin-Gilmer","text":"Justin Gilmer"}],"/K-means-clustering":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/K-means-clustering","text":"K-means clustering"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/K-means-clustering","text":"K-means clustering"}],"/KBGAN":[{"source":"/TransE","target":"/KBGAN","text":"KBGAN"}],"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences":[{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"},{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"}],"/KL-divergence":[{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/KL-divergence","text":"KL-divergence"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/KL-divergence","text":"KL-divergence"}],"/Kai-Keng-Ang":[{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Kai-Keng-Ang","text":"Kai Keng Ang"}],"/Kai-Yu":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Kai-Yu","text":"Kai Yu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Kai-Yu","text":"Kai Yu"}],"/Kaiming-He":[{"source":"/Optimized-Product-Quantization","target":"/Kaiming-He","text":"Kaiming He"}],"/Kang-Hyun-Lee":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kang-Hyun-Lee","text":"Kang Hyun Lee"}],"/Kappa-coefficient":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Kappa-coefficient","text":"Kappa coefficient"}],"/Katja-Hofmann":[{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"}],"/Katz-Centrality":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Katz-Centrality","text":"Katz Centrality"}],"/Kawin-Ethayarajh":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Kawin-Ethayarajh","text":"Kawin Ethayarajh"}],"/Ke-Li":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Ke-Li","text":"Ke Li"}],"/Keita-Kurita":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Keita-Kurita","text":"Keita Kurita"}],"/Kelsey-Allen":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Kelsey-Allen","text":"Kelsey Allen"}],"/Kelvin-Guu":[{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kelvin-Guu","text":"Kelvin Guu"}],"/Kenneth-Church":[{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"},{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"}],"/Kernel-CMAC-Architecture":[{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Kernel-CMAC-Architecture","text":"Kernel CMAC (Architecture)"}],"/Kernel-CMAC-With-Improved-Capability":[{"source":"/Week-Summary-021120-221120","target":"/Kernel-CMAC-With-Improved-Capability","text":"Kernel CMAC With Improved Capability"}],"/Khaled-Koutini":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Khaled-Koutini","text":"Khaled Koutini"}],"/Khoa-Pham":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Khoa-Pham","text":"Khoa Pham"}],"/Knowledge-Based-Agents":[{"source":"/CE7429-Lecture-12","target":"/Knowledge-Based-Agents","text":"Knowledge Based Agents"}],"/Knowledge-Distillation":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"}],"/Knowledge-Graph-Embeddings-and-Explainable-AI":[{"source":"/Bilinear-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Ontology","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/TransE","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Translational-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"}],"/Knowledge-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Match-and-Map","target":"/Knowledge-Graphs","text":"Knowledge Graphs"}],"/Knowledge-Graphs-Embeddings":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/TransE","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"}],"/Konstantinos-Drossos":[{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"}],"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT":[{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"}],"/Koray-Kavukcuoglu":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Koray-Kavukcuoglu","text":"Koray Kavukcuoglu"}],"/Kotaro-Funakoshi":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"}],"/Kronecker-Delta":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Kronecker-Delta","text":"Kronecker Delta"}],"/Kuhwan-Jeong":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kuhwan-Jeong","text":"Kuhwan Jeong"}],"/Kun-Chen":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Kun-Chen","text":"Kun Chen"}],"/Kunio-Kashino":[{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Kunio-Kashino","text":"Kunio Kashino"}],"/Kurt-Shuster":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Kurt-Shuster","text":"Kurt Shuster"}],"/Kurtosis":[{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"},{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"}],"/Kyosuke-Nishida":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Kyosuke-Nishida","text":"Kyosuke Nishida"}],"/Kyunghyun-Cho":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Kyunghyun-Cho","text":"Kyunghyun Cho"}],"/L0-regularization":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/L0-regularization","text":"L0 regularization"}],"/LAMBADA":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/LAMBADA","text":"LAMBADA"}],"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING":[{"source":"/Week-Summary-301120-061220","target":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","text":"LANGUAGE MODEL IS ALL YOU NEED - NATURAL LANGUAGE UNDERSTANDING AS QUESTION ANSWERING"}],"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS":[{"source":"/Match-and-Map","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"},{"source":"/Week-Summary-141220-271220","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"}],"/LDC2002E18":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2002E18","text":"LDC2002E18"}],"/LDC2003E14":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2003E14","text":"LDC2003E14"}],"/LDC2004T08":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2004T08","text":"LDC2004T08"}],"/LDC2005T0":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2005T0","text":"LDC2005T0"}],"/LIAR-Politifact":[{"source":"/Misinformation-has-High-Perplexity","target":"/LIAR-Politifact","text":"LIAR-Politifact"}],"/LITIS-Rouen-dataset":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"}],"/LLE":[{"source":"/Visualizing-Data-using-t-SNE","target":"/LLE","text":"LLE"}],"/LSTM":[{"source":"/BiLSTM","target":"/LSTM","text":"LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/LSTM","text":"LSTM"},{"source":"/GraphSAGE-Filter","target":"/LSTM","text":"LSTM"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"},{"source":"/Tree-LSTM","target":"/LSTM","text":"LSTM"}],"/Label-Flip-Rate":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Label-Flip-Rate","text":"Label Flip Rate"}],"/Lam-Pham":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"}],"/Lanczos-algorithm":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Lanczos-algorithm","text":"Lanczos algorithm"}],"/Language-Models-are-Few-Shot-Learners":[{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"},{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"}],"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP":[{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"},{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"}],"/Laplace-operator":[{"source":"/Laplacian-Filter","target":"/Laplace-operator","text":"Laplace operator"},{"source":"/Laplacian-of-Gaussian-Filter","target":"/Laplace-operator","text":"Laplace operator"}],"/Laplacian-Filter":[{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"},{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"}],"/Laplacian-Matrix":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/GCN-Filter","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Graph-Fourier-Transform","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Spectral-Graph-Convolutions","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Spectral-Graph-Theory","target":"/Laplacian-Matrix","text":"Laplacian Matrix"}],"/Laplacian-Positional-Encodings":[{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Positional-Encodings","text":"Laplacian Positional Encodings"}],"/Laplacian-of-Gaussian-Filter":[{"source":"/CE7491-Lecture-3","target":"/Laplacian-of-Gaussian-Filter","text":"Laplacian of Gaussian Filter"}],"/Large-Scale-Information-Network-Embedding-LINE":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Large-Scale-Information-Network-Embedding-LINE","text":"Large-Scale Information Network Embedding (LINE)"}],"/Latent-Alignment-Models":[{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"}],"/Latent-Space":[{"source":"/CE7491-Lecture-8","target":"/Latent-Space","text":"Latent Space"}],"/Laurence-Liew":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Laurence-Liew","text":"Laurence Liew"}],"/Laurens-van-der-Maaten":[{"source":"/Visualizing-Data-using-t-SNE","target":"/Laurens-van-der-Maaten","text":"Laurens van der Maaten"}],"/Layer-wise-Sampling":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"}],"/LeakyReLU":[{"source":"/GAT-Filter","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/Graph-Attention","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/WaveTransformer","target":"/LeakyReLU","text":"LeakyReLU"}],"/Learning-Convergence-of-CMAC-Technique":[{"source":"/Week-Summary-021120-221120","target":"/Learning-Convergence-of-CMAC-Technique","text":"Learning Convergence of CMAC Technique"}],"/Learning-Rate":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Learning-Rate","text":"Learning Rate"}],"/Learning-Without-Forgetting":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Learning-Without-Forgetting","text":"Learning Without Forgetting"}],"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition":[{"source":"/Week-Summary-010620-210620","target":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","text":"Learning not to Discriminate - Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition"}],"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation":[{"source":"/Week-Summary-010620-210620","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"}],"/Least-Squares":[{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"}],"/Least-Squares-Solution-for-Inconsistent-Equations":[{"source":"/CZ1104-Lecture-7.1","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"}],"/Lei-Li":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lei-Li","text":"Lei Li"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Lei-Li","text":"Lei Li"}],"/Letter-Error-Rate":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Letter-Error-Rate","text":"Letter Error Rate"}],"/Levenshtein-Distance":[{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Levenshtein-Distance","text":"Levenshtein Distance"}],"/Levenshtein-Transformer-Architecture":[{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"}],"/Lexical-Consistency":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Lexical-Consistency","text":"Lexical Consistency"},{"source":"/Inter-sentential-Relations","target":"/Lexical-Consistency","text":"Lexical Consistency"}],"/Li-Yang":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Li-Yang","text":"Li Yang"}],"/Liang-Ding":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Liang-Ding","text":"Liang Ding"}],"/Liangyou-Li":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Liangyou-Li","text":"Liangyou Li"}],"/LibriSpeech":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriSpeech","text":"LibriSpeech"}],"/LibriVox":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriVox","text":"LibriVox"}],"/Lifelong-Learning":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Lifelong-Learning","text":"Lifelong Learning"}],"/Lihua-Qian":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lihua-Qian","text":"Lihua Qian"}],"/Likert-Scores":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"}],"/Lin-Qiu":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lin-Qiu","text":"Lin Qiu"}],"/Linear-Algebra":[{"source":"/Spectral-Graph-Theory","target":"/Linear-Algebra","text":"Linear Algebra"}],"/Linear-Discriminant-Analysis":[{"source":"/CE7429-Lecture-6","target":"/Linear-Discriminant-Analysis","text":"Linear Discriminant Analysis"}],"/Linearized-Graph":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"}],"/Linguistic-Fuzzy-Logic":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"}],"/Linguistic-Hedges":[{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Linguistic-Hedges","text":"Linguistic Hedges"}],"/Link-Prediction":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Link-Prediction","text":"Link Prediction"}],"/Linli-Xu":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Linli-Xu","text":"Linli Xu"}],"/Liu-Ren":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Liu-Ren","text":"Liu Ren"}],"/Local-Entropy":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Local-Entropy","text":"Local Entropy"}],"/Locality-Invariant":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Locality-Invariant","text":"Locality Invariant"}],"/Long-Term-Memory":[{"source":"/CE7429-Lecture-13","target":"/Long-Term-Memory","text":"Long Term Memory"}],"/Longteng-Guo":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Longteng-Guo","text":"Longteng Guo"}],"/Longyue-Wang":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Longyue-Wang","text":"Longyue Wang"}],"/Lotfi-Asker-Zadeh":[{"source":"/Compositional-Rule-of-Inference","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Fuzzy-Sets-1965","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"}],"/Lottery-Ticket-Hypothesis":[{"source":"/Rewinding","target":"/Lottery-Ticket-Hypothesis","text":"Lottery Ticket Hypothesis"}],"/Luca-Constabello":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Luca-Constabello","text":"Luca Constabello"}],"/Luis-Magdalena":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Luis-Magdalena","text":"Luis Magdalena"}],"/Luke-Zettlemoyer":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Luke-Zettlemoyer","text":"Luke Zettlemoyer"}],"/Luminance":[{"source":"/CE7491-Lecture-3","target":"/Luminance","text":"Luminance"}],"/Lyapunov-Model-Reference-MRAC":[{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"}],"/MATE":[{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/MATE","text":"MATE"}],"/METEOR":[{"source":"/10-things-you-should-know-about-dialogue","target":"/METEOR","text":"METEOR"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/METEOR","text":"METEOR"}],"/MNIST":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/MNIST","text":"MNIST"}],"/MSCOCO":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/MSCOCO","text":"MSCOCO"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/MSCOCO","text":"MSCOCO"}],"/MSDialog":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MSDialog","text":"MSDialog"}],"/Maarten-De-Vos":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Maarten-De-Vos","text":"Maarten De Vos"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Maarten-De-Vos","text":"Maarten De Vos"}],"/Machine-Learning":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Machine-Learning","text":"Machine Learning"},{"source":"/Laplacian-Matrix","target":"/Machine-Learning","text":"Machine Learning"}],"/Machine-Learning-Conversations":[{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Conversations","text":"Machine Learning Conversations"}],"/Machine-Learning-Reliability-and-Robustness":[{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Reliability-and-Robustness","text":"Machine Learning Reliability and Robustness"}],"/Magdalena-Fuentes":[{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Magdalena-Fuentes","text":"Magdalena Fuentes"}],"/Mahalanobis-Distance":[{"source":"/CE7429-Lecture-5","target":"/Mahalanobis-Distance","text":"Mahalanobis Distance"}],"/Mahdi-Namazifar":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Mahdi-Namazifar","text":"Mahdi Namazifar"}],"/Manhattan-Distance":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Manhattan-Distance","text":"L1 norm"},{"source":"/TransE","target":"/Manhattan-Distance","text":"Manhattan Distance"}],"/Manoj-Plakal":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Manoj-Plakal","text":"Manoj Plakal"}],"/Manzil-Zaheer":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Manzil-Zaheer","text":"Manzil Zaheer"}],"/Margaret-Li":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Margaret-Li","text":"Margaret Li"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Margaret-Li","text":"Margaret Li"}],"/Maria-Rifqi":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Maria-Rifqi","text":"Maria Rifqi"}],"/Marjan-Ghazvininejad":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Marjan-Ghazvininejad","text":"Marjan Ghazvininejad"}],"/Mark-Chen":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Mark-Chen","text":"Mark Chen"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mark-Chen","text":"Mark Chen"}],"/Mark-Cieliebak":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Mark-Cieliebak","text":"Mark Cieliebak"}],"/Markov-Decision-Process":[{"source":"/Paper-Levenshtein-Transformer","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/RL-S2V","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Markov-Decision-Process","text":"Markov Decision Process"}],"/Markov-Random-Field":[{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Markov-Random-Field","text":"Markov Random Field"}],"/Marti-Hearst":[{"source":"/Break-into-Natural-Language-Processing","target":"/Marti-Hearst","text":"Marti Hearst"}],"/Martin-Schmitt":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Martin-Schmitt","text":"Martin Schmitt"}],"/Mary-Gray":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"}],"/Mary-Williamson":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Mary-Williamson","text":"Mary Williamson"}],"/Marzieh-Fadaee":[{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Marzieh-Fadaee","text":"Marzieh Fadaee"}],"/Marzyeh-Ghassemi":[{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Marzyeh-Ghassemi","text":"Marzyeh Ghassemi"}],"/Masahiro-Yasuda":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"}],"/Mask-Predict":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict","text":"Mask-Predict"}],"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models":[{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","text":"Mask-Predict - Parallel Decoding of Conditional Masked Language Models"}],"/Masked-Acoustic-Modelling":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Acoustic-Modelling","text":"Masked Acoustic Modelling"}],"/Masked-Graph-Modelling":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"}],"/Masked-Language-Modelling":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"}],"/Masked-Node-and-Edge-Modelling":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Node-and-Edge-Modelling","text":"Masked Node and Edge Modelling"}],"/Match-and-Map":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"Match and Map"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"MaMa"}],"/Mateusz-Litwin":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mateusz-Litwin","text":"Mateusz Litwin"}],"/Mateusz-Malinowski":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Mateusz-Malinowski","text":"Mateusz Malinowski"}],"/Mathew-Monfort":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Mathew-Monfort","text":"Mathew Monfort"}],"/Matrix-Approximation":[{"source":"/CZ1104-Lecture-8.4","target":"/Matrix-Approximation","text":"Matrix Approximation"}],"/Matt-Botvinick":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Matt-Botvinick","text":"Matt Botvinick"}],"/Matteo-Palmonari":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Matteo-Palmonari","text":"Matteo Palmonari"}],"/Matthias-Bethge":[{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Matthias-Bethge","text":"Matthias Bethge"}],"/Max-Pooling":[{"source":"/Flat-Graph-Pooling","target":"/Max-Pooling","text":"Max Pooling"}],"/Max-Welling":[{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Max-Welling","text":"Max Welling"}],"/Maximum-Receptive-Field":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"}],"/Maxine-Eskenazi":[{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Maxine-Eskenazi","text":"Maxine Eskenazi"}],"/May-10th-2021":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/May-10th-2021","text":"May 10th 2021"}],"/May-11th-2021":[{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/May-11th-2021","text":"May 11th 2021"}],"/May-18th-2020":[{"source":"/Week-Summary-180520-240520","target":"/May-18th-2020","text":"May 18th, 2020"}],"/May-18th-2021":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/May-18th-2021","text":"May 18th 2021"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/May-18th-2021","text":"May 18th 2021"}],"/May-1st-2021":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Optimized-Product-Quantization","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/May-1st-2021","text":"May 1st 2021"}],"/May-23rd-2020":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/May-23rd-2020","text":"May 23rd, 2020"}],"/May-24th-2020":[{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"}],"/May-25th-2020":[{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/May-25th-2020","text":"May 25th, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-25th-2020","text":"May 25th, 2020"}],"/May-26th-2020":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/May-26th-2020","text":"May 26th, 2020"}],"/May-27th-2020":[{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/May-27th-2020","text":"May 27th, 2020"}],"/May-28th-2020":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/May-28th-2020","text":"May 28th, 2020"}],"/May-29th-2020":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/May-29th-2020","text":"May 29th, 2020"}],"/May-30th-2020":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/May-30th-2020","text":"May 30th, 2020"}],"/May-31st-2020":[{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"}],"/May-3rd-2021":[{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/May-3rd-2021","text":"May 3rd 2021"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/May-3rd-2021","text":"May 3rd 2021"}],"/MeMo-workbench":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MeMo-workbench","text":"MeMo workbench"}],"/Mean-Reciprocal-Rank":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Mean-Reciprocal-Rank","text":"Mean Reciprocal Rank"}],"/Mean-Shift-Analysis-and-Applications":[{"source":"/Week-Summary-210920-011120","target":"/Mean-Shift-Analysis-and-Applications","text":"Mean Shift Analysis and Applications"}],"/Mean-Shift-Estimate":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Estimate","text":"Mean Shift Estimate"}],"/Mean-Shift-Filtering":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"}],"/Mean-Shift-Segmentation":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"}],"/Mean-Squared-Error":[{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Mean-Squared-Error","text":"Mean Squared Error"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Mean-Squared-Error","text":"Mean Squared Error"}],"/Mechanism-Design-for-Social-Good":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mechanism-Design-for-Social-Good","text":"Mechanism Design for Social Good"}],"/Median-Filtering":[{"source":"/CE7491-Lecture-2","target":"/Median-Filtering","text":"Median Filtering"}],"/Meena":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Meena","text":"Meena"}],"/Mehdi-Rezagholizadeh":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Mehdi-Rezagholizadeh","text":"Mehdi Rezagholizadeh"}],"/Mel-Spectrograms":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Mel-Spectrograms","text":"Mel Spectrograms"}],"/Melanie-Subbiah":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Melanie-Subbiah","text":"Melanie Subbiah"}],"/Melvin-Chen":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"}],"/Memory":[{"source":"/CE7429-Lecture-12","target":"/Memory","text":"Memory"}],"/Mengyue-Wu":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Mengyue-Wu","text":"Mengyue Wu"}],"/Message-Passing-Networks":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Message-Passing-Networks","text":"Message-Passing Networks"}],"/Meta-Gradients":[{"source":"/Metattack","target":"/Meta-Gradients","text":"Meta-Gradients"}],"/Meta-Path-Schema":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Meta-Path-Schema","text":"Meta-Path Schema"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Meta-Path-Schema","text":"Meta-Path Schema"}],"/Meta-Reinforcement-Learning":[{"source":"/Machine-Learning-Conversations","target":"/Meta-Reinforcement-Learning","text":"Meta Reinforcement Learning"}],"/Metattack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Metattack","text":"Metattack"}],"/Mia-Chen":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Mia-Chen","text":"Mia Chen"}],"/Micha%C3%ABl-Defferrard":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Micha%C3%ABl-Defferrard","text":"Michaël Defferrard"}],"/Michael-Auli":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Michael-Auli","text":"Michael Auli"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Michael-Auli","text":"Michael Auli"}],"/Michael-Carbin":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Michael-Carbin","text":"Michael Carbin"}],"/Michal-Valko":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Michal-Valko","text":"Michal Valko"}],"/Michel-Galley":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Michel-Galley","text":"Michel Galley"}],"/Michimasa-Inaba":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Michimasa-Inaba","text":"Michimasa Inaba"}],"/Mike-Timms":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"}],"/Milica-Ga%C5%A1i%C4%87":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"}],"/Mina-Schutz":[{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mina-Schutz","text":"Mina Schutz"}],"/MineRL-competition":[{"source":"/Machine-Learning-Conversations","target":"/MineRL-competition","text":"MineRL competition"}],"/Ming-Zhou":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ming-Zhou","text":"Ming Zhou"}],"/Mingxuan-Wang":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Mingxuan-Wang","text":"Mingxuan Wang"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Mingxuan-Wang","text":"Mingxuan Wang"}],"/Mingzhou-Xu":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Mingzhou-Xu","text":"Mingzhou Xu"}],"/Minh-Thang-Luong":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Minh-Thang-Luong","text":"Minh-Thang Luong"}],"/Mini-Turning-Benchmark-MTB":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mini-Turning-Benchmark-MTB","text":"Mini-Turning Benchmark (MTB)"}],"/Mirco-Ravanelli":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirco-Ravanelli","text":"Mirco Ravanelli"}],"/Mirella-Lapata":[{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Mirella-Lapata","text":"Mirella Lapata"}],"/Mirko-Bronzi":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirko-Bronzi","text":"Mirko Bronzi"}],"/Misinformation-has-High-Perplexity":[{"source":"/Covid19-politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Covid19-scientific","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/LIAR-Politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Week-Summary-010620-210620","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"}],"/Mitchell-Stern":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mitchell-Stern","text":"Mitchell Stern"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Mitchell-Stern","text":"Mitchell Stern"}],"/Mitsuku":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mitsuku","text":"Mitsuku"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Mitsuku","text":"Mitsuku"}],"/Mixout":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Mixout","text":"Mixout"}],"/Mixture-Model-Network-MoNet":[{"source":"/Mo-Filter","target":"/Mixture-Model-Network-MoNet","text":"Mixture Model Network (MoNet)"}],"/Mixture-of-Experts":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mixture-of-Experts","text":"Mixture of Experts"}],"/Mixture-of-Softmaxes":[{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mixture-of-Softmaxes","text":"Mixture of Softmaxes"}],"/Mixup":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mixup","text":"Mixup"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mixup","text":"Mixup"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Mixup","text":"Mixup"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"}],"/Mo-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Mo-Filter","text":"Mo-Filter"}],"/Mockingjay":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Mockingjay","text":"Mockingjay"}],"/Modal-Memory-Model-SOAR":[{"source":"/CE7429-Lecture-13","target":"/Modal-Memory-Model-SOAR","text":"Modal Memory Model (SOAR)"}],"/Mode-Collapse":[{"source":"/CE7491-Lecture-8","target":"/Mode-Collapse","text":"Mode Collapse"},{"source":"/Research-Ideas","target":"/Mode-Collapse","text":"Mode Collapse"}],"/Modeling-Local-Coherence-An-Entity-Based-Approach":[{"source":"/Week-Summary-060720-190720","target":"/Modeling-Local-Coherence-An-Entity-Based-Approach","text":"Modeling Local Coherence - An Entity-Based Approach"}],"/Models-of-Self-Organization":[{"source":"/CE7429-Lecture-7","target":"/Models-of-Self-Organization","text":"Models of Self-Organization"}],"/Modified-CMAC-MCMAC-Architecture":[{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"}],"/Modularity-Maximization":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Modularity-Maximization","text":"Modularity Maximization"}],"/Modus-Ponens":[{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"}],"/Mohammad-Gheshlaghi-Azar":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Mohammad-Gheshlaghi-Azar","text":"Mohammad Gheshlaghi Azar"}],"/Mohammad-Norouzi":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"}],"/Moments":[{"source":"/CE7429-Lecture-7","target":"/Moments","text":"Moments"}],"/Monte-Carlo":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Monte-Carlo","text":"Monte Carlo"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Monte-Carlo","text":"Monte Carlo"}],"/Moore-Penrose-Pseudoinverse":[{"source":"/CZ1104-Lecture-8.4","target":"/Moore-Penrose-Pseudoinverse","text":"Moore-Penrose Pseudoinverse"}],"/Mou-Wang":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mou-Wang","text":"Mou Wang"}],"/Moustapha-Cisse":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Moustapha-Cisse","text":"Moustapha Cisse"}],"/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011","text":"Movie Scripts (Danescu-Niculescu-Mizil and Lee, 2011)"}],"/Multi-Agent":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Multi-Agent","text":"Multi-Agent"}],"/Multi-Head-Self-Attention":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Attention","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Syntax-GNN","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"}],"/Multi-Modality":[{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"}],"/Multi-Moments-in-Time":[{"source":"/Spoken-Moments-dataset","target":"/Multi-Moments-in-Time","text":"Multi-Moments in Time"}],"/Multi-dimensional-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"}],"/Multi-task-Learning":[{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Multi-task-Learning","text":"Multi-task Learning"}],"/Multi30k":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi30k","text":"Multi30k"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"}],"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"},{"source":"/Week-Summary-010620-210620","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"}],"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative":[{"source":"/Week-Summary-170820-230820","target":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","text":"Multilingual KERMIT - It’s Not Easy Being Generative"}],"/Multiple-Regression-Analysis":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Multiple-Regression-Analysis","text":"Multiple Regression Analysis"}],"/Multisystem-fusion-model-based-on-tag-relationship":[{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Multisystem-fusion-model-based-on-tag-relationship","text":"Multisystem fusion model based on tag relationship"}],"/Music-Captioning":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Music-Captioning","text":"Music Captioning"}],"/Mustafa-Sert":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Mustafa-Sert","text":"Mustafa Sert"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Mustafa-Sert","text":"Mustafa Sert"}],"/Myle-Ott":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Myle-Ott","text":"Myle Ott"}],"/N-grams":[{"source":"/DeepWalk","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"}],"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper":[{"source":"/Week-Summary-210920-011120","target":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","text":"NEFCLASS - A Neuro-Fuzzy approach for the classification of data (Paper)"}],"/NEFCLASS-Architecture":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"}],"/NIST02":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST02","text":"NIST02"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST02","text":"NIST02"}],"/NIST03":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST03","text":"NIST03"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST03","text":"NIST03"}],"/NIST04":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST04","text":"NIST04"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST04","text":"NIST04"}],"/NIST05":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST05","text":"NIST05"}],"/NIST06":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST06","text":"NIST06"}],"/NIST08":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST08","text":"NIST08"}],"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION":[{"source":"/Week-Summary-030820-160820","target":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","text":"NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION"}],"/NP-Hard":[{"source":"/Graph-Neural-Networks","target":"/NP-Hard","text":"NP-Hard"}],"/NP-Intermediate":[{"source":"/Graph-Isomorphism","target":"/NP-Intermediate","text":"NP-Intermediate"}],"/Naman-Goyal":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Naman-Goyal","text":"Naman Goyal"}],"/Named-Entity":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Named-Entity","text":"Named Entity"}],"/Named-Entity-Recognition":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Named-Entity-Recognition","text":"Named Entity Recognition"}],"/Nan-Duan":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Nan-Duan","text":"Nan Duan"}],"/Nash-Equilibrium":[{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"},{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"}],"/Natural-Langauge-Understanding":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Natural-Langauge-Understanding","text":"Natural Langauge Understanding"}],"/Natural-Language-Inference":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Natural-Language-Inference","text":"Natural Language Inference"}],"/Natural-Language-Processing":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Natural-Language-Processing","text":"Natural Language Processing"}],"/Navdeep-Jaitly":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Navdeep-Jaitly","text":"Navdeep Jaitly"}],"/Nayeon-Lee":[{"source":"/Misinformation-has-High-Perplexity","target":"/Nayeon-Lee","text":"Nayeon Lee"}],"/Negative-Sampling":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/DeepWalk","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"}],"/Neighborhood-Explosion":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighborhood Explosion"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighbourhood Expansion"}],"/Neighbors":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Neighbors","text":"Neighbors"}],"/Nettack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"}],"/Neural-Machine-Translation":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Neural-Machine-Translation","text":"NMT"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"}],"/Neural-Machine-Translation-without-Embeddings":[{"source":"/Research-Ideas","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"},{"source":"/Week-Summary-310820-200920","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"}],"/Neural-Network":[{"source":"/CE7491-Lecture-8","target":"/Neural-Network","text":"Neural Network"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Flat-Graph-Pooling","target":"/Neural-Network","text":"Neural Network"},{"source":"/Graph-Auto-Encoders","target":"/Neural-Network","text":"Neural Network"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Neural-Network","text":"Neural Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Neural-Network","text":"Neural Network"}],"/Neural-User-Simulator":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Neural-User-Simulator","text":"Neural User Simulator"}],"/News-Crawl-2007-English":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-English","text":"News Crawl 2007 English"}],"/News-Crawl-2007-French":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-French","text":"News Crawl 2007 French"}],"/News-Crawl-2010-English":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-English","text":"News Crawl 2010 English"}],"/News-Crawl-2010-French":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-French","text":"News Crawl 2010 French"}],"/Next-Sentence-Prediction":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"}],"/Next-Utterance-Selection":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Next-Utterance-Selection","text":"Next Utterance Selection"}],"/Nguyen-Cat-Ho":[{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Nguyen-Cat-Ho","text":"Nguyen Cat Ho"}],"/Nicholas-Roberts":[{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Nicholas-Roberts","text":"Nicholas Roberts"}],"/Nick-Ryder":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Nick-Ryder","text":"Nick Ryder"}],"/Nicolas-Heess":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Nicolas-Heess","text":"Nicolas Heess"}],"/Nicolas-Riche":[{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Nicolas-Riche","text":"Nicolas Riche"}],"/Nikita-Kitaev":[{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Nikita-Kitaev","text":"Nikita Kitaev"}],"/Nilpotent-Minimum":[{"source":"/T-norm","target":"/Nilpotent-Minimum","text":"Nilpotent Minimum"}],"/Nitika-Mathur":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Nitika-Mathur","text":"Nitika Mathur"}],"/Noah-Fiedel":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Noah-Fiedel","text":"Noah Fiedel"}],"/Noah-Smith":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Noah-Smith","text":"Noah Smith"}],"/Noam-Shazeer":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Noam-Shazeer","text":"Noam Shazeer"}],"/Noboru-Harada":[{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Noboru-Harada","text":"Noboru Harada"}],"/Nobuhiro-Kaji":[{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Nobuhiro-Kaji","text":"Nobuhiro Kaji"}],"/Node-Classification":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Node-Classification","text":"Node Classification"}],"/Node-Co-occurrence":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"}],"/Node-Positional-Encodings":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Node-Positional-Encodings","text":"Node Positional Encodings"}],"/Node-Status":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"}],"/Node-wise-Sampling":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"}],"/Noise-Contrasitive-Estimation-NCE":[{"source":"/Negative-Sampling","target":"/Noise-Contrasitive-Estimation-NCE","text":"Noise Contrasitive Estimation (NCE)"}],"/Noisy-Parallel-Decoding-NPD":[{"source":"/Paper-Levenshtein-Transformer","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"}],"/Non-Autoregressive":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive","text":"Non-Autoregressive"}],"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning":[{"source":"/Week-Summary-240820-300820","target":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","text":"Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning"}],"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments":[{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","text":"Non-Autoregressive Machine Translation with Latent Alignments"}],"/Non-Autoregressive-Transformer":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"}],"/Non-Autoregressive-Transformer-by-Position-Learning":[{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"}],"/Non-Gaussianity":[{"source":"/CE7429-Lecture-7","target":"/Non-Gaussianity","text":"Non-Gaussianity"}],"/Non-maximal-Suppression":[{"source":"/CE7491-Lecture-3","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"},{"source":"/Research-Ideas","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"}],"/Normal-Distribution":[{"source":"/CE7429-Lecture-7","target":"/Normal-Distribution","text":"Normal Distribution"}],"/November-17th-2020":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/November-17th-2020","text":"November 17th, 2020"}],"/November-1st-2020":[{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"}],"/November-22nd-2020":[{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"}],"/November-23rd-2020":[{"source":"/Week-Summary-231120-291120","target":"/November-23rd-2020","text":"November 23rd, 2020"}],"/November-26th-2020":[{"source":"/Catch-the-Tails-of-BERT","target":"/November-26th-2020","text":"November 26th, 2020"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/November-26th-2020","text":"November 26th, 2020"}],"/November-27th-2020":[{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/November-27th-2020","text":"November 27th, 2020"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/November-27th-2020","text":"November 27th, 2020"}],"/November-29th-2020":[{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/November-29th-2020","text":"November 29th, 2020"}],"/November-2nd-2020":[{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-2nd-2020","text":"November 2nd, 2020"}],"/November-30th-2020":[{"source":"/Week-Summary-301120-061220","target":"/November-30th-2020","text":"November 30th, 2020"}],"/November-8th-2020":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/November-8th-2020","text":"November 8th, 2020"}],"/November-9th-2020":[{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/November-9th-2020","text":"November 9th, 2020"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/November-9th-2020","text":"November 9th, 2020"}],"/Nucleus-Sampling":[{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Nucleus-Sampling","text":"Nucleus Sampling"}],"/Null-Space":[{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space","text":"Null Space"}],"/Null-Space-kernel":[{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space-kernel","text":"Null Space (kernel)"}],"/Nullity":[{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"},{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"}],"/Occams-Razor":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Occams-Razor","text":"Occam's Razor"}],"/October-10th-2020":[{"source":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","target":"/October-10th-2020","text":"October 10th, 2020"}],"/October-11th-2019":[{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/October-11th-2019","text":"October 11th, 2019"}],"/October-12th-2020":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/October-12th-2020","text":"October 12th, 2020"}],"/October-19th-2020":[{"source":"/Generative-Pretraining-from-Pixels","target":"/October-19th-2020","text":"October 19th, 2020"}],"/October-20th-2020":[{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/October-20th-2020","text":"October 20th, 2020"}],"/October-31st-2020":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/October-31st-2020","text":"October 31st, 2020"}],"/October-7th-2020":[{"source":"/CE7491-Lecture-8","target":"/October-7th-2020","text":"October 7th, 2020"}],"/OffenseEval":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/OffenseEval","text":"OffenseEval"}],"/Okko-R%C3%A4s%C3%A4nen":[{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Okko-R%C3%A4s%C3%A4nen","text":"Okko Räsänen"}],"/Olga-Kovaleva":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Olga-Kovaleva","text":"Olga Kovaleva"}],"/Omer-Levy":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Omer-Levy","text":"Omer Levy"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Omer-Levy","text":"Omer Levy"}],"/Ontology":[{"source":"/Knowledge-Graphs","target":"/Ontology","text":"Ontology"}],"/OpenAI":[{"source":"/Week-Summary-010620-210620","target":"/OpenAI","text":"OpenAI"}],"/OpenSubtitles":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/OpenSubtitles","text":"OpenSubtitles"}],"/OpenSubtitles2018-En-Ru":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/OpenSubtitles2018-En-Ru","text":"OpenSubtitles2018 En-Ru"}],"/Oriol-Vinyals":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Oriol-Vinyals","text":"Oriol Vinyals"}],"/Orthogonal-Basis":[{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"}],"/Orthogonal-Decomposition-Thereom":[{"source":"/CZ1104-Lecture-7.1","target":"/Orthogonal-Decomposition-Thereom","text":"Orthogonal Decomposition Thereom"}],"/Orthogonal-Vector-Conjecture":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Orthogonal-Vector-Conjecture","text":"Orthogonal Vector Conjecture"}],"/Orthogonality":[{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonality"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-7.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Orthogonality","text":"orthogonal"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"orthogonal"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"Orthogonality"}],"/Orthonormal":[{"source":"/CZ1104-Lecture-6.2","target":"/Orthonormal","text":"Orthonormal"}],"/Oscar-Cordon":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Oscar-Cordon","text":"Oscar Cordon"}],"/Osman-Ramadan":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Osman-Ramadan","text":"Osman Ramadan"}],"/Over-Squashing":[{"source":"/Graph-Neural-Networks","target":"/Over-Squashing","text":"Over-Squashing"}],"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4":[{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"}],"/Overview-of-the-dialogue-breakdown-detection-challenge-3":[{"source":"/Week-Summary-220620-050720","target":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","text":"Overview of the dialogue breakdown detection challenge 3"}],"/PA-GNN":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PA-GNN","text":"PA-GNN"}],"/PARAdigm-for-DIalog-System-Evaluation":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/PARAdigm-for-DIalog-System-Evaluation","text":"PARAdigm for DIalog System Evaluation"}],"/PCA":[{"source":"/Research-Ideas","target":"/PCA","text":"PCA"}],"/PENMAN":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/PENMAN","text":"PENMAN"}],"/PGD-Topology-Attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PGD-Topology-Attack","text":"PGD Topology Attack"}],"/PIQA":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/PIQA","text":"PIQA"}],"/PSE-library":[{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/PSE-library","text":"PSE library"}],"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture":[{"source":"/Week-Summary-021120-221120","target":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","text":"PSECMAC - A Novel Self-Organizing Multiresolution Associative Memory Architecture"}],"/Pan-Yaozhang":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Pan-Yaozhang","text":"Pan Yaozhang"}],"/Paper-Levenshtein-Transformer":[{"source":"/Week-Summary-170820-230820","target":"/Paper-Levenshtein-Transformer","text":"(Paper) Levenshtein Transformer"}],"/ParlAI":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ParlAI","text":"ParlAI"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ParlAI","text":"ParlAI"}],"/Part-of-Speech":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Part-of-Speech","text":"Part of Speech"}],"/Partial-Scoring":[{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Partial-Scoring","text":"Partial Scoring"}],"/Pascale-Fung":[{"source":"/Misinformation-has-High-Perplexity","target":"/Pascale-Fung","text":"Pascale Fung"}],"/Pasquale-Minervini":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Pasquale-Minervini","text":"Pasquale Minervini"}],"/Path":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Path","text":"Path"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Path","text":"Path"}],"/Paul-Michel":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Paul-Michel","text":"Paul Michel"}],"/Pawe%C5%82-Budzianowski":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Pawe%C5%82-Budzianowski","text":"Paweł Budzianowski"}],"/Pearl-Causal-Hierarchy":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Pearl-Causal-Hierarchy","text":"Pearl Causal Hierarchy"}],"/Pearsons-Correlation-Coefficient":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"}],"/Peer-Review":[{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Peer-Review","text":"Peer Review"}],"/Peio-Gonzalez":[{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Peio-Gonzalez","text":"Peio Gonzalez"}],"/Peng-Li":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Peng-Li","text":"Peng Li"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Peng-Li","text":"Peng Li"}],"/Peng-Qi":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Peng-Qi","text":"Peng Qi"}],"/Penn-Treebank":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Penn-Treebank","text":"Penn Treebank"}],"/Permutation-Invariant":[{"source":"/Equivariant-Functions","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Graph-Neural-Networks","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Permutation-Invariant","text":"Permutation Invariance"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Permutation-Invariant","text":"Permutation Invariant"}],"/PerronFrobenius-Theorem":[{"source":"/Eigenvector-Centrality","target":"/PerronFrobenius-Theorem","text":"Perron–Frobenius Theorem"}],"/PersonaChat":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/PersonaChat","text":"PersonaChat"}],"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too":[{"source":"/Week-Summary-060720-190720","target":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","text":"Personalizing Dialogue Agents - I have a dog, do you have pets too"}],"/Petar-Veli%C4%8Dkovi%C4%87":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Petar-Veli%C4%8Dkovi%C4%87","text":"Petar Veličković"}],"/Peter-Bell":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Peter-Bell","text":"Peter Bell"}],"/Peter-Lee":[{"source":"/Frontiers-in-Machine-Learning","target":"/Peter-Lee","text":"Peter Lee"}],"/Peter-Meer":[{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Peter-Meer","text":"Peter Meer"}],"/Philip-Pham":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Philip-Pham","text":"Philip Pham"}],"/Philipp-Koch":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Philipp-Koch","text":"Philipp Koch"}],"/Phillip-Keung":[{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Phillip-Keung","text":"Phillip Keung"}],"/Phoneme-Recoginition":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Phoneme-Recoginition","text":"Phoneme Recoginition"}],"/Pierre-Vandergheynst":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Pierre-Vandergheynst","text":"Pierre Vandergheynst"}],"/Pietro-Li%C3%B2":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pietro-Li%C3%B2","text":"Pietro Liò"}],"/Po-Han-Chi":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-Han-Chi","text":"Po-Han Chi"}],"/Po-chun-Hsu":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-chun-Hsu","text":"Po-chun Hsu"}],"/Point-Normal-Equations":[{"source":"/CZ1104-Lecture-6.2","target":"/Point-Normal-Equations","text":"Point Normal Equations"}],"/Point-Processing":[{"source":"/CE7491-Lecture-2","target":"/Point-Processing","text":"Point Processing"}],"/Point-Transformer":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Point-Transformer","text":"Point Transformer"}],"/Poisoning-Attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Poisoning-Attack","text":"Poisoning Attack"},{"source":"/Metattack","target":"/Poisoning-Attack","text":"Poisoning Attack"}],"/Poly-Filter":[{"source":"/Cheby-Filter","target":"/Poly-Filter","text":"Poly-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Poly-Filter","text":"Poly-Filter"}],"/Polynomial-time":[{"source":"/Graph-Neural-Networks","target":"/Polynomial-time","text":"Polynomial-time"}],"/Pooling":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Pooling","text":"Pooling"},{"source":"/CE7491-Lecture-4","target":"/Pooling","text":"Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Pooling","text":"Pooling"},{"source":"/Graph-Pooling","target":"/Pooling","text":"Pooling"},{"source":"/GraphSAGE-Filter","target":"/Pooling","text":"Pooling"}],"/Poor-Mans-BERT-Smaller-and-Faster-Transformer-Models":[{"source":"/Week-Summary-180520-240520","target":"/Poor-Mans-BERT-Smaller-and-Faster-Transformer-Models","text":"Poor Man's BERT - Smaller and Faster Transformer Models"}],"/Position-Non-Autoregressive-Transformers-PNAT":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"}],"/Positional-Encodings":[{"source":"/Graph-Positional-Encodings","target":"/Positional-Encodings","text":"Positional Encodings"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Positional-Encodings","text":"Positional Encodings"}],"/Prafulla-Dhariwal":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"}],"/Pranav-Shyam":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Pranav-Shyam","text":"Pranav Shyam"}],"/Precise-Fuzzy-Logic":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"}],"/Precision":[{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Precision","text":"Precision"}],"/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence":[{"source":"/Reading-List","target":"/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence","text":"Prediction Machines - The Simple Economics of Artificial Intelligence"}],"/Principal-Component-Analysis":[{"source":"/CE7429-Lecture-5","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"}],"/Principal-Neighbourhood-Aggregation":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Principal-Neighbourhood-Aggregation","text":"Principal Neighbourhood Aggregation"}],"/Principle-of-Incompatibility":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Principle-of-Incompatibility","text":"Principle of Incompatibility"}],"/Pro-GNN":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Pro-GNN","text":"Pro-GNN"}],"/Probabilistic-Modeling":[{"source":"/Graphite","target":"/Probabilistic-Modeling","text":"Probabilistic Modeling"}],"/Probing":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Probing","text":"Probing"}],"/Probing-Neural-Dialog-Models-for-Conversational-Understanding":[{"source":"/DailyDialog","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/Week-Summary-010620-210620","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/WikiText-103","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"}],"/Product-Quantization":[{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Product-Quantization","text":"Product Quantization"}],"/Product-T-norm":[{"source":"/T-norm","target":"/Product-T-norm","text":"Product T-norm"}],"/Projection-Matrix":[{"source":"/CZ1104-Lecture-7.1","target":"/Projection-Matrix","text":"Projection Matrix"}],"/Projection-Pursuit":[{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"}],"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation":[{"source":"/Graph-Reordering","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/Linearized-Graph","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/Masked-Graph-Modelling","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/PENMAN","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"}],"/Properties":[{"source":"/CE7491-Lecture-8","target":"/Properties","text":"Properties"}],"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training":[{"source":"/Week-Summary-010620-210620","target":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","text":"ProphetNet - Predicting Future N-gram for Sequence-to-Sequence Pre-training"}],"/Protein-Protein-Interaction-data":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Protein-Protein-Interaction-data","text":"Protein-Protein Interaction data"}],"/Pruning":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"}],"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture":[{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"}],"/Pubmed":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pubmed","text":"Pubmed"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Pubmed","text":"Pubmed"}],"/Pushmeet-Kohli":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Pushmeet-Kohli","text":"Pushmeet Kohli"}],"/Pyramid-Scene-Parsing-Network":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Pyramid-Scene-Parsing-Network","text":"Pyramid Scene Parsing Network"}],"/Pythagoras-Theorem":[{"source":"/CZ1104-Lecture-6.2","target":"/Pythagoras-Theorem","text":"Pythagoras Theorem"}],"/QM9":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/QM9","text":"QM9"}],"/QR-Factorization":[{"source":"/CZ1104-Lecture-6.3","target":"/QR-Factorization","text":"QR Factorization"}],"/Qian-Hangwei":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"}],"/Qifa-Ke":[{"source":"/Optimized-Product-Quantization","target":"/Qifa-Ke","text":"Qifa Ke"}],"/Qifan-Wang":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Qifan-Wang","text":"Qifan Wang"}],"/Qingli-Yan":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Qingli-Yan","text":"Qingli Yan"}],"/Qiu-Ran":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Qiu-Ran","text":"Qiu Ran"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Qiu-Ran","text":"Qiu Ran"}],"/Qiuqiang-Kong":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Qiuqiang-Kong","text":"Qiuqiang Kong"}],"/QuAC":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/QuAC","text":"QuAC"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/QuAC","text":"QuAC"}],"/Quan-Du":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Quan-Du","text":"Quan Du"}],"/Quantitative-Color-Specification":[{"source":"/CE7491-Lecture-3","target":"/Quantitative-Color-Specification","text":"Quantitative Color Specification"}],"/Quantization":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Quantization","text":"Quantization"}],"/Question-Answering":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/Research-Ideas","target":"/Question-Answering","text":"Question Answering"}],"/Question-Answering-Dialogue-Systems":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"}],"/Qun-Liu":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Qun-Liu","text":"Qun Liu"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Qun-Liu","text":"Qun Liu"}],"/Quora-Question-Pairs":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Quora-Question-Pairs","text":"Quora Question Pairs"}],"/R-Channing-Moore":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/R-Channing-Moore","text":"R Channing Moore"}],"/RACE":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/RACE","text":"RACE"}],"/REINFORCE":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/REINFORCE","text":"REINFORCE"}],"/RGCN-Filter":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RGCN-Filter","text":"RGCN-Filter"}],"/RIPPLe":[{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/RIPPLe","text":"RIPPLe"}],"/RL-S2V":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RL-S2V","text":"RL-S2V"}],"/ROUGE":[{"source":"/10-things-you-should-know-about-dialogue","target":"/ROUGE","text":"ROUGE"},{"source":"/Machine-Learning-Conversations","target":"/ROUGE","text":"ROUGE"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/ROUGE","text":"ROUGE"}],"/RUBER":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/RUBER","text":"RUBER"}],"/RW-based-Sampler":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/RW-based-Sampler","text":"RW-based Sampler"}],"/Radko-Mesiar":[{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Radko-Mesiar","text":"Radko Mesiar"}],"/Raluca-Ada-Popa":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"}],"/Ramaswamy-Palaniappan":[{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"}],"/Random-Forest":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Random-Forest","text":"Random Forest"}],"/Random-Walk":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/DeepWalk","target":"/Random-Walk","text":"Random Walk"},{"source":"/RW-based-Sampler","target":"/Random-Walk","text":"Random Walk"},{"source":"/Temporal-Random-Walk","target":"/Random-Walk","text":"Random Walk"},{"source":"/node2vec","target":"/Random-Walk","text":"Random Walk"}],"/Randomly-Assign-Train-and-Track":[{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"Randomly Assign, Train and Track"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"RATT"}],"/Raphael-Shu":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Raphael-Shu","text":"Raphael Shu"}],"/Ravenclaw-dialogue-system":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Ravenclaw-dialogue-system","text":"Ravenclaw dialogue system"}],"/Razvan-Pascanu":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Razvan-Pascanu","text":"Razvan Pascanu"}],"/ReLU":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"}],"/ReWatt":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/ReWatt","text":"ReWatt"}],"/Reading-Comprehension":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reading-Comprehension","text":"Reading Comprehension"}],"/Recall":[{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Recall","text":"Recall"}],"/Receiver-Operating-Characteristics-ROC":[{"source":"/CE7429-Lecture-10","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"},{"source":"/CE7429-Lecture-9","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"}],"/Receptive-Field":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"}],"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks":[{"source":"/Effective-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Filter-Damping","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Maximum-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"}],"/Recipes-for-building-an-open-domain-chatbot-Generative-BST":[{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"},{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"}],"/Reconstruction-Loss":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Graph-Auto-Encoders","target":"/Reconstruction-Loss","text":"Reconstruction Loss"}],"/Reconstructor":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/DeepWalk","target":"/Reconstructor","text":"Reconstructor"}],"/Recurrent-Neural-Networks":[{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Recurrent-Neural-Networks","text":"Recurrent layers"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Recurrent-Neural-Networks","text":"RNNs"}],"/Recursive-Graph-to-Graph-Transformer":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Recursive-Graph-to-Graph-Transformer","text":"Recursive Graph-to-Graph Transformer"}],"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement":[{"source":"/Recursive-Graph-to-Graph-Transformer","target":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","text":"Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency Parsing with Iterative Refinement"}],"/Rediet-Abebe":[{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"}],"/Reflexive-Anaphora":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reflexive-Anaphora","text":"Reflexive Anaphora"}],"/Regina-Barzilay":[{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Regina-Barzilay","text":"Regina Barzilay"}],"/Region-Proposal-Network":[{"source":"/CE7491-Lecture-6","target":"/Region-Proposal-Network","text":"Region Proposal Network"}],"/Reinforcement-Learning":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Meta-Reinforcement-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/RL-S2V","target":"/Reinforcement-Learning","text":"Reinforcement Learning"}],"/Relation-Extraction":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"}],"/Relational-inductive-biases-deep-learning-and-graph-networks":[{"source":"/Graph-Neural-Networks","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Inductive-Biases","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"}],"/Remi-Munos":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Remi-Munos","text":"Remi Munos"}],"/Representation-learning":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite","target":"/Representation-learning","text":"Representation learning"},{"source":"/Machine-Learning-Conversations","target":"/Representation-learning","text":"Representation learning"}],"/Resource-Description-Framework":[{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Resource-Description-Framework","text":"Resource Description Framework"}],"/Restaurants-8k":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"}],"/Rethinking-the-Value-of-Transformer-Components":[{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"},{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"}],"/Rewinding":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"}],"/Rewiring":[{"source":"/ReWatt","target":"/Rewiring","text":"Rewiring"}],"/Rewon-Child":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Rewon-Child","text":"Rewon Child"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Rewon-Child","text":"Rewon Child"}],"/Rich-Caruana":[{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"}],"/Richard-Socher":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Richard-Socher","text":"Richard Socher"}],"/RingGNNs":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/RingGNNs","text":"RingGNNs"}],"/RoBERTa":[{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"},{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"}],"/Rogerio-Feris":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Rogerio-Feris","text":"Rogerio Feris"}],"/Roll-in-Policy":[{"source":"/Paper-Levenshtein-Transformer","target":"/Roll-in-Policy","text":"Roll-in Policy"}],"/Romal-Thoppilan":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Romal-Thoppilan","text":"Romal Thoppilan"}],"/Ross-King":[{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Ross-King","text":"Ross King"}],"/RotatE":[{"source":"/Translational-Models","target":"/RotatE","text":"RotatE"}],"/Rudolf-Kruse":[{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Rudolf-Kruse","text":"Rudolf Kruse"}],"/Rui-Wang":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Rui-Wang","text":"Rui Wang"}],"/Rule-Based-Approaches":[{"source":"/CE7429-Lecture-12","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"}],"/Ruofei-Zhang":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ruofei-Zhang","text":"Ruofei Zhang"}],"/Ryan-Faulkner":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ryan-Faulkner","text":"Ryan Faulkner"}],"/Ryo-Masumura":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Ryo-Masumura","text":"Ryo Masumura"}],"/Ryuichiro-Higashinaka":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"}],"/SELU":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"}],"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS":[{"source":"/Graph-Convolutional-Network","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"},{"source":"/Spectral-Graph-Convolutions","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"}],"/SFX-restaurant":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/SFX-restaurant","text":"SFX restaurant"}],"/SNE":[{"source":"/Visualizing-Data-using-t-SNE","target":"/SNE","text":"SNE"}],"/SNIPS":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/SNIPS","text":"SNIPS"}],"/SPICE":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"}],"/SPIDEr":[{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/SPIDEr","text":"SPIDEr"}],"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues":[{"source":"/Week-Summary-220620-050720","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"},{"source":"/datasets","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"}],"/SQuADv2":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SQuADv2","text":"SQuADv2"}],"/SST-2":[{"source":"/Catch-the-Tails-of-BERT","target":"/SST-2","text":"SST-2"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/SST-2","text":"SST-2"}],"/Saizheng-Zhang":[{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Saizheng-Zhang","text":"Saizheng Zhang"}],"/Sam-McCandlish":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sam-McCandlish","text":"Sam McCandlish"}],"/Sample-and-Rank":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sample-and-Rank","text":"Sample-and-Rank"}],"/Samuel-Lipping":[{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Samuel-Lipping","text":"Samuel Lipping"}],"/Samuele-Cornell":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Samuele-Cornell","text":"Samuele Cornell"}],"/Sandhini-Agarwal":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sandhini-Agarwal","text":"Sandhini Agarwal"}],"/Sanghyun-Yoo":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Sanghyun-Yoo","text":"Sanghyun Yoo"}],"/Sanjiv-Kumar":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Sanjiv-Kumar","text":"Sanjiv Kumar"}],"/Sanket-Shah":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sanket-Shah","text":"Sanket Shah"}],"/Santiago-Ontanon":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Santiago-Ontanon","text":"Santiago Ontanon"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Santiago-Ontanon","text":"Santiago Ontanon"}],"/Sarthak-Garg":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Sarthak-Garg","text":"Sarthak Garg"}],"/Sascha-Hornauer":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Sascha-Hornauer","text":"Sascha Hornauer"}],"/Saurabh-Garg":[{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Saurabh-Garg","text":"Saurabh Garg"}],"/Saurabh-Saxena":[{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Saurabh-Saxena","text":"Saurabh Saxena"}],"/Saving-Lives-with-Interpretable-ML":[{"source":"/Frontiers-in-Machine-Learning","target":"/Saving-Lives-with-Interpretable-ML","text":"Saving Lives with Interpretable ML"}],"/Scaffolding":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Scaffolding","text":"Scaffolding"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Scaffolding","text":"Scaffolding"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Scaffolding","text":"Scaffolding"}],"/Scalabilty":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Scalabilty","text":"Scalabilty"}],"/ScenarioSA":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ScenarioSA","text":"ScenarioSA"}],"/Schema-Guided-Dialog-SGD":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Schema-Guided-Dialog-SGD","text":"Schema-Guided Dialog (SGD)"}],"/Scott-Gray":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Scott-Gray","text":"Scott Gray"}],"/Security-and-Machine-Learning":[{"source":"/Frontiers-in-Machine-Learning","target":"/Security-and-Machine-Learning","text":"Security and Machine Learning"}],"/Self-BLEU":[{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"}],"/Self-Organized-Feature-Mapping-SOFM":[{"source":"/CE7429-Lecture-7","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"},{"source":"/CE7429-Lecture-8","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"}],"/Self-Supervised-Learning":[{"source":"/CE7491-Lecture-7","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"}],"/Self-Tuning-Regulator":[{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"}],"/Semantic-Memory-Duration":[{"source":"/CE7429-Lecture-13","target":"/Semantic-Memory-Duration","text":"Semantic Memory Duration"}],"/Semantic-Role-Labeling":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"}],"/Semantic-Segmentation":[{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Semantic-Segmentation","text":"Semantic Segmentation"}],"/Semi-Autoregressive-Neural-Machine-Translation":[{"source":"/Week-Summary-170820-230820","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-180520-240520","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi Autoregressive Neural Machine Translation"}],"/Semi-Autoregressive-Transformer-SAT":[{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"}],"/Semi-Supervised":[{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Semi-Supervised","text":"Semi-Supervised"}],"/Sensible-and-Specificity-Average-SSA":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"}],"/Senso-motoric-Maps":[{"source":"/CE7429-Lecture-7","target":"/Senso-motoric-Maps","text":"Senso-motoric Maps"}],"/Sensory-Memory":[{"source":"/CE7429-Lecture-13","target":"/Sensory-Memory","text":"Sensory Memory"}],"/Sentence-BERT":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"}],"/Sentence-Subject-Detection":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Sentence-Subject-Detection","text":"Sentence Subject Detection"}],"/Sepformer":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Sepformer","text":"Sepformer"}],"/September-15th-2020":[{"source":"/CE7429-Lecture-11","target":"/September-15th-2020","text":"September 15th, 2020"}],"/September-16th-2020":[{"source":"/CE7491-Lecture-6","target":"/September-16th-2020","text":"September 16th, 2020"}],"/September-18th-2020":[{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/September-18th-2020","text":"September 18th, 2020"}],"/September-19th-2020":[{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/September-19th-2020","text":"September 19th, 2020"}],"/September-1st-2020":[{"source":"/CE7429-Lecture-8","target":"/September-1st-2020","text":"September 1st, 2020"}],"/September-20th-2020":[{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"}],"/September-21st-2020":[{"source":"/Week-Summary-210920-011120","target":"/September-21st-2020","text":"September 21st, 2020"}],"/September-22nd-2020":[{"source":"/CE7429-Lecture-13","target":"/September-22nd-2020","text":"September 22nd, 2020"}],"/September-23rd-2020":[{"source":"/CE7491-Lecture-7","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/September-23rd-2020","text":"September 23rd, 2020"}],"/September-24th-2020":[{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/September-24th-2020","text":"September 24th, 2020"}],"/September-25th-2020":[{"source":"/Color-Indexing","target":"/September-25th-2020","text":"September 25th, 2020"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/September-25th-2020","text":"September 25th, 2020"}],"/September-29th-2020":[{"source":"/Fuzzy-Sets-1965","target":"/September-29th-2020","text":"September 29th, 2020"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/September-29th-2020","text":"September 29th, 2020"}],"/September-2nd-2020":[{"source":"/CE7491-Lecture-4","target":"/September-2nd-2020","text":"September 2nd, 2020"}],"/September-4th-2020":[{"source":"/CE7429-Lecture-9","target":"/September-4th-2020","text":"September 4th, 2020"}],"/September-8th-2020":[{"source":"/CE7429-Lecture-10","target":"/September-8th-2020","text":"September 8th, 2020"}],"/September-9th-2020":[{"source":"/CE7491-Lecture-5","target":"/September-9th-2020","text":"September 9th, 2020"}],"/Sequence-Level-Interpolation":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Sequence-Level-Interpolation","text":"Sequence-Level Interpolation"}],"/Sequence-Refinement":[{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Sequence-Refinement","text":"Sequence Refinement"}],"/Shabnam-Ghaffarzadegan":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Shabnam-Ghaffarzadegan","text":"Shabnam Ghaffarzadegan"}],"/Shallow-To-Deep-SDT-Algorithm":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"}],"/Shallow-to-Deep-Training-for-Neural-Machine-Translation":[{"source":"/Week-Summary-301120-061220","target":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","text":"Shallow-to-Deep Training for Neural Machine Translation"}],"/Sharath-Adavanne":[{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Sharath-Adavanne","text":"Sharath Adavanne"}],"/Shawn-Hershey":[{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Shawn-Hershey","text":"Shawn Hershey"}],"/Sheng-Zhao":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Sheng-Zhao","text":"Sheng Zhao"}],"/Shengchen-Li":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Shengchen-Li","text":"Shengchen Li"}],"/Shikib-Mehri":[{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Shikib-Mehri","text":"Shikib Mehri"}],"/Shixiang-Gu":[{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Shixiang-Gu","text":"Shixiang Gu"}],"/Shiyu-Chang":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Shiyu-Chang","text":"Shiyu Chang"}],"/Shoichiro-Saito":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Shoichiro-Saito","text":"Shoichiro Saito"}],"/Short-Term-Memory":[{"source":"/CE7429-Lecture-13","target":"/Short-Term-Memory","text":"Short Term Memory"}],"/Short-Time-Fourier-Transform":[{"source":"/Sepformer","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"},{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"}],"/Shortest-Path":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Shortest-Path","text":"Shortest Path"}],"/Shu-wen-Yang":[{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Shu-wen-Yang","text":"Shu-wen Yang"}],"/Shucong-Zhang":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Shucong-Zhang","text":"Shucong Zhang"}],"/Shujian-Huang":[{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Shujian-Huang","text":"Shujian Huang"}],"/Shuzi-Niu":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Shuzi-Niu","text":"Shuzi Niu"}],"/Sigmoid":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Sigmoid","text":"Sigmoid"}],"/Signed-Graphs":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"}],"/Sijia-Liu":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Sijia-Liu","text":"Sijia Liu"}],"/Sim-Kai":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Sim-Kai","text":"Sim Kai"}],"/Similar":[{"source":"/CZ1104-Lecture-8.2","target":"/Similar","text":"Similar"}],"/Similarity-Invariant":[{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Invariant","text":"Similarity Invariant"}],"/Similarity-Transform":[{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Transform","text":"Similarity Transform"}],"/Simon-See":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"}],"/Simple-Graph":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"}],"/Simple-Recurrent-Unit-SRU":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simple-Recurrent-Unit-SRU","text":"Simple Recurrent Unit (SRU)"}],"/Simpler-Simple-Recurrent-Unit-SSRU":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"}],"/Singleton-Fuzzy-Rule-Based-Systems":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singleton-Fuzzy-Rule-Based-Systems","text":"Singleton Fuzzy Rule-Based Systems"}],"/Singular":[{"source":"/CZ1104-Lecture-8.1","target":"/Singular","text":"Singular"}],"/Singular-Value-Decomposition":[{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"}],"/Singular-Values":[{"source":"/CZ1104-Lecture-8.1","target":"/Singular-Values","text":"Singular Values"}],"/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR","text":"Singular value decomposition and QR with column pivoting methods (SVD-QR)"}],"/Sintiani-Teddy":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Sintiani-Teddy","text":"Sintiani Teddy"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Sintiani-Teddy","text":"Sintiani Teddy"}],"/Siqi-Sun":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Siqi-Sun","text":"Siqi Sun"}],"/Sivaraman-Balakrishnan":[{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Sivaraman-Balakrishnan","text":"Sivaraman Balakrishnan"}],"/Slot-Detection":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Slot-Detection","text":"Slot Detection"}],"/Small-World-Graphs":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Small-World-Graphs","text":"Small World Graphs"}],"/Sobel-Gradient":[{"source":"/CE7491-Lecture-3","target":"/Sobel-Gradient","text":"Sobel Gradient"}],"/Soft-Attention":[{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Soft-Attention","text":"Soft Attention"}],"/Softmax":[{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/Entity-GCN","target":"/Softmax","text":"Softmax"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Softmax","text":"Softmax"},{"source":"/Negative-Sampling","target":"/Softmax","text":"Softmax"},{"source":"/Week-Summary-180520-240520","target":"/Softmax","text":"Softmax"},{"source":"/diffpool","target":"/Softmax","text":"Softmax"}],"/Solon-Barocas":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Solon-Barocas","text":"Solon Barocas"}],"/Somatosensoric-Maps":[{"source":"/CE7429-Lecture-7","target":"/Somatosensoric-Maps","text":"Somatosensoric Maps"}],"/Sophie-Rosset":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Sophie-Rosset","text":"Sophie Rosset"}],"/SouYong-Jin":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/SouYong-Jin","text":"SouYong Jin"}],"/Span":[{"source":"/CZ1104-Lecture-6.3","target":"/Span","text":"Span"}],"/Spanning-Tree":[{"source":"/Laplacian-Matrix","target":"/Spanning-Tree","text":"Spanning Tree"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Spanning-Tree","text":"Spanning Tree"}],"/Spatial-Filtering":[{"source":"/CE7491-Lecture-2","target":"/Spatial-Filtering","text":"Spatial Filtering"}],"/Spatial-Graph-Filtering":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"}],"/Speaker-Sensitive-Response-Evaluation-Model-SSREM":[{"source":"/Week-Summary-010620-210620","target":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","text":"Speaker Sensitive Response Evaluation Model (SSREM)"}],"/Spectral-Decomposition":[{"source":"/CZ1104-Lecture-8.1","target":"/Spectral-Decomposition","text":"Spectral Decomposition"}],"/Spectral-Graph":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Spectral-Graph","text":"Spectral Graph"},{"source":"/Spectral-Graph-Convolutions","target":"/Spectral-Graph","text":"Spectral Graph"}],"/Spectral-Graph-Convolutions":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Spectral-Graph-Convolutions","text":"Spectral Graph Convolutions"}],"/Spectral-Graph-Filtering":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"}],"/Spectral-Graph-Theory":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Graph-Positional-Encodings","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"}],"/Spectral-Power-Distribution":[{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"}],"/Spectral-Theorem":[{"source":"/CZ1104-Lecture-8.2","target":"/Spectral-Theorem","text":"Spectral Theorem"},{"source":"/Spectral-Graph-Theory","target":"/Spectral-Theorem","text":"Spectral Theorem"}],"/Spectrum":[{"source":"/CZ1104-Lecture-8.1","target":"/Spectrum","text":"Spectrum"}],"/Speech-Recognition":[{"source":"/Automated-Audio-Captioning","target":"/Speech-Recognition","text":"Speech Recognition"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Speech-Recognition","text":"Speech Recognition"}],"/Speech-Separation":[{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Speech-Separation","text":"Speech Separation"}],"/Speech-XLNet":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Speech-XLNet","text":"Speech-XLNet"}],"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions":[{"source":"/Adaptive-Mean-Margin","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"},{"source":"/Spoken-Moments-dataset","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"}],"/Spoken-Moments-dataset":[{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Spoken-Moments-dataset","text":"Spoken Moments dataset"}],"/Srinadh-Bhojanapalli":[{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Srinadh-Bhojanapalli","text":"Srinadh Bhojanapalli"}],"/Standard-Basis":[{"source":"/CZ1104-Lecture-6.2","target":"/Standard-Basis","text":"Standard Basis"}],"/Starplots":[{"source":"/CE7429-Lecture-4","target":"/Starplots","text":"Starplots"}],"/Static":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Static","text":"Static"}],"/Stavros-Volos":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Stavros-Volos","text":"Stavros Volos"}],"/Stefan-Ultes":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Stefan-Ultes","text":"Stefan Ultes"}],"/Stefano-Ermon":[{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Stefano-Ermon","text":"Stefano Ermon"}],"/Steffen-Schneider":[{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Steffen-Schneider","text":"Steffen Schneider"}],"/Stephen-Casper":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stephen-Casper","text":"Stephen Casper"}],"/Stephen-Roller":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Stephen-Roller","text":"Stephen Roller"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Stephen-Roller","text":"Stephen Roller"}],"/Steve-Renals":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Steve-Renals","text":"Steve Renals"}],"/Stochastic-Gradient-Descent":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Stochastic-Gradient-Descent","text":"SGD"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Stochastic-Gradient-Descent","text":"Stochastic Gradient Descent"}],"/Structural-Message-Passing-Networks":[{"source":"/Graph-Positional-Encodings","target":"/Structural-Message-Passing-Networks","text":"Structural Message-Passing Networks"}],"/Structural-Role":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Structural-Role","text":"Structural Role"}],"/Stuart-Shieber":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stuart-Shieber","text":"Stuart Shieber"}],"/Su-Lin-Blodgett":[{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Su-Lin-Blodgett","text":"Su Lin Blodgett"}],"/SubTle-Corpus":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SubTle-Corpus","text":"SubTle Corpus"}],"/Subgraph":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Subgraph","text":"Subgraph"},{"source":"/Subgraph-wise-Sampling","target":"/Subgraph","text":"Subgraph"}],"/Subgraph-wise-Sampling":[{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Edge-based-Sampler","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"}],"/Subject-Predicate-Agreement":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Predicate-Agreement","text":"Subject-Predicate Agreement"}],"/Subject-Vector-Machines":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"}],"/Subject-Verb-Agreement":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"}],"/Subtractive-Color-Mixing":[{"source":"/CE7491-Lecture-3","target":"/Subtractive-Color-Mixing","text":"Subtractive Color Mixing"}],"/Suchi-Saria":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"}],"/Sufeng-Duan":[{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Sufeng-Duan","text":"Sufeng Duan"}],"/Sunayana-Sitaram":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sunayana-Sitaram","text":"Sunayana Sitaram"}],"/Super-Resolution":[{"source":"/CE7491-Lecture-6","target":"/Super-Resolution","text":"Super-Resolution"},{"source":"/CE7491-Lecture-7","target":"/Super-Resolution","text":"Super-Resolution"}],"/SuperGLUE-Benchmark":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SuperGLUE-Benchmark","text":"SuperGLUE Benchmark"}],"/Survey-on-Evaluation-Methods-for-Dialogue-Systems":[{"source":"/Week-Summary-010620-210620","target":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","text":"Survey on Evaluation Methods for Dialogue Systems"}],"/Susan-Athey":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"}],"/Susan-Dumais":[{"source":"/Machine-Learning-Conversations","target":"/Susan-Dumais","text":"Susan Dumais"}],"/Sven-Schlarb":[{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Sven-Schlarb","text":"Sven Schlarb"}],"/SwitchBoard":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/SwitchBoard","text":"SwitchBoard"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SwitchBoard","text":"SwitchBoard"}],"/Switchable-Normalization":[{"source":"/CE7491-Lecture-5","target":"/Switchable-Normalization","text":"Switchable Normalization"}],"/Switchboard-Coherence":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Research-Ideas","target":"/Switchboard-Coherence","text":"Switchboard Coherence"}],"/Symmetric":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Symmetric","text":"Symmetry"},{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/Laplacian-Matrix","target":"/Symmetric","text":"Symmetric"}],"/Syntax-GNN":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-GNN","text":"Syntax-GNN"}],"/Syntax-Tree":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-Tree","text":"Syntax Tree"}],"/T-conorm":[{"source":"/Fuzzy-Set","target":"/T-conorm","text":"T-conorm"}],"/T-norm":[{"source":"/Fuzzy-Set","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"}],"/TAC-Knowledge-Base-Population":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/TAC-Knowledge-Base-Population","text":"TAC Knowledge Base Population"}],"/TACRED":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/TACRED","text":"TACRED"}],"/TALNet":[{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/TALNet","text":"TALNet"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/TALNet","text":"TALNet"}],"/TAU-Urban-Acoustic-Scenes-2018":[{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/TAU-Urban-Acoustic-Scenes-2018","text":"TAU Urban Acoustic Scenes 2018"}],"/TER":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"}],"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS":[{"source":"/Audio-Grounding-dataset","target":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","text":"TEXT-TO-AUDIO GROUNDING - BUILDING CORRESPONDENCE BETWEEN CAPTIONS AND SOUND EVENTS"}],"/TF-IDF":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Misinformation-has-High-Perplexity","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Research-Ideas","target":"/TF-IDF","text":"TF-IDF"}],"/TIMIT-dataset":[{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/TIMIT-dataset","text":"TIMIT dataset"}],"/TRACKE":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"}],"/TREC":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/TREC","text":"TREC"}],"/TUT-acoustic-scenes-2016":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/TUT-acoustic-scenes-2016","text":"TUT acoustic scenes 2016"}],"/Tacit-Knowledge":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Tacit-Knowledge","text":"Tacit Knowledge"}],"/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs":[{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs","text":"Takagi-Sugeno-Kang-type Fuzzy Rule-Based Systems (TSK-type FRBSs)"}],"/Takeaways":[{"source":"/July-3rd-2020","target":"/Takeaways","text":"Takeaway(s)"}],"/Tam%C3%A1s-Szab%C3%B3":[{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Tam%C3%A1s-Szab%C3%B3","text":"Tamás Szabó"}],"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics":[{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"}],"/Tao-Qin":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tao-Qin","text":"Tao Qin"}],"/Task-Oriented-Dialogue-Systems":[{"source":"/10-things-you-should-know-about-dialogue","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Machine-Learning-Conversations","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"}],"/Task-Regularization":[{"source":"/CE7491-Lecture-8","target":"/Task-Regularization","text":"Task Regularization"}],"/Task-Success-Rate":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"}],"/Tassadaq-Hussain":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Tassadaq-Hussain","text":"Tassadaq Hussain"}],"/Telecoupling":[{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Telecoupling","text":"Telecoupling"}],"/Temporal-Invariant":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Temporal-Invariant","text":"Temporal Invariant"}],"/Temporal-Neighbors":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Neighbors","text":"Temporal Neighbors"}],"/Temporal-Random-Walk":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Random-Walk","text":"Temporal Random Walk"}],"/Tetsuro-Takahashi":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"}],"/Text-Classification":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Text-Classification","text":"Text Classification"}],"/Text-To-Text-Transfer-Transformer":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Text-To-Text-Transfer-Transformer","text":"Text-To-Text Transfer Transformer"}],"/Texture-Synthesis-Using-Convolutional-Neural-Networks":[{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","text":"Texture Synthesis Using Convolutional Neural Networks"}],"/Texture-Synthesis-by-Non-parametric-Sampling":[{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-by-Non-parametric-Sampling","text":"Texture Synthesis by Non-parametric Sampling"}],"/Thanh-Ngo":[{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Thanh-Ngo","text":"Thanh Ngo"}],"/The-Book-of-Why-The-New-Science-of-Cause-and-Effect":[{"source":"/Reading-List","target":"/The-Book-of-Why-The-New-Science-of-Cause-and-Effect","text":"The Book of Why - The New Science of Cause and Effect"}],"/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning":[{"source":"/Compositional-Rule-of-Inference","target":"/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning","text":"The Concept of a Linguistic Variable and its Application to Approximate Reasoning"}],"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics":[{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Research-Ideas","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"}],"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks":[{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"}],"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models":[{"source":"/Week-Summary-250520-310520","target":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","text":"The Unreasonable Volatility of Neural Machine Translation Models"}],"/Thomas-Dietterich":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"}],"/Thomas-Lidy":[{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Thomas-Lidy","text":"Thomas Lidy"}],"/Tianlong-Chen":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Tianlong-Chen","text":"Tianlong Chen"}],"/Tie-Yan-Liu":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"}],"/Tien-Ly":[{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Tien-Ly","text":"Tien Ly"}],"/Tiezheng-Ge":[{"source":"/Optimized-Product-Quantization","target":"/Tiezheng-Ge","text":"Tiezheng Ge"}],"/Time2Vec":[{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Time2Vec","text":"Time2Vec"}],"/Timothy-Baldwin":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Timothy-Baldwin","text":"Timothy Baldwin"}],"/Tom-Henighan":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Tom-Henighan","text":"Tom Henighan"}],"/Tong-Xiao":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Tong-Xiao","text":"Tong Xiao"}],"/Tovly-Deutsch":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Tovly-Deutsch","text":"Tovly Deutsch"}],"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset":[{"source":"/Week-Summary-060720-190720","target":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","text":"Towards Empathetic Open-domain Conversation Models - a New Benchmark and Dataset"}],"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols":[{"source":"/Week-Summary-220620-050720","target":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","text":"Towards Unified Dialogue System Evaluation - A Comprehensive Analysis of Current Evaluation Protocols"}],"/Towards-a-Human-like-Open-Domain-Chatbot":[{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"},{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"}],"/Trace":[{"source":"/CZ1104-Lecture-7.2","target":"/Trace","text":"Trace"}],"/Trail":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Trail","text":"Trail"}],"/TransE":[{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/TransE","text":"TransE"}],"/Transfer-Learning":[{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/Research-Ideas","target":"/Transfer-Learning","text":"Transfer Learning"}],"/Transformer":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Transformer","text":"Transformer"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Transformer","text":"Transformer"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Break-into-Natural-Language-Processing","target":"/Transformer","text":"Transformer"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Transformer","text":"Transformer"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Transformer","text":"Transformer"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Transformer","text":"Transformer"},{"source":"/GRaph-Aware-Transformer","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Positional-Encodings","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Transformer","text":"Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Transformer","text":"Transformer"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Transformer","text":"Transformer"},{"source":"/Syntax-GNN","target":"/Transformer","text":"Transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Transformer","text":"Transformer"},{"source":"/WaveTransformer","target":"/Transformer","text":"Transformer"}],"/Transformer-XL":[{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Week-Summary-200720-020820","target":"/Transformer-XL","text":"Transformer-XL"}],"/Translation-Invariant":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Translation-Invariant","text":"Translation Invariant"}],"/Translational-Models":[{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Translational-Models","text":"Translational Models#Knowledge Graph Embeddings and Explainable AI"}],"/Transportability":[{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Transportability","text":"Transportability"}],"/Tree-LSTM":[{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Tree-LSTM","text":"Tree-LSTM"},{"source":"/Graph-LSTM","target":"/Tree-LSTM","text":"Tree-LSTM"}],"/Trevor-Cohn":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Trevor-Cohn","text":"Trevor Cohn"}],"/TriPy":[{"source":"/10-things-you-should-know-about-dialogue","target":"/TriPy","text":"TriPy"}],"/Triplet-Loss":[{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Triplet-Loss","text":"Triplet Loss"}],"/Tristimulus-Color-Theory":[{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Color-Theory","text":"Tristimulus Color Theory"}],"/Tristimulus-Values":[{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Values","text":"Tristimulus Values"}],"/TriviaQA":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/TriviaQA","text":"TriviaQA"}],"/Trusted-Execution-Environments":[{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Trusted-Execution-Environments","text":"Trusted Execution Environments"}],"/Tsung-Hsien-Wen":[{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Tsung-Hsien-Wen","text":"Tsung-Hsien Wen"}],"/Tuomas-Virtanen":[{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"}],"/Turab-Iqbal":[{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Turab-Iqbal","text":"Turab Iqbal"}],"/Turing-NLG":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Turing-NLG","text":"Turing-NLG"}],"/Twitter-Conversation-Corpus-Bak-and-Oh-2019":[{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Twitter-Conversation-Corpus-Bak-and-Oh-2019","text":"Twitter Conversation Corpus (Bak and Oh, 2019)"}],"/Type-I-Errors":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-I-Errors","text":"Type I Errors"}],"/Type-II-Errors":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-II-Errors","text":"Type II Errors"}],"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"}],"/UNI-SNE":[{"source":"/Visualizing-Data-using-t-SNE","target":"/UNI-SNE","text":"UNI-SNE"}],"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION":[{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","text":"UNSUPERVISED DISCRIMINATIVE LEARNING OF SOUNDS FOR AUDIO EVENT CLASSIFICATION"}],"/USPTO":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/USPTO","text":"USPTO"}],"/Ubuntu-Dialogue-Corpus":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Ubuntu-Dialogue-Corpus","text":"Ubuntu Dialogue Corpus"}],"/Undirected":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Undirected","text":"Undirected"},{"source":"/Graph-Convolutional-Network","target":"/Undirected","text":"Undirected"}],"/Unit-Vector":[{"source":"/CZ1104-Lecture-6.1","target":"/Unit-Vector","text":"Unit Vector"}],"/Universal-Approximation-Theorem":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"},{"source":"/Graph-Isomorphism-Networks","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"}],"/Universal-Dependency-Treebanks":[{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Universal-Dependency-Treebanks","text":"Universal Dependency Treebanks"}],"/Unlikelihood-Training":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"}],"/Unsigned":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Unsigned","text":"Unsigned"}],"/Unsupervised":[{"source":"/Generative-Pretraining-from-Pixels","target":"/Unsupervised","text":"Unsupervised"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Unsupervised","text":"Unsupervised"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Unsupervised","text":"Unsupervised"}],"/Unsupervised-Discriminative-Learning-of-Sounds":[{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Unsupervised-Discriminative-Learning-of-Sounds","text":"Unsupervised Discriminative Learning of Sounds"}],"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT":[{"source":"/Week-Summary-220620-050720","target":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","text":"Unsupervised Evaluation of Interactive Dialog with DialoGPT"}],"/UrbanSound8k":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/UrbanSound8k","text":"UrbanSound8k"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/UrbanSound8k","text":"UrbanSound8k"}],"/Uri-Shaham":[{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Uri-Shaham","text":"Uri Shaham"}],"/VGG19-Architecture":[{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/VGG19-Architecture","text":"VGG19 (Architecture)"}],"/VGGish":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/VGGish","text":"VGGish"},{"source":"/TRACKE","target":"/VGGish","text":"VGGish"}],"/Vamsi-Krishna-Ithapu":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Vamsi-Krishna-Ithapu","text":"Vamsi Krishna Ithapu"}],"/Variational-Auto-Encoder":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-VAE","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"}],"/Variational-Deep-Reinforcement-Learning-VariBad":[{"source":"/Machine-Learning-Conversations","target":"/Variational-Deep-Reinforcement-Learning-VariBad","text":"Variational Deep Reinforcement Learning (VariBad)"}],"/Vector-Quantization":[{"source":"/Optimized-Product-Quantization","target":"/Vector-Quantization","text":"Vector Quantization"}],"/Vicinal-Risk-Minimization":[{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Vicinal-Risk-Minimization","text":"Vicinal Risk Minimization"}],"/Victor-Bapst":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victor-Bapst","text":"Victor Bapst"}],"/Victoria-Langston":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victoria-Langston","text":"Victoria Langston"}],"/Vikas-Joshi":[{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Vikas-Joshi","text":"Vikas Joshi"}],"/Vinicius-Zambaldi":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Vinicius-Zambaldi","text":"Vinicius Zambaldi"}],"/Virtual-Reality":[{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Virtual-Reality","text":"Virtual Reality"}],"/Visualizing-Data-using-t-SNE":[{"source":"/Week-Summary-060720-190720","target":"/Visualizing-Data-using-t-SNE","text":"Visualizing Data using t-SNE"}],"/Voted-Appropriateness":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Voted-Appropriateness","text":"Voted Appropriateness"}],"/WAT2017-Small-NMT-En-Ja":[{"source":"/Paper-Levenshtein-Transformer","target":"/WAT2017-Small-NMT-En-Ja","text":"WAT2017 Small-NMT En-Ja"}],"/WEANet-SUSTAIN":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/WEANet-SUSTAIN","text":"WEANet-SUSTAIN"}],"/WIKIHOP-dataset":[{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/WIKIHOP-dataset","text":"WIKIHOP dataset"}],"/WMT":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/WMT","text":"WMT"}],"/WMT14-De-En":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/WMT","target":"/WMT14-De-En","text":"WMT14 De-En"}],"/WMT14-En-De":[{"source":"/Paper-Levenshtein-Transformer","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/WMT","target":"/WMT14-En-De","text":"WMT14 En-De"}],"/WMT14-En-Fr":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"}],"/WMT14-Fr-En":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"}],"/WMT16-De-En":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/WMT","target":"/WMT16-De-En","text":"WMT16 De-En"}],"/WMT16-En-De":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/WMT","target":"/WMT16-En-De","text":"WMT16 En-De"}],"/WMT16-En-Ro":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"}],"/WMT16-Ro-En":[{"source":"/Paper-Levenshtein-Transformer","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"}],"/WMT17-Automatic-Post-Editing-APE-Task-En-De":[{"source":"/Paper-Levenshtein-Transformer","target":"/WMT17-Automatic-Post-Editing-APE-Task-En-De","text":"WMT17 Automatic Post-Editing (APE) Task En-De"}],"/WMT17-En-De":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/WMT","target":"/WMT17-En-De","text":"WMT17 En-De"}],"/WMT17-En-Zh":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-En-Zh","text":"WMT17 En-Zh"}],"/WMT17-Zh-En":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"}],"/WMT18-En-De":[{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT18-En-De","text":"WMT18 En-De"},{"source":"/WMT","target":"/WMT18-En-De","text":"WMT18 En-De"}],"/WMT19-En-De":[{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/WMT19-En-De","text":"WMT19 En-De"}],"/WSJ":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/WSJ","text":"WSJ"}],"/Walk":[{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Walk","text":"Walk"},{"source":"/Path","target":"/Walk","text":"Walk"},{"source":"/Trail","target":"/Walk","text":"Walk"}],"/Wall-Street-Journal":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Wall-Street-Journal","text":"Wall Street Journal"}],"/WaveNet":[{"source":"/WaveTransformer","target":"/WaveNet","text":"WaveNet"}],"/WaveTransformer":[{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/WaveTransformer","text":"WaveTransformer"}],"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information":[{"source":"/WaveTransformer","target":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","text":"WaveTransformer - A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information"}],"/Weak-Agreement":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"}],"/WebNLG":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"}],"/Weighted-Kappa-Agreement":[{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Weighted-Kappa-Agreement","text":"Weighted Kappa Agreement"}],"/Weinan-Zhang":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Weinan-Zhang","text":"Weinan Zhang"}],"/Weisfieler-Lehman-test":[{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"k-WL tests"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/Graph-Isomorphism","target":"/Weisfieler-Lehman-test","text":"Weisfieler-Lehman test"}],"/Weizhen-Qi":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Weizhen-Qi","text":"Weizhen Qi"}],"/Wenjie-Li":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Wenjie-Li","text":"Wenjie Li"}],"/Wenwu-Wang":[{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Wenwu-Wang","text":"Wenwu Wang"}],"/Wenxuan-Wang":[{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Wenxuan-Wang","text":"Wenxuan Wang"}],"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP":[{"source":"/Week-Summary-231120-291120","target":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","text":"What Can We Do to Improve Peer Review in NLP"}],"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers":[{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"},{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"}],"/White-box-attack":[{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"}],"/WiC":[{"source":"/Catch-the-Tails-of-BERT","target":"/WiC","text":"WiC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WiC","text":"WiC"}],"/Widrow-Hoff":[{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Widrow-Hoff","text":"Widrow-Hoff"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Widrow-Hoff","text":"Widrow-Hoff"}],"/WikiText-103":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/WikiText-103","text":"WikiText-103"}],"/Wikidata":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/Match-and-Map","target":"/Wikidata","text":"Wikidata"}],"/William-Chan":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/William-Chan","text":"William Chan"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/William-Chan","text":"William Chan"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/William-Chan","text":"William Chan"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/William-Chan","text":"William Chan"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/William-Chan","text":"William Chan"}],"/William-Hamilton":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/William-Hamilton","text":"William Hamilton"}],"/Winograd":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winograd","text":"Winograd"},{"source":"/Winograd-NLI","target":"/Winograd","text":"Winograd"}],"/Winograd-NLI":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Winograd-NLI","text":"Winograd NLI"}],"/Winogrande":[{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Winograd-NLI","target":"/Winogrande","text":"Winogrande"}],"/Within-Dimension-Neighbor":[{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Within-Dimension-Neighbor","text":"Within-Dimension Neighbor"}],"/Wizard-of-Wikipedia":[{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"}],"/Wolfgang-Wechler":[{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Wolfgang-Wechler","text":"Wolfgang Wechler"}],"/Word-Error-Rate-WER":[{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"}],"/Word-Sense-Disambiguation":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Word-Sense-Disambiguation","text":"Word Sense Disambiguation"}],"/Working-Memory-Model":[{"source":"/CE7429-Lecture-13","target":"/Working-Memory-Model","text":"Working Memory Model"}],"/XLNet":[{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"}],"/Xavier-Bresson":[{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Xavier-Bresson","text":"Xavier Bresson"}],"/Xi-Shao":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xi-Shao","text":"Xi Shao"}],"/Xian-Li":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xian-Li","text":"Xian Li"}],"/Xiang-Gao":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Xiang-Gao","text":"Xiang Gao"}],"/Xiao-Liu":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Xiao-Liu","text":"Xiao Liu"}],"/Xiaofeng-Hong":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Xiaofeng-Hong","text":"Xiaofeng Hong"}],"/Xiaolei-Zhang":[{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Xiaolei-Zhang","text":"Xiaolei Zhang"}],"/Xiaoyu-Shen":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Xiaoyu-Shen","text":"Xiaoyu Shen"}],"/XinXin-Zhu":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/XinXin-Zhu","text":"XinXin Zhu"}],"/Xingchen-Song":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Xingchen-Song","text":"Xingchen Song"}],"/Xingjian-He":[{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Xingjian-He","text":"Xingjian He"}],"/Xu-Tan":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Xu-Tan","text":"Xu Tan"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Xu-Tan","text":"Xu Tan"}],"/Xuan-Zhang":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xuan-Zhang","text":"Xuan Zhang"}],"/Xuenan-Xu":[{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Xuenan-Xu","text":"Xuenan Xu"}],"/Xuezhe-Ma":[{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xuezhe-Ma","text":"Xuezhe Ma"}],"/Y-Lan-Boureau":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"}],"/Yang-Zhang":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Yang-Zhang","text":"Yang Zhang"}],"/Yankai-Lin":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Yankai-Lin","text":"Yankai Lin"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yankai-Lin","text":"Yankai Lin"}],"/Yanran-Li":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Yanran-Li","text":"Yanran Li"}],"/Yao-Ma":[{"source":"/Deep-Learning-on-Graphs-book","target":"/Yao-Ma","text":"Yao Ma"}],"/Yap-Kim-Hui":[{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Yap-Kim-Hui","text":"Yap Kim Hui"}],"/Yasunori-Ohishi":[{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"}],"/Yejin-Bang":[{"source":"/Misinformation-has-High-Perplexity","target":"/Yejin-Bang","text":"Yejin Bang"}],"/Yen-Chun-Chen":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yen-Chun-Chen","text":"Yen-Chun Chen"}],"/Yeyun-Gong":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yeyun-Gong","text":"Yeyun Gong"}],"/Yi-Hsiu-Liao":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Hsiu-Liao","text":"Yi-Hsiu Liao"}],"/Yi-Ren":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Yi-Ren","text":"Yi Ren"}],"/Yi-Te-Hsu":[{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Te-Hsu","text":"Yi-Te Hsu"}],"/YiSi-0":[{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"}],"/YiSi-1":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"}],"/YiSi-2":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"}],"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources":[{"source":"/Week-Summary-010620-210620","target":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","text":"YiSi - a Unified Semantic MT Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources"}],"/Yifeng-Lu":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Yifeng-Lu","text":"Yifeng Lu"}],"/Yiheng-Huang":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Yiheng-Huang","text":"Yiheng Huang"}],"/Yin-Cao":[{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Yin-Cao","text":"Yin Cao"}],"/Yinhan-Liu":[{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Yinhan-Liu","text":"Yinhan Liu"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Yinhan-Liu","text":"Yinhan Liu"}],"/Yizhe-Zhang":[{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yizhe-Zhang","text":"Yizhe Zhang"}],"/Yonatan-Belinkov":[{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Yonatan-Belinkov","text":"Yonatan Belinkov"}],"/Yong-Yu":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yong-Yu","text":"Yong Yu"}],"/Yongjing-Yin":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Yongjing-Yin","text":"Yongjing Yin"}],"/Yoshua-Bengio":[{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Yoshua-Bengio","text":"Yoshua Bengio"}],"/Younes-Bensouda-Mourri":[{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"},{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"}],"/Young-Sang-Choi":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Sang-Choi","text":"Young Sang Choi"}],"/Young-Seok-Kim":[{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Seok-Kim","text":"Young-Seok Kim"}],"/Yu-Bao":[{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yu-Bao","text":"Yu Bao"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Yu-Bao","text":"Yu Bao"}],"/Yu-Yan":[{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yu-Yan","text":"Yu Yan"}],"/Yue-Lang":[{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Yue-Lang","text":"Yue Lang"}],"/Yuexian-Zou":[{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Yuexian-Zou","text":"Yuexian Zou"}],"/Yufan-Jiang":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Yufan-Jiang","text":"Yufan Jiang"}],"/Yuhao-Zhang":[{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Yuhao-Zhang","text":"Yuhao Zhang"}],"/Yuiko-Tsunomori":[{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"}],"/Yujia-Li":[{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Yujia-Li","text":"Yujia Li"}],"/Yuka-Kobayashi":[{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Yuka-Kobayashi","text":"Yuka Kobayashi"}],"/Yuma-Koizumi":[{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yuma-Koizumi","text":"Yuma Koizumi"}],"/Yun-Wang":[{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Yun-Wang","text":"Yun Wang"}],"/Yusong-Wu":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Yusong-Wu","text":"Yusong Wu"}],"/Zelin-Zhou":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zelin-Zhou","text":"Zelin Zhou"}],"/Zeyu-Xie":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zeyu-Xie","text":"Zeyu Xie"}],"/Zhangyang-Wang":[{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Zhangyang-Wang","text":"Zhangyang Wang"}],"/Zhaohan-Daniel-Guo":[{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Zhaohan-Daniel-Guo","text":"Zhaohan Daniel Guo"}],"/Zhaopeng-Tu":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"}],"/Zhengyuan-Yang":[{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Zhengyuan-Yang","text":"Zhengyuan Yang"}],"/Zhiling-Zhang":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zhiling-Zhang","text":"Zhiling Zhang"}],"/Zhiyong-Wu":[{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Zhiyong-Wu","text":"Zhiyong Wu"}],"/Zhou-Yu":[{"source":"/July-3rd-2020","target":"/Zhou-Yu","text":"Zhou Yu"}],"/Zhou-Zhao":[{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Zhou-Zhao","text":"Zhou Zhao"}],"/Zhuangzhuang-Liu":[{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Zhuangzhuang-Liu","text":"Zhuangzhuang Liu"}],"/Zi-Yang":[{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Zi-Yang","text":"Zi Yang"}],"/Ziqiang-Cao":[{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Ziqiang-Cao","text":"Ziqiang Cao"}],"/Ziyang-Luo":[{"source":"/Catch-the-Tails-of-BERT","target":"/Ziyang-Luo","text":"Ziyang Luo"}],"/Ziyang-Wang":[{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Ziyang-Wang","text":"Ziyang Wang"}],"/Ziyue-Wang":[{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Ziyue-Wang","text":"Ziyue Wang"}],"/ablation":[{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/ablation","text":"ablation"}],"/adversarial-attacks":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Security-and-Machine-Learning","target":"/adversarial-attacks","text":"adversarial attacks"}],"/bAbI":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/bAbI","text":"bAbI"}],"/bi-level-optimization":[{"source":"/Metattack","target":"/bi-level-optimization","text":"bi-level optimization"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/bi-level-optimization","text":"bi-level optimization"}],"/bottleneck-issues":[{"source":"/Machine-Learning-Conversations","target":"/bottleneck-issues","text":"bottleneck issues"}],"/chrF":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/chrF","text":"chrF"}],"/clustering-coefficient":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/clustering-coefficient","text":"clustering coefficient"}],"/cosine-similarity":[{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/cosine-similarity","text":"cosine similarity"},{"source":"/Catch-the-Tails-of-BERT","target":"/cosine-similarity","text":"cosine similarity"}],"/cross-attention":[{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"}],"/cross-entropy":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/cross-entropy","text":"cross entropy"},{"source":"/Machine-Learning-Conversations","target":"/cross-entropy","text":"cross entropy"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/cross-entropy","text":"cross entropy"}],"/cross-validation":[{"source":"/CE7429-Lecture-9","target":"/cross-validation","text":"cross validation"},{"source":"/Machine-Learning-Conversations","target":"/cross-validation","text":"cross validation"}],"/datasets":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/datasets","text":"datasets"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/datasets","text":"datasets"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/datasets","text":"datasets"}],"/diffpool":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/diffpool","text":"diffpool"}],"/embed":[{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/embed","text":"embed"}],"/eval-2000-SWBD":[{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/eval-2000-SWBD","text":"eval 2000 SWBD"}],"/exposure-bias":[{"source":"/Machine-Learning-Conversations","target":"/exposure-bias","text":"exposure bias"}],"/fertilities":[{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"}],"/gPool":[{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/gPool","text":"gPool"}],"/generalized-attention-mechanism":[{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"}],"/geometry":[{"source":"/Catch-the-Tails-of-BERT","target":"/geometry","text":"geometry"}],"/https//github.com/audio-captioning/clotho-datasethttps//github.com/audio-captioning/clotho-dataset":[{"source":"/Clotho-dataset","target":"/https//github.com/audio-captioning/clotho-datasethttps//github.com/audio-captioning/clotho-dataset","text":"github"}],"/iNAT":[{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/iNAT","text":"iNAT"}],"/ibAbI":[{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ibAbI","text":"ibAbI"}],"/language-model":[{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/language-model","text":"language model"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/language-model","text":"language model"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/language-model","text":"language model"}],"/meta-learning":[{"source":"/Meta-Reinforcement-Learning","target":"/meta-learning","text":"meta-learning"},{"source":"/Metattack","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-010620-210620","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-200720-020820","target":"/meta-learning","text":"meta-learning"}],"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION":[{"source":"/Mixup","target":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","text":"mixup - BEYOND EMPIRICAL RISK MINIMIZATION"}],"/newsdev2016-En-Ro":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"}],"/newsdev2016-Ro-En":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"}],"/newstest2013-De-En":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2013-De-En","text":"newstest2013 De-En"}],"/newstest2013-En-De":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2013-En-De","text":"newstest2013 En-De"}],"/newstest2014-De-En":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-De-En","text":"newstest2014 De-En"}],"/newstest2014-En-De":[{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"}],"/newstest2016-En-Ro":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"}],"/newstest2016-Ro-En":[{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"}],"/node2vec":[{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/node2vec","text":"node2vec"},{"source":"/Large-Scale-Information-Network-Embedding-LINE","target":"/node2vec","text":"node2vec"}],"/noisy-gradient-descent":[{"source":"/Security-and-Machine-Learning","target":"/noisy-gradient-descent","text":"noisy gradient descent"}],"/quantum-entropy-regularization":[{"source":"/Security-and-Machine-Learning","target":"/quantum-entropy-regularization","text":"quantum entropy regularization"}],"/sacreBLEU":[{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/sacreBLEU","text":"sacreBLEU"}],"/self-attention":[{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/GAT-Filter","target":"/self-attention","text":"self-attention"},{"source":"/Graph-Attention","target":"/self-attention","text":"self-attention"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/self-attention","text":"self-attention"}],"/self-similarity":[{"source":"/Catch-the-Tails-of-BERT","target":"/self-similarity","text":"self-similarity"}],"/skip-gram":[{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/skip-gram","text":"skip-gram"},{"source":"/DeepWalk","target":"/skip-gram","text":"skip-gram"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/skip-gram","text":"skip-gram"}],"/spaCy":[{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/spaCy","text":"spaCy"}],"/structural-causal-model":[{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"}],"/t-SNE":[{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"}],"/transformer":[{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/transformer","text":"transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/transformer","text":"Transformer"}],"/word2vec":[{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/word2vec","text":"word2vec"},{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/word2vec","text":"word2vec"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/word2vec","text":"word2vec"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/word2vec","text":"word2vec"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/word2vec","text":"word2vec"}]}},"links":[{"source":"/Paper-Levenshtein-Transformer","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/Paper-Levenshtein-Transformer","target":"/Changhan-Wang","text":"Changhan Wang"},{"source":"/Paper-Levenshtein-Transformer","target":"/Jake-Zhao-Junbo","text":"Jake Zhao Junbo"},{"source":"/Paper-Levenshtein-Transformer","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/Paper-Levenshtein-Transformer","target":"/Imitation-Learning","text":"Imitation Learning"},{"source":"/Paper-Levenshtein-Transformer","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/Paper-Levenshtein-Transformer","target":"/Roll-in-Policy","text":"Roll-in Policy"},{"source":"/Paper-Levenshtein-Transformer","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Paper-Levenshtein-Transformer","target":"/WAT2017-Small-NMT-En-Ja","text":"WAT2017 Small-NMT En-Ja"},{"source":"/Paper-Levenshtein-Transformer","target":"/WMT17-Automatic-Post-Editing-APE-Task-En-De","text":"WMT17 Automatic Post-Editing (APE) Task En-De"},{"source":"/Paper-Levenshtein-Transformer","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Hyundong-Cho","text":"Hyundong Cho"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Jonathan-May","text":"Jonathan May"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Cornell-Movie","text":"Cornell Movie"},{"source":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","target":"/Nucleus-Sampling","text":"Nucleus Sampling"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"},{"source":"/10-things-you-should-know-about-dialogue","target":"/July-24th-2020","text":"July 24th, 2020"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Act","text":"Dialogue Act"},{"source":"/10-things-you-should-know-about-dialogue","target":"/TriPy","text":"TriPy"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/10-things-you-should-know-about-dialogue","target":"/BLEU","text":"BLEU"},{"source":"/10-things-you-should-know-about-dialogue","target":"/ROUGE","text":"ROUGE"},{"source":"/10-things-you-should-know-about-dialogue","target":"/METEOR","text":"METEOR"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Ravenclaw-dialogue-system","text":"Ravenclaw dialogue system"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Dialogue-Modelling","text":"Dialogue Modelling"},{"source":"/10-things-you-should-know-about-dialogue","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Yongjing-Yin","text":"Yongjing Yin"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Fandong-Meng","text":"Fandong Meng"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jinsong-Su","text":"Jinsong Su"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Chulun-Zhou","text":"Chulun Zhou"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Zhengyuan-Yang","text":"Zhengyuan Yang"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Jiebo-Luo","text":"Jiebo Luo"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/December-23rd-2020","text":"December 23rd 2020"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/Multi30k","text":"Multi30k"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","target":"/MSCOCO","text":"MSCOCO"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rogers","text":"Anna Rogers"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Olga-Kovaleva","text":"Olga Kovaleva"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Anna-Rumshisky","text":"Anna Rumshisky"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/January-12th-2021","text":"January 12th 2021"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Part-of-Speech","text":"Part of Speech"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Predicate-Agreement","text":"Subject-Predicate Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Cloze-Task","text":"Cloze Task"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Named-Entity","text":"Named Entity"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Tacit-Knowledge","text":"Tacit Knowledge"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Probing","text":"Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Isotropy","text":"Isotropy"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Embeddings","text":"Embeddings"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Word-Sense-Disambiguation","text":"Word Sense Disambiguation"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reflexive-Anaphora","text":"Reflexive Anaphora"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/self-attention","text":"self-attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Denoising","text":"Denoising"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Mixout","text":"Mixout"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Turing-NLG","text":"Turing-NLG"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GPT-3","text":"GPT-3"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Transformer","text":"Transformer"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Neural-Machine-Translation","text":"NMT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Abstractive-Summarization","text":"Abstractive Summarization"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Subject-Verb-Agreement","text":"Subject-Verb Agreement"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Sentence-Subject-Detection","text":"Sentence Subject Detection"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Quantization","text":"Quantization"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/BERT","text":"BERT"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Natural-Language-Inference","text":"Natural Language Inference"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Reading-Comprehension","text":"Reading Comprehension"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Text-Classification","text":"Text Classification"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/datasets","text":"datasets"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Amnesic-Probing","text":"Amnesic Probing"},{"source":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","target":"/Pruning","text":"Pruning"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mixup","text":"Mixup"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/A-Robust-Framework-For-Acoustic-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Yi-Ren","text":"Yi Ren"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Jinglin-Liu","text":"Jinglin Liu"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Xu-Tan","text":"Xu Tan"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Zhou-Zhao","text":"Zhou Zhao"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Sheng-Zhao","text":"Sheng Zhao"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Conditional-Masked-prediction-with-Mixed-Attention-coMMA","text":"Conditional Masked prediction with Mixed-Attention (coMMA)"},{"source":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","target":"/Transformer","text":"Transformer"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Ryo-Masumura","text":"Ryo Masumura"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Kyosuke-Nishida","text":"Kyosuke Nishida"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Shoichiro-Saito","text":"Shoichiro Saito"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Transformer","text":"Transformer"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/BLEU","text":"BLEU"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/TRACKE","text":"TRACKE"},{"source":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","target":"/Scaffolding","text":"Scaffolding"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Margaret-Li","text":"Margaret Li"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Stephen-Roller","text":"Stephen Roller"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/June-24th-2020","text":"June 24th, 2020"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/PersonaChat","text":"PersonaChat"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","target":"/Likert-Scores","text":"Likert Scores"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Cem-Subakan","text":"Cem Subakan"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirco-Ravanelli","text":"Mirco Ravanelli"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Samuele-Cornell","text":"Samuele Cornell"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Mirko-Bronzi","text":"Mirko Bronzi"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Jianyuan-Zhong","text":"Jianyuan Zhong"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/05-Feb-2022","text":"05-Feb-2022"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Sepformer","text":"Sepformer"},{"source":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","target":"/Speech-Separation","text":"Speech Separation"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Yusong-Wu","text":"Yusong Wu"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Kun-Chen","text":"Kun Chen"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Ziyue-Wang","text":"Ziyue Wang"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xuan-Zhang","text":"Xuan Zhang"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Fudong-Nian","text":"Fudong Nian"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Shengchen-Li","text":"Shengchen Li"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Xi-Shao","text":"Xi Shao"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Transformer","text":"Transformer"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Mustafa-Sert","text":"Mustafa Sert"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Embeddings","text":"Embeddings"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/VGGish","text":"VGGish"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/word2vec","text":"word2vec"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/BLEU","text":"BLEU"},{"source":"/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Alex-Shamis","text":"Alex Shamis"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Stavros-Volos","text":"Stavros Volos"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Antoine-Delignat-Lavaud","text":"Antoine Delignat-Lavaud"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Trusted-Execution-Environments","text":"Trusted Execution Environments"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Raluca-Ada-Popa","text":"Raluca Ada Popa"},{"source":"/Accelerating-Machine-Learning-with-Confidential-Computing","target":"/Emmett-Witchel","text":"Emmett Witchel"},{"source":"/Adaptive-Mean-Margin","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"},{"source":"/Adjacency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Hengshuang-Zhao","text":"Hengshuang Zhao"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/January-27th-2021","text":"January 27th 2021"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Semantic-Segmentation","text":"Semantic Segmentation"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Pyramid-Scene-Parsing-Network","text":"Pyramid Scene Parsing Network"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/3D-Point-Cloud-Estimation","text":"3D Point Cloud Estimation"},{"source":"/Advancing-Visual-Intelligence-via-Neural-System-Design","target":"/Point-Transformer","text":"Point Transformer"},{"source":"/Alan-Turing-The-Enigma","target":"/Andrew-Hodges","text":"Andrew Hodges"},{"source":"/Alan-Turing-The-Enigma","target":"/July-31st-2020","text":"July 31st, 2020"},{"source":"/Amnesic-Probing","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Anh-Nguyen","text":"Anh Nguyen"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Khoa-Pham","text":"Khoa Pham"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dat-Ngo","text":"Dat Ngo"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Thanh-Ngo","text":"Thanh Ngo"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Dropout","text":"Dropout"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ReLU","text":"ReLU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/ELU","text":"ELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/SELU","text":"SELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/GELU","text":"GELU"},{"source":"/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network","target":"/Inverse-Square-Root-Linear-Unit","text":"ISRLU"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Chris-Baume","text":"Chris Baume"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Qiuqiang-Kong","text":"Qiuqiang Kong"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Tassadaq-Hussain","text":"Tassadaq Hussain"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification","target":"/AudioSet","text":"AudioSet"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Chulhee-Yun","text":"Chulhee Yun"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Srinadh-Bhojanapalli","text":"Srinadh Bhojanapalli"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Ankit-Singh-Rawat","text":"Ankit Singh Rawat"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Sanjiv-Kumar","text":"Sanjiv Kumar"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/May-28th-2020","text":"May 28th, 2020"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","target":"/Transformer","text":"Transformer"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/August-28th-2020","text":"August 28th, 2020"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Mike-Timms","text":"Mike Timms"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Intelligent-Tutoring-Systems-ITS","text":"Intelligent Tutoring Systems (ITS)"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Natural-Language-Processing","text":"Natural Language Processing"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Facial-Recognition","text":"Facial Recognition"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Augmented-Reality","text":"Augmented Reality"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Virtual-Reality","text":"Virtual Reality"},{"source":"/Artificial-Intelligence-AI-in-Education","target":"/Dragan-Gasevic","text":"Dragan Gasevic"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Kai-Yu","text":"Kai Yu"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss","target":"/Pooling","text":"Pooling"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Ay%C5%9Feg%C3%BCl-%C3%96zkaya-Eren","text":"Ayşegül Özkaya Eren"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Mustafa-Sert","text":"Mustafa Sert"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/February-14th-2021","text":"February 14th 2021"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daisuke-Niizumi","text":"Daisuke Niizumi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Masahiro-Yasuda","text":"Masahiro Yasuda"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/GPT-2","text":"GPT-2"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/VGGish","text":"VGGish"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BertScore","text":"BertScore"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/BLEU","text":"BLEU"},{"source":"/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Grounding-dataset","target":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","text":"TEXT-TO-AUDIO GROUNDING - BUILDING CORRESPONDENCE BETWEEN CAPTIONS AND SOUND EVENTS"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Audio-Grounding-dataset","target":"/AudioSet","text":"AudioSet"},{"source":"/Audio-Grounding-dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Chris-Dongjoo-Kim","text":"Chris Dongjoo Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Byeongchang-Kim","text":"Byeongchang Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Hyunmin-Lee","text":"Hyunmin Lee"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/Gunhee-Kim","text":"Gunhee Kim"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/February-10th-2021","text":"February 10th 2021"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioCaps","text":"AudioCaps"},{"source":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","target":"/AudioSet","text":"AudioSet"},{"source":"/AudioCaps","target":"/AudioCaps-Generating-Captions-for-Audios-in-The-Wild","text":"AudioCaps - Generating Captions for Audios in The Wild"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Sharath-Adavanne","text":"Sharath Adavanne"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/BLEU","text":"BLEU"},{"source":"/Automated-Audio-Captioning-with-Recurrent-Neural-Networks","target":"/PSE-library","text":"PSE library"},{"source":"/Automated-Audio-Captioning","target":"/Speech-Recognition","text":"Speech Recognition"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Ramaswamy-Palaniappan","text":"Ramaswamy Palaniappan"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Yue-Lang","text":"Yue Lang"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification","target":"/Bag-of-Features","text":"Bag of Features"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Maarten-De-Vos","text":"Maarten De Vos"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/May-18th-2021","text":"May 18th 2021"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/Accuracy","text":"Accuracy"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/F1-score","text":"F1 score"},{"source":"/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mechanism-Design-for-Social-Good","text":"Mechanism Design for Social Good"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Rediet-Abebe","text":"Rediet Abebe"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Mary-Gray","text":"Mary Gray"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Augustin-Chaintreau","text":"Augustin Chaintreau"},{"source":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","target":"/Irene-Lo","text":"Irene Lo"},{"source":"/BiLSTM","target":"/LSTM","text":"LSTM"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Manzil-Zaheer","text":"Manzil Zaheer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Guru-Guruganesh","text":"Guru Guruganesh"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Avinava-Dubey","text":"Avinava Dubey"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Joshua-Ainslie","text":"Joshua Ainslie"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Chris-Alberti","text":"Chris Alberti"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Santiago-Ontanon","text":"Santiago Ontanon"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Philip-Pham","text":"Philip Pham"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Anirudh-Ravula","text":"Anirudh Ravula"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Qifan-Wang","text":"Qifan Wang"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Li-Yang","text":"Li Yang"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Amr-Ahmed","text":"Amr Ahmed"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/August-11th-2020","text":"August 11th, 2020"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/BigBird","text":"BigBird"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Transformer","text":"Transformer"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/self-attention","text":"self-attention"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/generalized-attention-mechanism","text":"generalized attention mechanism"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Erd%C5%91s-R%C3%A9nyi-model","text":"Erdős-Rényi model"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Spectral-Graph","text":"Spectral Graph"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Small-World-Graphs","text":"Small World Graphs"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/clustering-coefficient","text":"clustering coefficient"},{"source":"/Big-Bird-Transformers-for-Longer-Sequences","target":"/Orthogonal-Vector-Conjecture","text":"Orthogonal Vector Conjecture"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Amit-Sharma","text":"Amit Sharma"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Susan-Athey","text":"Susan Athey"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Elias-Bareinboim","text":"Elias Bareinboim"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Pearl-Causal-Hierarchy","text":"Pearl Causal Hierarchy"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Bayes-Network","text":"Bayes Network"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Decision-Trees","text":"Decision Trees"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/structural-causal-model","text":"structural causal model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Cheng-Zhang","text":"Cheng Zhang"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Deep-Causal-Manipulation-Augmented-Model","text":"Deep Causal Manipulation Augmented Model"},{"source":"/Big-Ideas-in-Causality-and-Machine-Learning","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Bilinear-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Jean-Bastien-Grill","text":"Jean-Bastien Grill"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florian-Strub","text":"Florian Strub"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Florent-Altche","text":"Florent Altche"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Corentin-Tallec","text":"Corentin Tallec"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Elena-Buchatskaya","text":"Elena Buchatskaya"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Carl-Doersch","text":"Carl Doersch"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bernado-Avila-Pires","text":"Bernado Avila Pires"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Zhaohan-Daniel-Guo","text":"Zhaohan Daniel Guo"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Mohammad-Gheshlaghi-Azar","text":"Mohammad Gheshlaghi Azar"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bilal-Piot","text":"Bilal Piot"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Koray-Kavukcuoglu","text":"Koray Kavukcuoglu"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Remi-Munos","text":"Remi Munos"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Michal-Valko","text":"Michal Valko"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Contrastive-Loss","text":"Contrastive Loss"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"Bootstrap Your Own Latent"},{"source":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","target":"/Bootstrap-Your-Own-Latent","text":"BYOL"},{"source":"/Bootstrap-Your-Own-Latent","target":"/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning","text":"Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"},{"source":"/Break-into-Natural-Language-Processing","target":"/Marti-Hearst","text":"Marti Hearst"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"},{"source":"/Break-into-Natural-Language-Processing","target":"/July-30th-2020","text":"July 30th, 2020"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/Transformer","text":"Transformer"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-2","text":"GPT-2"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Andrew-Ng","text":"Andrew Ng"},{"source":"/Break-into-Natural-Language-Processing","target":"/Kenneth-Church","text":"Kenneth Church"},{"source":"/Break-into-Natural-Language-Processing","target":"/%C5%81ukasz-Kaiser","text":"Łukasz Kaiser"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"},{"source":"/Break-into-Natural-Language-Processing","target":"/Younes-Bensouda-Mourri","text":"Younes Bensouda Mourri"},{"source":"/Break-into-Natural-Language-Processing","target":"/GPT-3","text":"GPT-3"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zelin-Zhou","text":"Zelin Zhou"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zhiling-Zhang","text":"Zhiling Zhang"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Zeyu-Xie","text":"Zeyu Xie"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/05-Jan-2022","text":"05-Jan-2022"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Fluency-ENhanced-Sentence-bert-Evaluation","text":"FENSE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/METEOR","text":"METEOR"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/CIDEr","text":"CIDEr"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/SPICE","text":"SPICE"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/TF-IDF","text":"TF-IDF"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/cosine-similarity","text":"cosine similarity"},{"source":"/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS","target":"/Sentence-BERT","text":"Sentence-BERT"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Eric-Jang","text":"Eric Jang"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Shixiang-Gu","text":"Shixiang Gu"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Ben-Poole","text":"Ben Poole"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Max-trick","text":"Gumbel-Max trick"},{"source":"/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX","target":"/Gumbel-Distribution","text":"Gumbel Distribution"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-2","text":"CE7429 - Lecture 2"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-3","text":"CE7429 - Lecture 3"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-4","text":"CE7429 - Lecture 4"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-5","text":"CE7429 - Lecture 5"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-6","text":"CE7429 - Lecture 6"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-7","text":"CE7429 - Lecture 7"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-8","text":"CE7429 - Lecture 8"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-9","text":"CE7429 - Lecture 9"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-10","text":"CE7429 - Lecture 10"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-11","text":"CE7429 - Lecture 11"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-12","text":"CE7429 - Lecture 12"},{"source":"/CE7429-Computational-Intelligence-Methods-and-Applications","target":"/CE7429-Lecture-13","text":"CE7429 - Lecture 13"},{"source":"/CE7429-Lecture-10","target":"/September-8th-2020","text":"September 8th, 2020"},{"source":"/CE7429-Lecture-10","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"},{"source":"/CE7429-Lecture-11","target":"/September-15th-2020","text":"September 15th, 2020"},{"source":"/CE7429-Lecture-12","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/CE7429-Lecture-12","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/CE7429-Lecture-12","target":"/Knowledge-Based-Agents","text":"Knowledge Based Agents"},{"source":"/CE7429-Lecture-12","target":"/Memory","text":"Memory"},{"source":"/CE7429-Lecture-13","target":"/September-22nd-2020","text":"September 22nd, 2020"},{"source":"/CE7429-Lecture-13","target":"/Semantic-Memory-Duration","text":"Semantic Memory Duration"},{"source":"/CE7429-Lecture-13","target":"/Catastrophic-Forgetting","text":"Catastrophic Forgetting"},{"source":"/CE7429-Lecture-13","target":"/Modal-Memory-Model-SOAR","text":"Modal Memory Model (SOAR)"},{"source":"/CE7429-Lecture-13","target":"/Sensory-Memory","text":"Sensory Memory"},{"source":"/CE7429-Lecture-13","target":"/Short-Term-Memory","text":"Short Term Memory"},{"source":"/CE7429-Lecture-13","target":"/Long-Term-Memory","text":"Long Term Memory"},{"source":"/CE7429-Lecture-13","target":"/Adaptive-Character-of-Thought-ACT-Memory-Model","text":"Adaptive Character of Thought (ACT) Memory Model"},{"source":"/CE7429-Lecture-13","target":"/Working-Memory-Model","text":"Working Memory Model"},{"source":"/CE7429-Lecture-13","target":"/Chunking","text":"Chunking"},{"source":"/CE7429-Lecture-2","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/CE7429-Lecture-2","target":"/Computational-Intelligence","text":"Computational Intelligence"},{"source":"/CE7429-Lecture-3","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/CE7429-Lecture-3","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"},{"source":"/CE7429-Lecture-3","target":"/Bayes-Theorem","text":"Bayes Theorem"},{"source":"/CE7429-Lecture-4","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/CE7429-Lecture-4","target":"/Starplots","text":"Starplots"},{"source":"/CE7429-Lecture-5","target":"/August-21st-2020","text":"August 21st, 2020"},{"source":"/CE7429-Lecture-5","target":"/Chernoff-Faces","text":"Chernoff Faces"},{"source":"/CE7429-Lecture-5","target":"/Exploratory-Data-Analysis","text":"Exploratory Data Analysis"},{"source":"/CE7429-Lecture-5","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-5","target":"/Mahalanobis-Distance","text":"Mahalanobis Distance"},{"source":"/CE7429-Lecture-6","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Discriminant-Component-Analysis","text":"Discriminant Component Analysis"},{"source":"/CE7429-Lecture-6","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-6","target":"/Linear-Discriminant-Analysis","text":"Linear Discriminant Analysis"},{"source":"/CE7429-Lecture-6","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/August-28th-2020","text":"August 28th, 2020"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Principal-Component-Analysis","text":"Principal Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Fishers-Discriminant-Analysis","text":"Fisher's Discriminant Analysis"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Expectation-Mean","text":"Expectation (Mean)"},{"source":"/CE7429-Lecture-7","target":"/Moments","text":"Moments"},{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"},{"source":"/CE7429-Lecture-7","target":"/Normal-Distribution","text":"Normal Distribution"},{"source":"/CE7429-Lecture-7","target":"/Non-Gaussianity","text":"Non-Gaussianity"},{"source":"/CE7429-Lecture-7","target":"/Kurtosis","text":"Kurtosis"},{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"},{"source":"/CE7429-Lecture-7","target":"/Entropy","text":"Entropy"},{"source":"/CE7429-Lecture-7","target":"/Projection-Pursuit","text":"Projection Pursuit"},{"source":"/CE7429-Lecture-7","target":"/Independent-Component-Analysis","text":"Independent Component Analysis"},{"source":"/CE7429-Lecture-7","target":"/Models-of-Self-Organization","text":"Models of Self-Organization"},{"source":"/CE7429-Lecture-7","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"},{"source":"/CE7429-Lecture-7","target":"/Senso-motoric-Maps","text":"Senso-motoric Maps"},{"source":"/CE7429-Lecture-7","target":"/Somatosensoric-Maps","text":"Somatosensoric Maps"},{"source":"/CE7429-Lecture-8","target":"/September-1st-2020","text":"September 1st, 2020"},{"source":"/CE7429-Lecture-8","target":"/Self-Organized-Feature-Mapping-SOFM","text":"Self-Organized Feature Mapping (SOFM)"},{"source":"/CE7429-Lecture-9","target":"/September-4th-2020","text":"September 4th, 2020"},{"source":"/CE7429-Lecture-9","target":"/cross-validation","text":"cross validation"},{"source":"/CE7429-Lecture-9","target":"/Curse-of-Dimensionality","text":"Curse of Dimensionality"},{"source":"/CE7429-Lecture-9","target":"/Confusion-Matrix","text":"Confusion Matrix"},{"source":"/CE7429-Lecture-9","target":"/Receiver-Operating-Characteristics-ROC","text":"Receiver Operating Characteristics (ROC)"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism","text":"Graph Isomorphism"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Aggregator-Functions","text":"Aggregator Functions"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Injective","text":"Injective"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Principal-Neighbourhood-Aggregation","text":"Principal Neighbourhood Aggregation"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Feed-forward","text":"Feed-forward"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Symmetric","text":"Symmetry"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Equivariant","text":"Equivariance"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"k-WL tests"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Substructure-Networks","text":"Graph Substructure Networks"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Complexity","text":"Complexity"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/RingGNNs","text":"RingGNNs"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Low-Rank-Global-Attention","text":"Graph Low-Rank Global Attention"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Weisfieler-Lehman-test","text":"WL test"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Stochastic-Gradient-Descent","text":"SGD"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Isomorphism-Networks","text":"GINs"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","target":"/Node-Positional-Encodings","text":"Node Positional Encodings"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-1","text":"CE7491 Lecture 1"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-2","text":"CE7491 Lecture 2"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-3","text":"CE7491 Lecture 3"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-4","text":"CE7491 Lecture 4"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-5","text":"CE7491 Lecture 5"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-6","text":"CE7491 Lecture 6"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-7","text":"CE7491 Lecture 7"},{"source":"/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING","target":"/CE7491-Lecture-8","text":"CE7491 Lecture 8"},{"source":"/CE7491-Lecture-1","target":"/Field-of-View","text":"Field of View"},{"source":"/CE7491-Lecture-1","target":"/Depth-of-Field","text":"Depth of Field"},{"source":"/CE7491-Lecture-1","target":"/Gray-Level-Indexing","text":"Gray-Level Indexing"},{"source":"/CE7491-Lecture-1","target":"/Image-Dithering","text":"Image Dithering"},{"source":"/CE7491-Lecture-2","target":"/August-19th-2020","text":"August 19th, 2020"},{"source":"/CE7491-Lecture-2","target":"/Point-Processing","text":"Point Processing"},{"source":"/CE7491-Lecture-2","target":"/Spatial-Filtering","text":"Spatial Filtering"},{"source":"/CE7491-Lecture-2","target":"/Image-Negatives","text":"Image Negatives"},{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"},{"source":"/CE7491-Lecture-2","target":"/Averaging-Filter","text":"Averaging Filter"},{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"},{"source":"/CE7491-Lecture-2","target":"/High-Boost-Filtering","text":"High Boost Filtering"},{"source":"/CE7491-Lecture-2","target":"/Laplacian-Filter","text":"Laplacian Filter"},{"source":"/CE7491-Lecture-2","target":"/Median-Filtering","text":"Median Filtering"},{"source":"/CE7491-Lecture-2","target":"/Histogram-Equalization","text":"Histogram Equalization"},{"source":"/CE7491-Lecture-2","target":"/Contrast-Stretching","text":"Contrast Stretching"},{"source":"/CE7491-Lecture-3","target":"/August-26th-2020","text":"August 26th, 2020"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Quantitative-Color-Specification","text":"Quantitative Color Specification"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Color-Theory","text":"Tristimulus Color Theory"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Grassmanns-Law","text":"Grassmann's Law"},{"source":"/CE7491-Lecture-3","target":"/Spectral-Power-Distribution","text":"Spectral Power Distribution"},{"source":"/CE7491-Lecture-3","target":"/Luminance","text":"Luminance"},{"source":"/CE7491-Lecture-3","target":"/Chromaticity","text":"Chromaticity"},{"source":"/CE7491-Lecture-3","target":"/Tristimulus-Values","text":"Tristimulus Values"},{"source":"/CE7491-Lecture-3","target":"/Subtractive-Color-Mixing","text":"Subtractive Color Mixing"},{"source":"/CE7491-Lecture-3","target":"/Sobel-Gradient","text":"Sobel Gradient"},{"source":"/CE7491-Lecture-3","target":"/Laplacian-of-Gaussian-Filter","text":"Laplacian of Gaussian Filter"},{"source":"/CE7491-Lecture-3","target":"/Canny-Edge-Detector","text":"Canny Edge Detector"},{"source":"/CE7491-Lecture-3","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"},{"source":"/CE7491-Lecture-3","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"},{"source":"/CE7491-Lecture-3","target":"/Hough-Transform","text":"Hough Transform"},{"source":"/CE7491-Lecture-4","target":"/September-2nd-2020","text":"September 2nd, 2020"},{"source":"/CE7491-Lecture-4","target":"/Pooling","text":"Pooling"},{"source":"/CE7491-Lecture-5","target":"/September-9th-2020","text":"September 9th, 2020"},{"source":"/CE7491-Lecture-5","target":"/Batch-Normalization","text":"Batch Normalization"},{"source":"/CE7491-Lecture-5","target":"/Switchable-Normalization","text":"Switchable Normalization"},{"source":"/CE7491-Lecture-6","target":"/September-16th-2020","text":"September 16th, 2020"},{"source":"/CE7491-Lecture-6","target":"/Region-Proposal-Network","text":"Region Proposal Network"},{"source":"/CE7491-Lecture-6","target":"/Faster-R-CNN","text":"Faster R-CNN"},{"source":"/CE7491-Lecture-6","target":"/Image-Restoration","text":"Image Restoration"},{"source":"/CE7491-Lecture-6","target":"/Super-Resolution","text":"Super-Resolution"},{"source":"/CE7491-Lecture-6","target":"/Deconvolution-Transposed-Convolution","text":"Deconvolution (Transposed Convolution)"},{"source":"/CE7491-Lecture-6","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-7","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/CE7491-Lecture-7","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-7","target":"/Super-Resolution","text":"Super-Resolution"},{"source":"/CE7491-Lecture-7","target":"/GAN-Inversion","text":"GAN-Inversion"},{"source":"/CE7491-Lecture-7","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/CE7491-Lecture-8","target":"/October-7th-2020","text":"October 7th, 2020"},{"source":"/CE7491-Lecture-8","target":"/Image-to-Image-Translation","text":"Image-to-Image Translation"},{"source":"/CE7491-Lecture-8","target":"/Deep-Fakes","text":"Deep Fakes"},{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/CE7491-Lecture-8","target":"/Latent-Space","text":"Latent Space"},{"source":"/CE7491-Lecture-8","target":"/Neural-Network","text":"Neural Network"},{"source":"/CE7491-Lecture-8","target":"/Properties","text":"Properties"},{"source":"/CE7491-Lecture-8","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/CE7491-Lecture-8","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"},{"source":"/CE7491-Lecture-8","target":"/Nash-Equilibrium","text":"Nash Equilibrium"},{"source":"/CE7491-Lecture-8","target":"/Mode-Collapse","text":"Mode Collapse"},{"source":"/CE7491-Lecture-8","target":"/Task-Regularization","text":"Task Regularization"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Thomas-Lidy","text":"Thomas Lidy"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Alexander-Schindler","text":"Alexander Schindler"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING","target":"/TUT-acoustic-scenes-2016","text":"TUT acoustic scenes 2016"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Augustin-Arnault","text":"Augustin Arnault"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Nicolas-Riche","text":"Nicolas Riche"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/TALNet","text":"TALNet"},{"source":"/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT","target":"/Time2Vec","text":"Time2Vec"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Unit-Vector","text":"Unit Vector"},{"source":"/CZ1104-Lecture-6.1","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/CZ1104-Lecture-6.1","target":"/Dot-Product","text":"Dot Product"},{"source":"/CZ1104-Lecture-6.1","target":"/Cauchy-Schwarz-Inequality","text":"Cauchy-Schwarz Inequality"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonality"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Point-Normal-Equations","text":"Point Normal Equations"},{"source":"/CZ1104-Lecture-6.2","target":"/Standard-Basis","text":"Standard Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Pythagoras-Theorem","text":"Pythagoras Theorem"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthonormal","text":"Orthonormal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"Orthogonal"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/CZ1104-Lecture-6.2","target":"/Best-Approximation-Theorem","text":"Best Approximation Theorem"},{"source":"/CZ1104-Lecture-6.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-6.3","target":"/Span","text":"Span"},{"source":"/CZ1104-Lecture-6.3","target":"/Gram-Schmidt","text":"Gram Schmidt"},{"source":"/CZ1104-Lecture-6.3","target":"/QR-Factorization","text":"QR Factorization"},{"source":"/CZ1104-Lecture-7.1","target":"/Consistency-in-a-System-of-Equations","text":"Consistency in a System of Equations"},{"source":"/CZ1104-Lecture-7.1","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"},{"source":"/CZ1104-Lecture-7.1","target":"/Orthogonal-Decomposition-Thereom","text":"Orthogonal Decomposition Thereom"},{"source":"/CZ1104-Lecture-7.1","target":"/Projection-Matrix","text":"Projection Matrix"},{"source":"/CZ1104-Lecture-7.2","target":"/Binary-Matrix-Operations","text":"Binary Matrix Operations"},{"source":"/CZ1104-Lecture-7.2","target":"/BC","text":"A"},{"source":"/CZ1104-Lecture-7.2","target":"/Invertibility","text":"Invertibility"},{"source":"/CZ1104-Lecture-7.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-7.2","target":"/Trace","text":"Trace"},{"source":"/CZ1104-Lecture-7.2","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Singular-Values","text":"Singular Values"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"},{"source":"/CZ1104-Lecture-8.1","target":"/Singular","text":"Singular"},{"source":"/CZ1104-Lecture-8.1","target":"/Determinant","text":"Determinant"},{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"},{"source":"/CZ1104-Lecture-8.1","target":"/Spectrum","text":"Spectrum"},{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space-kernel","text":"Null Space (kernel)"},{"source":"/CZ1104-Lecture-8.1","target":"/Characteristic-Equation","text":"Characteristic Equation"},{"source":"/CZ1104-Lecture-8.1","target":"/Nullity","text":"Nullity"},{"source":"/CZ1104-Lecture-8.1","target":"/Null-Space","text":"Null Space"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/CZ1104-Lecture-8.1","target":"/Spectral-Decomposition","text":"Spectral Decomposition"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.1","target":"/Eigenvector","text":"Eigenvector"},{"source":"/CZ1104-Lecture-8.1","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.1","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.1","target":"/Geometric-Multiplicity","text":"Geometric Multiplicity"},{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Spectral-Theorem","text":"Spectral Theorem"},{"source":"/CZ1104-Lecture-8.2","target":"/Symmetric","text":"Symmetric"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Algebraic-Multiplicity","text":"Algebraic Multiplicity"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigen-Space","text":"Eigen Space"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.2","target":"/Orthogonality","text":"orthogonally"},{"source":"/CZ1104-Lecture-8.2","target":"/Diagonalisable","text":"Diagonalisable"},{"source":"/CZ1104-Lecture-8.2","target":"/Similar","text":"Similar"},{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Transform","text":"Similarity Transform"},{"source":"/CZ1104-Lecture-8.2","target":"/Similarity-Invariant","text":"Similarity Invariant"},{"source":"/CZ1104-Lecture-8.2","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.4","target":"/Orthogonality","text":"orthogonal"},{"source":"/CZ1104-Lecture-8.4","target":"/Matrix-Approximation","text":"Matrix Approximation"},{"source":"/CZ1104-Lecture-8.4","target":"/Condition-Number","text":"Condition Number"},{"source":"/CZ1104-Lecture-8.4","target":"/Moore-Penrose-Pseudoinverse","text":"Moore-Penrose Pseudoinverse"},{"source":"/CZ1104-Lecture-8.4","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/CZ1104-Lecture-8.4","target":"/Four-Fundamental-Subspaces","text":"Four Fundamental Subspaces"},{"source":"/Catch-the-Tails-of-BERT","target":"/Ziyang-Luo","text":"Ziyang Luo"},{"source":"/Catch-the-Tails-of-BERT","target":"/November-26th-2020","text":"November 26th, 2020"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"},{"source":"/Catch-the-Tails-of-BERT","target":"/BERT","text":"BERT"},{"source":"/Catch-the-Tails-of-BERT","target":"/RoBERTa","text":"RoBERTa"},{"source":"/Catch-the-Tails-of-BERT","target":"/SST-2","text":"SST-2"},{"source":"/Catch-the-Tails-of-BERT","target":"/Anisotropy","text":"Anisotropy"},{"source":"/Catch-the-Tails-of-BERT","target":"/geometry","text":"geometry"},{"source":"/Catch-the-Tails-of-BERT","target":"/cosine-similarity","text":"cosine similarity"},{"source":"/Catch-the-Tails-of-BERT","target":"/self-similarity","text":"self-similarity"},{"source":"/Catch-the-Tails-of-BERT","target":"/WiC","text":"WiC"},{"source":"/Cheby-Filter","target":"/Poly-Filter","text":"Poly-Filter"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/Cheby-Filter","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Cheby-Filter","target":"/Orthogonal-Basis","text":"Orthogonal Basis"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Samuel-Lipping","text":"Samuel Lipping"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/February-10th-2021","text":"February 10th 2021"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/AudioCaps","text":"AudioCaps"},{"source":"/Clotho-An-Audio-Captioning-Dataset","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Clotho-dataset","target":"/https//github.com/audio-captioning/clotho-datasethttps//github.com/audio-captioning/clotho-dataset","text":"github"},{"source":"/Clotho-dataset","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/Color-Indexing","target":"/September-25th-2020","text":"September 25th, 2020"},{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"},{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"},{"source":"/Color-Indexing","target":"/Histogram-Intersection","text":"Histogram Intersection"},{"source":"/Color-Indexing","target":"/Incremental-Intersection","text":"Incremental Intersection"},{"source":"/Color-Indexing","target":"/Histogram-Backprojection","text":"Histogram Backprojection"},{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Neural-Network","text":"Neural Network"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Self-Tuning-Regulator","text":"Self-Tuning Regulator"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Least-Squares","text":"Least Squares"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Lyapunov-Model-Reference-MRAC","text":"Lyapunov Model Reference (MRAC)"},{"source":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Compositional-Rule-of-Inference","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Compositional-Rule-of-Inference","target":"/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning","text":"The Concept of a Linguistic Variable and its Application to Approximate Reasoning"},{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-Rule-of-Inference","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-Rule-of-Inference","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-Rule-of-Inference","target":"/Generalized-Modus-Ponens","text":"Generalized [[Modus Ponens"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Bernadette-Bouchon-Meunier","text":"Bernadette Bouchon-Meunier"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Radko-Mesiar","text":"Radko Mesiar"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Christophe-Marsala","text":"Christophe Marsala"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Maria-Rifqi","text":"Maria Rifqi"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Fuzzy-Deductive-Reasoning","text":"Fuzzy Deductive Reasoning"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Analogical-Scheme","text":"Analogical Scheme"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Compositional-Rule-of-Inference","text":"Compositional Rule of Inference"},{"source":"/Compositional-rule-of-inference-as-an-analogical-scheme","target":"/Modus-Ponens","text":"Modus Ponens"},{"source":"/Connected-Component","target":"/Connected-Component","text":"Connected Component"},{"source":"/Connected-Component","target":"/Connected-Graph","text":"Connected Graph"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Liang-Ding","text":"Liang Ding"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Longyue-Wang","text":"Longyue Wang"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Di-Wu","text":"Di Wu"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Dacheng-Tao","text":"Dacheng Tao"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/November-26th-2020","text":"November 26th, 2020"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Local-Entropy","text":"Local Entropy"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/cross-attention","text":"cross-attention"},{"source":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Ana-Peleteiro-Ramallo","text":"Ana Peleteiro Ramallo"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/December-2nd-2020","text":"December 2nd 2020"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Transformer","text":"Transformer"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","target":"/BERT","text":"BERT"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Micha%C3%ABl-Defferrard","text":"Michaël Defferrard"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Xavier-Bresson","text":"Xavier Bresson"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Pierre-Vandergheynst","text":"Pierre Vandergheynst"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/December-15th-2020","text":"December 15th 2020"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Kronecker-Delta","text":"Kronecker Delta"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Lanczos-algorithm","text":"Lanczos algorithm"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/MNIST","text":"MNIST"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/20NEWS","text":"20NEWS"},{"source":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Coreference","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Covid19-politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Covid19-scientific","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jisheng-Bai","text":"Jisheng Bai"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Chen-Chen","text":"Chen Chen"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mou-Wang","text":"Mou Wang"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Jiangfeng-Chen","text":"Jiangfeng Chen"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Xiaolei-Zhang","text":"Xiaolei Zhang"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Qingli-Yan","text":"Qingli Yan"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING","target":"/Mixup","text":"Mixup"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Yanran-Li","text":"Yanran Li"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Hui-Su","text":"Hui Su"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Xiaoyu-Shen","text":"Xiaoyu Shen"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Wenjie-Li","text":"Wenjie Li"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Ziqiang-Cao","text":"Ziqiang Cao"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/Shuzi-Niu","text":"Shuzi Niu"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"},{"source":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","target":"/DailyDialog","text":"DailyDialog"},{"source":"/DailyDialog","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Nicholas-Roberts","text":"Nicholas Roberts"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/David-Liang","text":"David Liang"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/January-7th-2021","text":"January 7th 2021"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/BERT","text":"BERT"},{"source":"/Decoding-and-Diversity-in-Machine-Translation","target":"/Beam-Search","text":"Beam Search"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/KL-divergence","text":"KL-divergence"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Mixup","text":"Mixup"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Triplet-Loss","text":"Triplet Loss"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio","target":"/Scaffolding","text":"Scaffolding"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Alexander-Schindler","text":"Alexander Schindler"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mina-Schutz","text":"Mina Schutz"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Jasmin-Pielorz","text":"Jasmin Pielorz"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Sven-Schlarb","text":"Sven Schlarb"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Ross-King","text":"Ross King"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Gammatone","text":"Gammatone"},{"source":"/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Deep-Learning-on-Graphs","text":"Deep Learning on Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Machine-Learning","text":"Machine Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/K-means-clustering","text":"K-means clustering"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/skip-gram","text":"skip-gram"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/word2vec","text":"word2vec"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Pooling","text":"Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Scalabilty","text":"Scalabilty"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Question-Answering","text":"Question Answering"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/WIKIHOP-dataset","text":"WIKIHOP dataset"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Entity-GCN","text":"Entity-GCN"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-to-Sequence","text":"Graph to Sequence"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/GGNN-Filter","text":"GGNN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree","text":"Degree"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Neighbors","text":"Neighbors"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Walk","text":"Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Trail","text":"Trail"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Path","text":"Path"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Subgraph","text":"Subgraph"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Connected-Component","text":"Connected Component"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Shortest-Path","text":"Shortest Path"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Diameter","text":"Diameter"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Degree-Centrality","text":"Degree Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Katz-Centrality","text":"Katz Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Betweenness-Centrality","text":"Betweenness Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Signal","text":"Graph Signal"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Discrete-Dynamic-Graphs","text":"Discrete Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Node-Classification","text":"Node Classification"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","target":"/Graph-Classification","text":"Graph Classification"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Static","text":"Static"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Undirected","text":"Undirected"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Unsigned","text":"Unsigned"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/node2vec","text":"node2vec"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Large-Scale-Information-Network-Embedding-LINE","text":"Large-Scale Information Network Embedding (LINE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree","text":"Degree"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hierarchical-Structural-Similarity-Measure","text":"Hierarchical Structural Similarity Measure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Structural-Role","text":"Structural Role"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Biased-Random-Walk","text":"Biased Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Status","text":"Node Status"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Degree-Centrality","text":"Degree Centrality"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Community-Structure","text":"Community Structure"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Modularity-Maximization","text":"Modularity Maximization"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Network-Embedding-HNE","text":"Heterogeneous Network Embedding (HNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/cross-entropy","text":"cross entropy"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Meta-Path-Schema","text":"Meta-Path Schema"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Random-Walk","text":"Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Bipartite-Network-Embedding-BiNE","text":"Bipartite Network Embedding (BiNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Extractor","text":"Extractor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Reconstructor","text":"Reconstructor"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Heterogeneous-Network-Embedding-DHNE","text":"Dynamic Heterogeneous Network Embedding (DHNE)"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Graph-Embbedding","text":"Graph Embbedding"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Neighbors","text":"Temporal Neighbors"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","target":"/Temporal-Random-Walk","text":"Temporal Random Walk"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Activation-Function","text":"Activation Function"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spectral-Graph-Filtering","text":"Spectral Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Inverse-Graph-Fourier-Transform","text":"Inverse Graph Fourier Transform"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Poly-Filter","text":"Poly-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Cheby-Filter","text":"Cheby-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Spatial-Graph-Filtering","text":"Spatial Graph Filtering"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GAT-Filter","text":"GAT-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/ECC-Filter","text":"ECC-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/GGNN-Filter","text":"GGNN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Mo-Filter","text":"Mo-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Pooling","text":"Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Flat-Graph-Pooling","text":"Flat Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Hierarchical-Graph-Pooling","text":"Hierarchical Graph Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/gPool","text":"gPool"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/diffpool","text":"diffpool"},{"source":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","target":"/EigenPooling","text":"EigenPooling"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Neural-Network","text":"Neural Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Evasion-Attack","text":"Evasion Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Poisoning-Attack","text":"Poisoning Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/White-box-attack","text":"White-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PGD-Topology-Attack","text":"PGD Topology Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Integrated-Gradient-Guided-Attack","text":"Integrated Gradient Guided Attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Metattack","text":"Metattack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RL-S2V","text":"RL-S2V"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/ReWatt","text":"ReWatt"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/GraphAT","text":"GraphAT"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Purification","text":"Graph Purification"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Jaccard-Similarity","text":"Jaccard Similarity"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Nettack","text":"Nettack"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Singular-Value-Decomposition","text":"Singular Value Decomposition"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Attention","text":"Graph Attention"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/RGCN-Filter","text":"RGCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/PA-GNN","text":"PA-GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","target":"/Pro-GNN","text":"Pro-GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Stochastic-Gradient-Descent","text":"Stochastic Gradient Descent"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighborhood Explosion"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Node-wise-Sampling","text":"Node-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Monte-Carlo","text":"Monte Carlo"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/GraphSAGE-Filter","text":"GraphSAGE-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Neighborhood-Explosion","text":"Neighbourhood Expansion"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Layer-wise-Sampling","text":"Layer-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Importance-Sampling","text":"Importance Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/Edge-based-Sampler","text":"Edge-based Sampler"},{"source":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","target":"/RW-based-Sampler","text":"RW-based Sampler"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Meta-Path-Schema","text":"Meta-Path Schema"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Heterogeneous-Graphs","text":"Heterogeneous Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Homogeneous","text":"Homogeneous"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Bipartite-Graphs","text":"Bipartite Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Within-Dimension-Neighbor","text":"Within-Dimension Neighbor"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Across-Dimension-Neighbor","text":"Across-Dimension Neighbor"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Balance-Theory","text":"Balance Theory"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Signed-Graphs","text":"Signed Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Hypergraphs","text":"Hypergraphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Graph-Filter","text":"Graph Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/EvolveGCN","text":"EvolveGCN"},{"source":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Auto-Encoders","text":"Graph Auto-Encoders"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Tree-LSTM","text":"Tree-LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/LSTM","text":"LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-LSTM","text":"Graph-LSTM"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Yao-Ma","text":"Yao Ma"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Jiliang-Tang","text":"Jiliang Tang"},{"source":"/Deep-Learning-on-Graphs-book","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-1-Introduction","text":"Deep Learning On Graphs Chapter 1 - Introduction"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs","text":"Deep Learning On Graphs Chapter 2 - Foundations of Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning","text":"Deep Learning On Graphs Chapter 3 - Foundations of Deep Learning"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding","text":"Deep Learning On Graphs Chapter 4 - Graph Embedding"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 5 - Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 7 - Scalable Graph Neural Networks"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs","text":"Deep Learning On Graphs Chapter 8 - Graph Neural Networks on Complex Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Deep-Learning-on-Graphs-book","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/DeepWalk","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/DeepWalk","target":"/Random-Walk","text":"Random Walk"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Extractor","text":"Extractor"},{"source":"/DeepWalk","target":"/skip-gram","text":"skip-gram"},{"source":"/DeepWalk","target":"/Node-Co-occurrence","text":"Node Co-occurrence"},{"source":"/DeepWalk","target":"/Reconstructor","text":"Reconstructor"},{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/DeepWalk","target":"/N-grams","text":"N-grams"},{"source":"/DeepWalk","target":"/Softmax","text":"Softmax"},{"source":"/DeepWalk","target":"/Hierarchical-Softmax","text":"Hierarchical Softmax"},{"source":"/DeepWalk","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Catherine-Yeo","text":"Catherine Yeo"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/Alyssa-Chen","text":"Alyssa Chen"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/August-11th-2020","text":"August 11th, 2020"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/GPT-2","text":"GPT-2"},{"source":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","target":"/XLNet","text":"XLNet"},{"source":"/Dependency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/TransE","text":"TransE"},{"source":"/Description-Embodied-Knowledge-Representation-Learning","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yizhe-Zhang","text":"Yizhe Zhang"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Siqi-Sun","text":"Siqi Sun"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Michel-Galley","text":"Michel Galley"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Yen-Chun-Chen","text":"Yen-Chun Chen"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Chris-Brockett","text":"Chris Brockett"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Xiang-Gao","text":"Xiang Gao"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jianfeng-Gao","text":"Jianfeng Gao"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Jingjing-Liu","text":"Jingjing Liu"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/Bill-Dolan","text":"Bill Dolan"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/July-18th-2020","text":"July 18th, 2020"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/DialoGPT","text":"DialoGPT"},{"source":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","target":"/GPT-2","text":"GPT-2"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/Hiroaki-Sugiyama","text":"Hiroaki Sugiyama"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","target":"/BERT","text":"BERT"},{"source":"/Diameter","target":"/Connected-Graph","text":"Connected Graph"},{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/August-12th-2020","text":"August 12th, 2020"},{"source":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","target":"/word2vec","text":"word2vec"},{"source":"/Discrete-Dynamic-Graphs","target":"/Dynamic-Graphs","text":"Dynamic Graphs"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Devendra-Singh-Sachan","text":"Devendra Singh Sachan"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Yuhao-Zhang","text":"Yuhao Zhang"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Peng-Qi","text":"Peng Qi"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/William-Hamilton","text":"William Hamilton"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/January-5th-2021","text":"January 5th 2021"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-Tree","text":"Syntax Tree"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Transformer","text":"Transformer"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Syntax-GNN","text":"Syntax-GNN"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Relation-Extraction","text":"Relation Extraction"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2005-WSJ","text":"CoNLL-2005 WSJ"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/CoNLL-2012","text":"CoNLL-2012"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/TACRED","text":"TACRED"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/F1-score","text":"F1 score"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Semantic-Role-Labeling","text":"Semantic Role Labeling"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/Named-Entity-Recognition","text":"NER"},{"source":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","target":"/BERT","text":"BERT"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Ali-Razavi","text":"Ali Razavi"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/July-31st-2020","text":"July 31st, 2020"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Do-Transformers-Need-Deep-Long-Range-Memory","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Anurag-Kumar","text":"Anurag Kumar"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Yun-Wang","text":"Yun Wang"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Vamsi-Krishna-Ithapu","text":"Vamsi Krishna Ithapu"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/Christian-Fuegen","text":"Christian Fuegen"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/15-Jul-2021","text":"15-Jul-2021"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/TALNet","text":"TALNet"},{"source":"/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning","target":"/WEANet-SUSTAIN","text":"WEANet-SUSTAIN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Mingzhou-Xu","text":"Mingzhou Xu"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Liangyou-Li","text":"Liangyou Li"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Qun-Liu","text":"Qun Liu"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/December-12th-2020","text":"December 12th 2020"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Transformer","text":"Transformer"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Intra-sentential-Relations","text":"Intra-sentential Relations"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Inter-sentential-Relations","text":"Inter-sentential Relations"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Adjacency","text":"Adjacency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Dependency","text":"Dependency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Lexical-Consistency","text":"Lexical Consistency"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Coreference","text":"Coreference"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-En-Fr","text":"IWSLT En-Fr"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/IWSLT-Zh-En","text":"IWSLT Zh-En"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/OpenSubtitles2018-En-Ru","text":"OpenSubtitles2018 En-Ru"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/WMT19-En-De","text":"WMT19 En-De"},{"source":"/Document-Graph-for-Neural-Machine-Translation","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Daiki-Takeuchi","text":"Daiki Takeuchi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yuma-Koizumi","text":"Yuma Koizumi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Yasunori-Ohishi","text":"Yasunori Ohishi"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Noboru-Harada","text":"Noboru Harada"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Kunio-Kashino","text":"Kunio Kashino"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Multi-task-Learning","text":"Multi-task Learning"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Mixup","text":"Mixup"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Beam-Search","text":"Beam Search"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Ho-Hsiang-Wu","text":"Ho-Hsiang Wu"},{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/Magdalena-Fuentes","text":"Magdalena Fuentes"},{"source":"/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION","target":"/08-Jun-2021","text":"08-Jun-2021"},{"source":"/Edge-based-Sampler","target":"/Subgraph-wise-Sampling","text":"Subgraph-wise Sampling"},{"source":"/Effective-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Te-Hsu","text":"Yi-Te Hsu"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Sarthak-Garg","text":"Sarthak Garg"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Yi-Hsiu-Liao","text":"Yi-Hsiu Liao"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Ilya-Chatsviorkin","text":"Ilya Chatsviorkin"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/December-3rd-2020","text":"December 3rd 2020"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/BLEU","text":"BLEU"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/self-attention","text":"self-attention"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Average-Attention-Network-AAN","text":"Average Attention Network (AAN)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simple-Recurrent-Unit-SRU","text":"Simple Recurrent Unit (SRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Simpler-Simple-Recurrent-Unit-SSRU","text":"Simpler Simple Recurrent Unit (SSRU)"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/L0-regularization","text":"L0 regularization"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Hard-Concrete-Distribution","text":"Hard Concrete Distribution"},{"source":"/Efficient-Inference-For-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/EigenPooling","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/EigenPooling","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Eigenvector-Centrality","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Eigenvector-Centrality","target":"/PerronFrobenius-Theorem","text":"Perron–Frobenius Theorem"},{"source":"/Eigenvector-Centrality","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Eigenvector-Centrality","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Entity-GCN","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Entity-GCN","target":"/Entity-Graph","text":"Entity Graph"},{"source":"/Entity-GCN","target":"/Softmax","text":"Softmax"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Helin-Wang","text":"Helin Wang"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Yuexian-Zou","text":"Yuexian Zou"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Dading-Chong","text":"Dading Chong"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Convolution","text":"Convolution"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Sigmoid","text":"Sigmoid"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/Accuracy","text":"Accuracy"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-10","text":"ESC-10"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/ESC-50","text":"ESC-50"},{"source":"/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention","target":"/UrbanSound8k","text":"UrbanSound8k"},{"source":"/Equivariant-Functions","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Equivariant-Functions","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Equivariant-Functions","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","target":"/Information-Retrieval","text":"Information Retrieval"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/James-Lee-Thorp","text":"James Lee-Thorp"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Joshua-Ainslie","text":"Joshua Ainslie"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Ilya-Eckstein","text":"Ilya Eckstein"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Santiago-Ontanon","text":"Santiago Ontanon"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/self-attention","text":"self-attention"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/transformer","text":"transformer"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/FNet","text":"FNet"},{"source":"/FNet-Mixing-Tokens-with-Fourier-Transforms","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Ahmad-Rashid","text":"Ahmad Rashid"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Alan-Do-Omri","text":"Alan Do-Omri"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Qun-Liu","text":"Qun Liu"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Mehdi-Rezagholizadeh","text":"Mehdi Rezagholizadeh"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/November-27th-2020","text":"November 27th, 2020"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture","text":"Bilingual Adversarial Text Generator (B-GAN) (Architecture)"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Cross-Domain-Loss","text":"Cross-Domain Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Adversarial-Loss","text":"Adversarial Loss"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/Multi30k","text":"Multi30k"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-English","text":"News Crawl 2007 English"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2007-French","text":"News Crawl 2007 French"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-English","text":"News Crawl 2010 English"},{"source":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","target":"/News-Crawl-2010-French","text":"News Crawl 2010 French"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/September-25th-2020","text":"September 25th, 2020"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Face-Recognition-Using-Eigenfaces","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ciprian-Chelba","text":"Ciprian Chelba"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Mia-Chen","text":"Mia Chen"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Ankur-Bapna","text":"Ankur Bapna"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/Noam-Shazeer","text":"Noam Shazeer"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/May-26th-2020","text":"May 26th, 2020"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","target":"/WMT18-En-De","text":"WMT18 En-De"},{"source":"/Filter-Damping","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Junliang-Guo","text":"Junliang Guo"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Xu-Tan","text":"Xu Tan"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Linli-Xu","text":"Linli Xu"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tao-Qin","text":"Tao Qin"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Enhong-Chen","text":"Enhong Chen"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Tie-Yan-Liu","text":"Tie-Yan Liu"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"},{"source":"/Flat-Graph-Pooling","target":"/Max-Pooling","text":"Max Pooling"},{"source":"/Flat-Graph-Pooling","target":"/Average-Pooling","text":"Average Pooling"},{"source":"/Flat-Graph-Pooling","target":"/Neural-Network","text":"Neural Network"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xuezhe-Ma","text":"Xuezhe Ma"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Chunting-Zhou","text":"Chunting Zhou"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Xian-Li","text":"Xian Li"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Eduard-Hovy","text":"Eduard Hovy"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Generative-Flow","text":"Generative Flow"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Invertibility","text":"invertible"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/FlowSeq","text":"FlowSeq"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Determinant","text":"Determinant"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Transformer","text":"Transformer"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/Importance-Weighted-Decoding","text":"Importance Weighted Decoding"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","target":"/IWSLT14-De-En","text":"IWSLT14 De-En"},{"source":"/Frontiers-in-Machine-Learning","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Frontiers-in-Machine-Learning","target":"/July-23rd-2020","text":"July 23rd, 2020"},{"source":"/Frontiers-in-Machine-Learning","target":"/Chris-Bishop","text":"Chris Bishop"},{"source":"/Frontiers-in-Machine-Learning","target":"/Peter-Lee","text":"Peter Lee"},{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Conversations","text":"Machine Learning Conversations"},{"source":"/Frontiers-in-Machine-Learning","target":"/Accelerating-Machine-Learning-with-Confidential-Computing","text":"Accelerating Machine Learning with Confidential Computing"},{"source":"/Frontiers-in-Machine-Learning","target":"/Security-and-Machine-Learning","text":"Security and Machine Learning"},{"source":"/Frontiers-in-Machine-Learning","target":"/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity","text":"Beyond Fairness - Pushing ML Frontiers for Social Equity"},{"source":"/Frontiers-in-Machine-Learning","target":"/Big-Ideas-in-Causality-and-Machine-Learning","text":"Big Ideas in Causality and Machine Learning"},{"source":"/Frontiers-in-Machine-Learning","target":"/Machine-Learning-Reliability-and-Robustness","text":"Machine Learning Reliability and Robustness"},{"source":"/Frontiers-in-Machine-Learning","target":"/Saving-Lives-with-Interpretable-ML","text":"Saving Lives with Interpretable ML"},{"source":"/Fuzzy-Set","target":"/T-norm","text":"T-norm"},{"source":"/Fuzzy-Set","target":"/T-conorm","text":"T-conorm"},{"source":"/Fuzzy-Sets-1965","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Fuzzy-Sets-1965","target":"/September-29th-2020","text":"September 29th, 2020"},{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Logic","text":"Fuzzy Logic"},{"source":"/Fuzzy-Sets-1965","target":"/Fuzzy-Set","text":"Fuzzy Set"},{"source":"/Fuzzy-Sets-1965","target":"/De-Morgans-Law","text":"De Morgan's Law"},{"source":"/Fuzzy-Sets-1965","target":"/Distributive-Law","text":"Distributive Law"},{"source":"/GAT-Filter","target":"/self-attention","text":"self-attention"},{"source":"/GAT-Filter","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/GCN-Filter","target":"/Cheby-Filter","text":"Cheby-Filter"},{"source":"/GCN-Filter","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/GGNN-Filter","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lihua-Qian","text":"Lihua Qian"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hao-Zhou","text":"Hao Zhou"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yu-Bao","text":"Yu Bao"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Mingxuan-Wang","text":"Mingxuan Wang"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lin-Qiu","text":"Lin Qiu"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Weinan-Zhang","text":"Weinan Zhang"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yong-Yu","text":"Yong Yu"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Lei-Li","text":"Lei Li"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Glancing-Transformer-GLAT","text":"Glancing Transformer (GLAT)"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Curriculum-Learning","text":"Curriculum Learning"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Hamming-Distance","text":"Hamming Distance"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Petar-Veli%C4%8Dkovi%C4%87","text":"Petar Veličković"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Guillem-Cucurull","text":"Guillem Cucurull"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Arantxa-Casanova","text":"Arantxa Casanova"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Adriana-Romero","text":"Adriana Romero"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pietro-Li%C3%B2","text":"Pietro Liò"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Yoshua-Bengio","text":"Yoshua Bengio"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/December-22nd-2020","text":"December 22nd 2020"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Spectral-Graph-Convolutions","text":"Spectral Graph Convolutions"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Graph-Attention-Network","text":"Graph Attention Network"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Cora","text":"Cora"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Citeseer","text":"Citeseer"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Pubmed","text":"Pubmed"},{"source":"/GRAPH-ATTENTION-NETWORKS-Paper","target":"/Protein-Protein-Interaction-data","text":"Protein-Protein Interaction data"},{"source":"/GRaph-Aware-Transformer","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"},{"source":"/GRaph-Aware-Transformer","target":"/Transformer","text":"Transformer"},{"source":"/GRaph-Aware-Transformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Antonio-Art%C3%A9s-Rodr%C3%ADguez","text":"Antonio Artés Rodríguez"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Generalized-CMAC-GCMAC","text":"Generalized CMAC (GCMAC)"},{"source":"/Generalizing-CMAC-Architecture-and-Training","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Mark-Chen","text":"Mark Chen"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Alec-Radford","text":"Alec Radford"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Rewon-Child","text":"Rewon Child"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Jeffrey-Wu","text":"Jeffrey Wu"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Heewoo-Jun","text":"Heewoo Jun"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"},{"source":"/Generative-Pretraining-from-Pixels","target":"/David-Luan","text":"David Luan"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Ilya-Sutskever","text":"Ilya Sutskever"},{"source":"/Generative-Pretraining-from-Pixels","target":"/October-19th-2020","text":"October 19th, 2020"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Unsupervised","text":"Unsupervised"},{"source":"/Generative-Pretraining-from-Pixels","target":"/GPT-2","text":"GPT-2"},{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"},{"source":"/Generative-Pretraining-from-Pixels","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/Generative-Pretraining-from-Pixels","target":"/ImageNet","text":"ImageNet"},{"source":"/GloVe-Twitter-200d","target":"/GloVe","text":"GloVe"},{"source":"/Graph-Adversarial-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Attention","target":"/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks","text":"Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks"},{"source":"/Graph-Attention","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Attention","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"},{"source":"/Graph-Attention","target":"/self-attention","text":"self-attention"},{"source":"/Graph-Attention","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Attention","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/Graph-Attention","target":"/Activation-Function","text":"Activation Function"},{"source":"/Graph-Auto-Encoders","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Auto-Encoders","target":"/Neural-Network","text":"Neural Network"},{"source":"/Graph-Auto-Encoders","target":"/Reconstruction-Loss","text":"Reconstruction Loss"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Auto-Encoders","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Convolutional-Network","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"},{"source":"/Graph-Convolutional-Network","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graph-Convolutional-Network","target":"/Undirected","text":"Undirected"},{"source":"/Graph-Convolutional-Network","target":"/Activation-Function","text":"Activation Function"},{"source":"/Graph-Convolutional-Network","target":"/Complexity","text":"Complexity"},{"source":"/Graph-Fourier-Transform","target":"/Fourier-Transform","text":"Fourier Transform"},{"source":"/Graph-Fourier-Transform","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Graph-Isomorphism-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism-Networks","target":"/Graph-Isomorphism","text":"Graph Isomorphism"},{"source":"/Graph-Isomorphism-Networks","target":"/Injective","text":"Injective"},{"source":"/Graph-Isomorphism-Networks","target":"/Aggregator-Functions","text":"aggregator"},{"source":"/Graph-Isomorphism-Networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-Isomorphism-Networks","target":"/Universal-Approximation-Theorem","text":"Universal Approximation Theorem"},{"source":"/Graph-Isomorphism","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Isomorphism","target":"/Isomorphism","text":"Isomorphism"},{"source":"/Graph-Isomorphism","target":"/NP-Intermediate","text":"NP-Intermediate"},{"source":"/Graph-Isomorphism","target":"/Weisfieler-Lehman-test","text":"Weisfieler-Lehman test"},{"source":"/Graph-Neural-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Neural-Networks","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Graph-Neural-Networks","target":"/NP-Hard","text":"NP-Hard"},{"source":"/Graph-Neural-Networks","target":"/Polynomial-time","text":"Polynomial-time"},{"source":"/Graph-Neural-Networks","target":"/Aggregator-Functions","text":"Aggregator Functions"},{"source":"/Graph-Neural-Networks","target":"/Over-Squashing","text":"Over-Squashing"},{"source":"/Graph-Neural-Networks","target":"/Fully-Connected-Graph","text":"Fully Connected Graph"},{"source":"/Graph-Neural-Networks","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Graph-Pooling","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Graph-Pooling","target":"/Pooling","text":"Pooling"},{"source":"/Graph-Pooling","target":"/Graclus","text":"Graclus"},{"source":"/Graph-Pooling","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Graph-Positional-Encodings","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Positional-Encodings","target":"/Index-Positional-Encoding","text":"Index Positional Encoding"},{"source":"/Graph-Positional-Encodings","target":"/Structural-Message-Passing-Networks","text":"Structural Message-Passing Networks"},{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Positional-Encodings","text":"Laplacian Positional Encodings"},{"source":"/Graph-Positional-Encodings","target":"/Spectral-Graph-Theory","text":"Spectral Graph Theory"},{"source":"/Graph-Positional-Encodings","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Graph-Positional-Encodings","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Graph-Positional-Encodings","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Positional-Encodings","target":"/Positional-Encodings","text":"Positional Encodings"},{"source":"/Graph-Purification","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Reordering","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/Graph-Structure-Learning","target":"/Graph-Adversarial-Defense","text":"Graph Adversarial Defense"},{"source":"/Graph-Substructure-Networks","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Graph-Substructure-Networks","target":"/Cycles","text":"Cycles"},{"source":"/Graph-Substructure-Networks","target":"/Cliques","text":"Cliques"},{"source":"/Graph-Substructure-Networks","target":"/Clusters","text":"Clusters"},{"source":"/Graph-Substructure-Networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graph-Substructure-Networks","target":"/Isomorphism","text":"Isomorphism"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Sanghyun-Yoo","text":"Sanghyun Yoo"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Seok-Kim","text":"Young-Seok Kim"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kang-Hyun-Lee","text":"Kang Hyun Lee"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Kuhwan-Jeong","text":"Kuhwan Jeong"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Junhwi-Choi","text":"Junhwi Choi"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Hoshik-Lee","text":"Hoshik Lee"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Young-Sang-Choi","text":"Young Sang Choi"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/December-20th-2020","text":"December 20th 2020"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRaph-Aware Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/GRaph-Aware-Transformer","text":"GRAT"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Transformer","text":"Transformer"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/BERT","text":"BERT"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Node-and-Edge-Modelling","text":"Masked Node and Edge Modelling"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Graph-Property-Prediction","text":"Graph Property Prediction"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Next-Sentence-Prediction","text":"Next Sentence Prediction"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/QM9","text":"QM9"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/Message-Passing-Networks","text":"Message-Passing Networks"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/DimeNet","text":"DimeNet"},{"source":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","target":"/USPTO","text":"USPTO"},{"source":"/Graph-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Graph-LSTM","target":"/Tree-LSTM","text":"Tree-LSTM"},{"source":"/Graph-LSTM","target":"/Breadth-First-Search","text":"Breadth-First Search"},{"source":"/Graph-LSTM","target":"/Depth-First-Search","text":"Depth-First Search"},{"source":"/Graph-Transformer","target":"/Graph-to-Sequence-Neural-Machine-Translation","text":"Graph-to-Sequence Neural Machine Translation"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Graph-Transformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Sufeng-Duan","text":"Sufeng Duan"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Hai-Zhao","text":"Hai Zhao"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Rui-Wang","text":"Rui Wang"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/January-4th-2021","text":"January 4th 2021"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Graph-Transformer","text":"Graph-Transformer"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/Multi-dimensional-Graphs","text":"Multi-dimensional Graphs"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Graph-to-Sequence-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/GraphAT","target":"/Graph-Adversarial-Learning","text":"Graph Adversarial Learning"},{"source":"/GraphSAGE-Filter","target":"/LSTM","text":"LSTM"},{"source":"/GraphSAGE-Filter","target":"/Pooling","text":"Pooling"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aditya-Grover","text":"Aditya Grover"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Aaron-Zweig","text":"Aaron Zweig"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Stefano-Ermon","text":"Stefano Ermon"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/December-22nd-2020","text":"December 22nd 2020"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Unsupervised","text":"Unsupervised"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Cora","text":"Cora"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Citeseer","text":"Citeseer"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Pubmed","text":"Pubmed"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Graphite-Iterative-Generative-Modeling-of-Graphs","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-AE","target":"/Auto-Encoders","text":"Auto-Encoders"},{"source":"/Graphite-AE","target":"/Graphite","text":"Graphite"},{"source":"/Graphite-VAE","target":"/Variational-Auto-Encoder","text":"Variational Auto-Encoder"},{"source":"/Graphite-VAE","target":"/Graphite","text":"Graphite"},{"source":"/Graphite","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"},{"source":"/Graphite","target":"/Probabilistic-Modeling","text":"Probabilistic Modeling"},{"source":"/Graphite","target":"/Representation-learning","text":"Representation learning"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Graph-Structure-Learning","text":"Graph Structure Learning"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Graphite","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Graphite","target":"/Associative","text":"Associative"},{"source":"/Graphite","target":"/Graphite-VAE","text":"Graphite-VAE"},{"source":"/Graphite","target":"/Graphite-AE","text":"Graphite-AE"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Qiu-Ran","text":"Qiu Ran"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Yankai-Lin","text":"Yankai Lin"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Peng-Li","text":"Peng Li"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/May-23rd-2020","text":"May 23rd, 2020"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST02","text":"NIST02"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST03","text":"NIST03"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST04","text":"NIST04"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST05","text":"NIST05"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST06","text":"NIST06"},{"source":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","target":"/NIST08","text":"NIST08"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Nguyen-Cat-Ho","text":"Nguyen Cat Ho"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Wolfgang-Wechler","text":"Wolfgang Wechler"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","target":"/Linguistic-Hedges","text":"Linguistic Hedges"},{"source":"/Hierarchical-Softmax","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Structural-Role","text":"Structural Role"},{"source":"/Hierarchical-Structural-Similarity-Measure","target":"/Dynamic-Time-Warping-DTW","text":"Dynamic Time Warping (DTW)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Sintiani-Teddy","text":"Sintiani Teddy"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchical-Clustering","text":"Hierarchical Clustering"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Agglomerative-Hierarchical-Clustering","text":"Agglomerative Hierarchical Clustering"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Widrow-Hoff","text":"Widrow-Hoff"},{"source":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture","text":"Hierarchically Clustered Adaptive Quantization CMAC (HCAQ-CMAC) (Architecture)"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Kawin-Ethayarajh","text":"Kawin Ethayarajh"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/October-11th-2019","text":"October 11th, 2019"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Isotropy","text":"Isotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Embeddings","text":"Embeddings"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"Anisotropy"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Anisotropy","text":"anisotrophic"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/ELMo","text":"ELMo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/Elmo","text":"Elmo"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GloVe","text":"GloVe"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/FastText","text":"FastText"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/BERT","text":"BERT"},{"source":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","target":"/GPT-2","text":"GPT-2"},{"source":"/Hypergraphs","target":"/Incidence-Matrix","text":"Incidence Matrix"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Turab-Iqbal","text":"Turab Iqbal"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Yin-Cao","text":"Yin Cao"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Wenwu-Wang","text":"Wenwu Wang"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/May-3rd-2021","text":"May 3rd 2021"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Acoustic-Scene-Classification","text":"Acoustic Scene Classification"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/AudioCaps","text":"AudioCaps"},{"source":"/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","target":"/October-10th-2020","text":"October 10th, 2020"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/September-23rd-2020","text":"September 23rd, 2020"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Neural-Network","text":"Neural Network"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","target":"/Fuzzy-Logic-Controllers","text":"Fuzzy Logic Controllers"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Kai-Keng-Ang","text":"Kai Keng Ang"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Cerebellar-Model-Articulation-Controller-CMAC","text":"Cerebellar Model Articulation Controller (CMAC)"},{"source":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","target":"/Modified-CMAC-MCMAC-Architecture","text":"Modified CMAC (MCMAC) (Architecture)"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Jiawei-Zhou","text":"Jiawei Zhou"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/Phillip-Keung","text":"Phillip Keung"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/May-25th-2020","text":"May 25th, 2020"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/William-Chan","text":"William Chan"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Chitwan-Saharia","text":"Chitwan Saharia"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Navdeep-Jaitly","text":"Navdeep Jaitly"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/August-15th-2020","text":"August 15th, 2020"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imputer","text":"Imputer"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Imitation-Learning","text":"Imitation Learning"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Wall-Street-Journal","text":"Wall Street Journal"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Character-Error-Rate-CER","text":"Character Error Rate (CER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Inductive-Biases","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Information-Theoretic-Probing","target":"/Information-Theoretic-Probing","text":"Information-Theoretic Probing"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mitchell-Stern","text":"Mitchell Stern"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/William-Chan","text":"William Chan"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jamie-Kiros","text":"Jamie Kiros"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/August-18th-2020","text":"August 18th, 2020"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Binary-Tree","text":"Binary Tree"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/self-attention","text":"self-attention"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Mixture-of-Softmaxes","text":"Mixture of Softmaxes"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/Softmax","text":"Softmax"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Integrated-Gradient-Guided-Attack","target":"/Fast-Gradient-Sign-Method","text":"Fast Gradient Sign Method"},{"source":"/Inter-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Inter-sentential-Relations","target":"/Lexical-Consistency","text":"Lexical Consistency"},{"source":"/Inter-sentential-Relations","target":"/Coreference","text":"Coreference"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Jorge-Casillas","text":"Jorge Casillas"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Oscar-Cordon","text":"Oscar Cordon"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Francisco-Herrera","text":"Francisco Herrera"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Luis-Magdalena","text":"Luis Magdalena"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/September-29th-2020","text":"September 29th, 2020"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Interpretability","text":"Interpretability"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Accuracy","text":"Accuracy"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Principle-of-Incompatibility","text":"Principle of Incompatibility"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Lotfi-Asker-Zadeh","text":"Lotfi Asker Zadeh"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Linguistic-Fuzzy-Logic","text":"Linguistic [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs","text":"Takagi-Sugeno-Kang-type Fuzzy Rule-Based Systems (TSK-type FRBSs)"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Precise-Fuzzy-Logic","text":"Precise [[Fuzzy Logic"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Orthogonality","text":"orthogonal"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Least-Squares-Solution-for-Inconsistent-Equations","text":"Least Squares Solution for Inconsistent Equations"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR","text":"Singular value decomposition and QR with column pivoting methods (SVD-QR)"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Singleton-Fuzzy-Rule-Based-Systems","text":"Singleton Fuzzy Rule-Based Systems"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Fuzzy-Rule-Based-Classification-System","text":"Fuzzy Rule-Based Classification System"},{"source":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","target":"/Approximate-Rule-Based-Systems","text":"Approximate Rule-Based Systems"},{"source":"/Intra-sentential-Relations","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Intra-sentential-Relations","target":"/Adjacency","text":"Adjacency"},{"source":"/Intra-sentential-Relations","target":"/Dependency","text":"Dependency"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Martin-Schmitt","text":"Martin Schmitt"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Hinrich-Sch%C3%BCtze","text":"Hinrich Schütze"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Iryna-Gurevych","text":"Iryna Gurevych"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/January-6th-2021","text":"January 6th 2021"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/BART","text":"BART"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Text-To-Text-Transfer-Transformer","text":"T5"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/AGENDA","text":"AGENDA"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/language-model","text":"language model"},{"source":"/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Alessandra-Cervone","text":"Alessandra Cervone"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Giuseppe-Riccardi","text":"Giuseppe Riccardi"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/SwitchBoard","text":"SwitchBoard"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Weighted-Kappa-Agreement","text":"Weighted Kappa Agreement"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Multiple-Regression-Analysis","text":"Multiple Regression Analysis"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/Gated-Recurrent-Unit","text":"Gated Recurrent Unit"},{"source":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Isotropy","target":"/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings","text":"How Contextual are Contextualized Word Representations - Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"},{"source":"/Isotropy","target":"/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works","text":"A Primer in BERTology - What We Know About How BERT Works"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jason-Lee","text":"Jason Lee"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Raphael-Shu","text":"Raphael Shu"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Kyunghyun-Cho","text":"Kyunghyun Cho"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/September-18th-2020","text":"September 18th, 2020"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Energy","text":"Energy"},{"source":"/July-3rd-2020","target":"/Takeaways","text":"Takeaway(s)"},{"source":"/July-3rd-2020","target":"/Zhou-Yu","text":"Zhou Yu"},{"source":"/July-3rd-2020","target":"/JSALT2020","text":"JSALT2020"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/William-Chan","text":"William Chan"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Nikita-Kitaev","text":"Nikita Kitaev"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kelvin-Guu","text":"Kelvin Guu"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Mitchell-Stern","text":"Mitchell Stern"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Jakob-Uszkoreit","text":"Jakob Uszkoreit"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/August-20th-2020","text":"August 20th, 2020"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Eigenvector-Centrality","text":"Eigenvector Centrality"},{"source":"/Katz-Centrality","target":"/Invertibility","text":"Invertibility"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/G%C3%A1bor-Horv%C3%A1th","text":"Gábor Horváth"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Tam%C3%A1s-Szab%C3%B3","text":"Tamás Szabó"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/November-9th-2020","text":"November 9th, 2020"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Kernel-CMAC-Architecture","text":"Kernel CMAC (Architecture)"},{"source":"/Kernel-CMAC-With-Improved-Capability","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Federico-Bianchi","text":"Federico Bianchi"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Gaetano-Rossiello","text":"Gaetano Rossiello"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Luca-Constabello","text":"Luca Constabello"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Matteo-Palmonari","text":"Matteo Palmonari"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Pasquale-Minervini","text":"Pasquale Minervini"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/December-28th-2020","text":"December 28th 2020"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Translational-Models","text":"Translational Models#Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Bilinear-Models","text":"Bilinear Models#Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Path","text":"Path"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/word2vec","text":"word2vec"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Mean-Reciprocal-Rank","text":"Mean Reciprocal Rank"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Explainability","text":"Explainability"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graph-Embeddings-and-Explainable-AI","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/Knowledge-Graphs-Embeddings","target":"/Link-Prediction","text":"Link Prediction"},{"source":"/Knowledge-Graphs","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Knowledge-Graphs","target":"/Ontology","text":"Ontology"},{"source":"/Knowledge-Graphs","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Knowledge-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Mahdi-Namazifar","text":"Mahdi Namazifar"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Alexandros-Papangelis","text":"Alexandros Papangelis"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Gokhan-Tur","text":"Gokhan Tur"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Dilek-Hakkani-T%C3%BCr","text":"Dilek Hakkani-Tür"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/December-1st-2020","text":"December 1st 2020"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Natural-Langauge-Understanding","text":"Natural Langauge Understanding"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Slot-Detection","text":"Slot Detection"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Intent-Detection","text":"Intent Detection"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/ATIS","text":"ATIS"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Restaurants-8k","text":"Restaurants-8k"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Question-Answering","text":"Question Answering"},{"source":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","target":"/Text-To-Text-Transfer-Transformer","text":"Text-To-Text Transfer Transformer"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Chenguang-Wang","text":"Chenguang Wang"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Xiao-Liu","text":"Xiao Liu"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/December-21st-2020","text":"December 21st 2020"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/language-model","text":"language model"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Unsupervised","text":"Unsupervised"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"Match and Map"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/TAC-Knowledge-Base-Population","text":"TAC Knowledge Base Population"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Match-and-Map","text":"MaMa"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Wikidata","text":"Wikidata"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/Named-Entity-Recognition","text":"Named Entity Recognition"},{"source":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","target":"/spaCy","text":"spaCy"},{"source":"/LIAR-Politifact","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Su-Lin-Blodgett","text":"Su Lin Blodgett"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Solon-Barocas","text":"Solon Barocas"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hal-Daum%C3%A9-III","text":"Hal Daumé III"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/Hanna-Wallach","text":"Hanna Wallach"},{"source":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","target":"/May-30th-2020","text":"May 30th, 2020"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Mann","text":"Benjamin Mann"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Nick-Ryder","text":"Nick Ryder"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Melanie-Subbiah","text":"Melanie Subbiah"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jared-Kaplan","text":"Jared Kaplan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Prafulla-Dhariwal","text":"Prafulla Dhariwal"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Arvind-Neelakantan","text":"Arvind Neelakantan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Pranav-Shyam","text":"Pranav Shyam"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Girish-Sastry","text":"Girish Sastry"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Amanda-Askell","text":"Amanda Askell"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sandhini-Agarwal","text":"Sandhini Agarwal"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ariel-Herbert-Voss","text":"Ariel Herbert-Voss"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Gretchen-Krueger","text":"Gretchen Krueger"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Tom-Henighan","text":"Tom Henighan"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Rewon-Child","text":"Rewon Child"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Aditya-Ramesh","text":"Aditya Ramesh"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jeffrey-Wu","text":"Jeffrey Wu"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Clemens-Winter","text":"Clemens Winter"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Hesse","text":"Christopher Hesse"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mark-Chen","text":"Mark Chen"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Eric-Sigler","text":"Eric Sigler"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Mateusz-Litwin","text":"Mateusz Litwin"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Scott-Gray","text":"Scott Gray"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Benjamin-Chess","text":"Benjamin Chess"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Jack-Clark","text":"Jack Clark"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Christopher-Berner","text":"Christopher Berner"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Sam-McCandlish","text":"Sam McCandlish"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Alec-Radford","text":"Alec Radford"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Ilya-Sutskever","text":"Ilya Sutskever"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Dario-Amodei","text":"Dario Amodei"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/June-3rd-2020","text":"June 3rd, 2020"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/LAMBADA","text":"LAMBADA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/TriviaQA","text":"TriviaQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-2","text":"GPT-2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/GPT-3","text":"GPT-3"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winograd","text":"Winograd"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/Winogrande","text":"Winogrande"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/PIQA","text":"PIQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ARC","text":"ARC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/CoQA","text":"CoQA"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/DROP","text":"DROP"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/QuAC","text":"QuAC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SQuADv2","text":"SQuADv2"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/RACE","text":"RACE"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/SuperGLUE-Benchmark","text":"SuperGLUE Benchmark"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/WiC","text":"WiC"},{"source":"/Language-Models-are-Few-Shot-Learners","target":"/ANLI","text":"ANLI"},{"source":"/Laplacian-Filter","target":"/Laplace-operator","text":"Laplace operator"},{"source":"/Laplacian-Matrix","target":"/Spanning-Tree","text":"Spanning Tree"},{"source":"/Laplacian-Matrix","target":"/Machine-Learning","text":"Machine Learning"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Symmetric","text":"Symmetric"},{"source":"/Laplacian-Matrix","target":"/Degree","text":"Degree"},{"source":"/Laplacian-Matrix","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Laplacian-Matrix","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Laplacian-Matrix","target":"/Simple-Graph","text":"Simple Graph"},{"source":"/Laplacian-Matrix","target":"/Connected-Component","text":"Connected Component"},{"source":"/Laplacian-of-Gaussian-Filter","target":"/Laplace-operator","text":"Laplace operator"},{"source":"/Large-Scale-Information-Network-Embedding-LINE","target":"/node2vec","text":"node2vec"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Chun-Shin-Lin","text":"Chun-Shin Lin"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/Ching-Tsan-Chiang","text":"Ching-Tsan Chiang"},{"source":"/Learning-Convergence-of-CMAC-Technique","target":"/November-8th-2020","text":"November 8th, 2020"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Gurunath-Reddy-Madhumani","text":"Gurunath Reddy Madhumani"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sanket-Shah","text":"Sanket Shah"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Basil-Abraham","text":"Basil Abraham"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Vikas-Joshi","text":"Vikas Joshi"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Sunayana-Sitaram","text":"Sunayana Sitaram"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/June-17th-2020","text":"June 17th, 2020"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Learning-Without-Forgetting","text":"Learning Without Forgetting"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Code-Mixing-Index-CMI","text":"Code Mixing Index (CMI)"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/BiLSTM","text":"BiLSTM"},{"source":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Qiu-Ran","text":"Qiu Ran"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Yankai-Lin","text":"Yankai Lin"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Peng-Li","text":"Peng Li"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Jie-Zhou","text":"Jie Zhou"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/June-15th-2020","text":"June 15th, 2020"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/August-25th-2020","text":"August 25th, 2020"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-Ro-En","text":"newsdev2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newsdev2016-En-Ro","text":"newsdev2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Sequence-Refinement","text":"Sequence Refinement"},{"source":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Lecture-1","target":"/August-12th-2020","text":"August 12th, 2020"},{"source":"/Lexical-Consistency","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Linearized-Graph","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Pan-Yaozhang","text":"Pan Yaozhang"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Jane-Shen","text":"Jane Shen"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Laurence-Liew","text":"Laurence Liew"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Yap-Kim-Hui","text":"Yap Kim Hui"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Sim-Kai","text":"Sim Kai"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/October-12th-2020","text":"October 12th, 2020"},{"source":"/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World","target":"/Simon-See","text":"Simon See"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Emre-Cakir","text":"Emre Cakir"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/SPIDEr","text":"SPIDEr"},{"source":"/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Huy-Le-Nguyen","text":"Huy Le Nguyen"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION","target":"/31-May-2021","text":"31-May-2021"},{"source":"/Machine-Learning-Conversations","target":"/Susan-Dumais","text":"Susan Dumais"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Conversations","target":"/MineRL-competition","text":"MineRL competition"},{"source":"/Machine-Learning-Conversations","target":"/Meta-Reinforcement-Learning","text":"Meta Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Variational-Deep-Reinforcement-Learning-VariBad","text":"Variational Deep Reinforcement Learning (VariBad)"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Representation-learning","text":"Representation learning"},{"source":"/Machine-Learning-Conversations","target":"/Homer","text":"Homer"},{"source":"/Machine-Learning-Conversations","target":"/FLAMBE","text":"FLAMBE"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Conditional-Language-Modelling","text":"Conditional Language Modelling"},{"source":"/Machine-Learning-Conversations","target":"/exposure-bias","text":"exposure bias"},{"source":"/Machine-Learning-Conversations","target":"/bottleneck-issues","text":"bottleneck issues"},{"source":"/Machine-Learning-Conversations","target":"/cross-entropy","text":"cross entropy"},{"source":"/Machine-Learning-Conversations","target":"/BLEU","text":"BLEU"},{"source":"/Machine-Learning-Conversations","target":"/ROUGE","text":"ROUGE"},{"source":"/Machine-Learning-Conversations","target":"/GPT-2","text":"GPT-2"},{"source":"/Machine-Learning-Conversations","target":"/Casual-Language-Modelling","text":"Casual Language Modelling"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/cross-validation","text":"cross validation"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Akshay-Krishnamurthy","text":"Akshay Krishnamurthy"},{"source":"/Machine-Learning-Conversations","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Machine-Learning-Conversations","target":"/Asli-Celikyilmaz","text":"Asli Celikyilmaz"},{"source":"/Machine-Learning-Conversations","target":"/Dan-Klein","text":"Dan Klein"},{"source":"/Machine-Learning-Conversations","target":"/Katja-Hofmann","text":"Katja Hofmann"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Besmira-Nushi","text":"Besmira Nushi"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/July-22nd-2020","text":"July 22nd, 2020"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Computer-Vision","text":"Computer Vision"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Ece-Kamar","text":"Ece Kamar"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Thomas-Dietterich","text":"Thomas Dietterich"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Suchi-Saria","text":"Suchi Saria"},{"source":"/Machine-Learning-Reliability-and-Robustness","target":"/Transportability","text":"Transportability"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Marjan-Ghazvininejad","text":"Marjan Ghazvininejad"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Omer-Levy","text":"Omer Levy"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Yinhan-Liu","text":"Yinhan Liu"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Luke-Zettlemoyer","text":"Luke Zettlemoyer"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/August-22nd-2020","text":"August 22nd, 2020"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Transformer","text":"Transformer"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-En-Zh","text":"WMT17 En-Zh"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/WMT17-Zh-En","text":"WMT17 Zh-En"},{"source":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","target":"/BERT","text":"BERT"},{"source":"/Masked-Graph-Modelling","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/Match-and-Map","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"},{"source":"/Match-and-Map","target":"/Knowledge-Graphs","text":"Knowledge Graphs"},{"source":"/Match-and-Map","target":"/Wikidata","text":"Wikidata"},{"source":"/Match-and-Map","target":"/Beam-Search","text":"Beam Search"},{"source":"/Maximum-Receptive-Field","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Dorin-Comaniciu","text":"Dorin Comaniciu"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Peter-Meer","text":"Peter Meer"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Estimate","text":"Mean Shift Estimate"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Bilateral-Filtering","text":"Bilateral Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Filtering","text":"Mean Shift Filtering"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Mean-Shift-Segmentation","text":"Mean Shift Segmentation"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Attraction-Force-Field","text":"Attraction Force Field"},{"source":"/Mean-Shift-Analysis-and-Applications","target":"/Edge-Flow-Propagation","text":"Edge Flow Propagation"},{"source":"/Meta-Reinforcement-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Meta-Reinforcement-Learning","target":"/meta-learning","text":"meta-learning"},{"source":"/Metattack","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Metattack","target":"/Poisoning-Attack","text":"Poisoning Attack"},{"source":"/Metattack","target":"/bi-level-optimization","text":"bi-level optimization"},{"source":"/Metattack","target":"/Meta-Gradients","text":"Meta-Gradients"},{"source":"/Metattack","target":"/meta-learning","text":"meta-learning"},{"source":"/Misinformation-has-High-Perplexity","target":"/Nayeon-Lee","text":"Nayeon Lee"},{"source":"/Misinformation-has-High-Perplexity","target":"/Yejin-Bang","text":"Yejin Bang"},{"source":"/Misinformation-has-High-Perplexity","target":"/Andrea-Madotto","text":"Andrea Madotto"},{"source":"/Misinformation-has-High-Perplexity","target":"/Pascale-Fung","text":"Pascale Fung"},{"source":"/Misinformation-has-High-Perplexity","target":"/June-16th-2020","text":"June 16th, 2020"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-scientific","text":"Covid19-scientific"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19-politifact","text":"Covid19-politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/FEVER","text":"FEVER"},{"source":"/Misinformation-has-High-Perplexity","target":"/BERT","text":"BERT"},{"source":"/Misinformation-has-High-Perplexity","target":"/LIAR-Politifact","text":"LIAR-Politifact"},{"source":"/Misinformation-has-High-Perplexity","target":"/GPT-2","text":"GPT-2"},{"source":"/Misinformation-has-High-Perplexity","target":"/Covid19","text":"Covid19"},{"source":"/Mixup","target":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","text":"mixup - BEYOND EMPIRICAL RISK MINIMIZATION"},{"source":"/Mo-Filter","target":"/Mixture-Model-Network-MoNet","text":"Mixture Model Network (MoNet)"},{"source":"/Mo-Filter","target":"/Degree","text":"Degree"},{"source":"/Mo-Filter","target":"/Gaussian-Kernel","text":"Gaussian Kernel"},{"source":"/Mo-Filter","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Mo-Filter","target":"/Convolution","text":"Convolution"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Shu-wen-Yang","text":"Shu-wen Yang"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-Han-Chi","text":"Po-Han Chi"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Po-chun-Hsu","text":"Po-chun Hsu"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Hung-yi-Lee","text":"Hung-yi Lee"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Mockingjay","text":"Mockingjay"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Masked-Acoustic-Modelling","text":"Masked Acoustic Modelling"},{"source":"/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders","target":"/Manhattan-Distance","text":"L1 norm"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Regina-Barzilay","text":"Regina Barzilay"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Mirella-Lapata","text":"Mirella Lapata"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Modeling-Local-Coherence-An-Entity-Based-Approach","target":"/Entity-Grid","text":"Entity Grid"},{"source":"/Multi-dimensional-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Multi30k","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Pawe%C5%82-Budzianowski","text":"Paweł Budzianowski"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Tsung-Hsien-Wen","text":"Tsung-Hsien Wen"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Bo-Hsiang-Tseng","text":"Bo-Hsiang Tseng"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/I%C3%B1igo-Casanueva","text":"Iñigo Casanueva"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Stefan-Ultes","text":"Stefan Ultes"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Osman-Ramadan","text":"Osman Ramadan"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Milica-Ga%C5%A1i%C4%87","text":"Milica Gašić"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/June-18th-2020","text":"June 18th, 2020"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/Dialogue-Modelling","text":"Dialogue Modelling"},{"source":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","target":"/SFX-restaurant","text":"SFX restaurant"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Harris-Chan","text":"Harris Chan"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Jamie-Kiros","text":"Jamie Kiros"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/William-Chan","text":"William Chan"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/August-21st-2020","text":"August 21st, 2020"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Multi30k","text":"Multi30k"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/BLEU","text":"BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Self-BLEU","text":"Self-BLEU"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT","text":"Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Zhuangzhuang-Liu","text":"Zhuangzhuang Liu"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Junyan-Fang","text":"Junyan Fang"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Xiaofeng-Hong","text":"Xiaofeng Hong"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/Gang-Liu","text":"Gang Liu"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/Multisystem-fusion-model-based-on-tag-relationship","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Ilaria-Manco","text":"Ilaria Manco"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Emmanouil-Benetos","text":"Emmanouil Benetos"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Elio-Quinton","text":"Elio Quinton"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Gyorgy-Fazekas","text":"Gyorgy Fazekas"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/May-10th-2021","text":"May 10th 2021"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Music-Captioning","text":"Music Captioning"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/GloVe","text":"GloVe"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/Soft-Attention","text":"Soft Attention"},{"source":"/MusCaps-Generating-Captions-for-Music-Audio","target":"/LSTM","text":"LSTM"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Detlef-Nauck","text":"Detlef Nauck"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Rudolf-Kruse","text":"Rudolf Kruse"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/October-31st-2020","text":"October 31st, 2020"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/Fuzzy-Perceptron","text":"Fuzzy Perceptron"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/NEFCLASS-Architecture","text":"NEFCLASS (Architecture)"},{"source":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","target":"/IRIS-dataset","text":"IRIS dataset"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/James-Bradbury","text":"James Bradbury"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Caiming-Xiong","text":"Caiming Xiong"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Richard-Socher","text":"Richard Socher"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/fertilities","text":"fertilities"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Noisy-Parallel-Decoding-NPD","text":"Noisy Parallel Decoding (NPD)"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/BLEU","text":"BLEU"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2013-De-En","text":"newstest2013 De-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-En-Ro","text":"newstest2016 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/newstest2016-Ro-En","text":"newstest2016 Ro-En"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","target":"/IWSLT16-En-De","text":"IWSLT16 En-De"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bo-An","text":"Bo An"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/November-17th-2020","text":"November 17th, 2020"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Janice-Lee-Ser-Huey","text":"Janice Lee Ser Huey"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Telecoupling","text":"Telecoupling"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/CART","text":"CART"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Random-Forest","text":"Random Forest"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Gerard-Goggin","text":"Gerard Goggin"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Andrew-Prahl","text":"Andrew Prahl"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Melvin-Chen","text":"Melvin Chen"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Bayesian-Belief-Networks","text":"Bayesian Belief Networks"},{"source":"/NTU-AI+X-Symposium-AI-for-Social-Good","target":"/Qian-Hangwei","text":"Qian Hangwei"},{"source":"/Negative-Sampling","target":"/Noise-Contrasitive-Estimation-NCE","text":"Noise Contrasitive Estimation (NCE)"},{"source":"/Negative-Sampling","target":"/Softmax","text":"Softmax"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Negative-Sampling","target":"/DeepWalk","text":"DeepWalk"},{"source":"/Negative-Sampling","target":"/Negative-Sampling","text":"Negative Sampling"},{"source":"/Neighborhood-Explosion","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/Nettack","target":"/Gray-box-attack","text":"Gray-box attack"},{"source":"/Nettack","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Uri-Shaham","text":"Uri Shaham"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Omer-Levy","text":"Omer Levy"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/September-19th-2020","text":"September 19th, 2020"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/IWSLT","text":"IWSLT"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"orthogonal"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Orthogonality","text":"Orthogonality"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/BLEU","text":"BLEU"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Neural-Machine-Translation-without-Embeddings","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Longteng-Guo","text":"Longteng Guo"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jing-Liu","text":"Jing Liu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/XinXin-Zhu","text":"XinXin Zhu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Xingjian-He","text":"Xingjian He"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Jie-Jiang","text":"Jie Jiang"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Hanqing-Lu","text":"Hanqing Lu"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/August-24th-2020","text":"August 24th, 2020"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactuals-Critical-MultiAgent-Learning-CMAL","text":"Counterfactuals-Critical MultiAgent Learning (CMAL)"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Image-Captioning","text":"Image Captioning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Multi-Agent","text":"Multi-Agent"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/REINFORCE","text":"REINFORCE"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/Counterfactual","text":"Counterfactual"},{"source":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","target":"/MSCOCO","text":"MSCOCO"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Chitwan-Saharia","text":"Chitwan Saharia"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/William-Chan","text":"William Chan"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Saurabh-Saxena","text":"Saurabh Saxena"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Mohammad-Norouzi","text":"Mohammad Norouzi"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Latent-Alignment-Models","text":"Latent Alignment Models"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Connectionist-Temporal-Classification-CTC","text":"Connectionist Temporal Classification (CTC)"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Imputer","text":"Imputer"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-Ro-En","text":"WMT16 Ro-En"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/WMT16-En-Ro","text":"WMT16 En-Ro"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/BLEU","text":"BLEU"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Dynamic-Programming","text":"Dynamic Programming"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Speech-Recognition","text":"Speech Recognition"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Yu-Bao","text":"Yu Bao"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Hao-Zhou","text":"Hao Zhou"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiangtao-Feng","text":"Jiangtao Feng"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Mingxuan-Wang","text":"Mingxuan Wang"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Shujian-Huang","text":"Shujian Huang"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Jiajun-Chen","text":"Jiajun Chen"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Lei-Li","text":"Lei Li"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/August-14th-2020","text":"August 14th, 2020"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Position-Non-Autoregressive-Transformers-PNAT","text":"Position Non-Autoregressive Transformers (PNAT)"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Monte-Carlo","text":"Monte Carlo"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/newstest2014-De-En","text":"newstest2014 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/IWSLT16-De-En","text":"IWSLT16 De-En"},{"source":"/Non-Autoregressive-Transformer-by-Position-Learning","target":"/Quora-Question-Pairs","text":"Quora Question Pairs"},{"source":"/Ontology","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Optimized-Product-Quantization","target":"/Tiezheng-Ge","text":"Tiezheng Ge"},{"source":"/Optimized-Product-Quantization","target":"/Kaiming-He","text":"Kaiming He"},{"source":"/Optimized-Product-Quantization","target":"/Qifa-Ke","text":"Qifa Ke"},{"source":"/Optimized-Product-Quantization","target":"/Jian-Sun","text":"Jian Sun"},{"source":"/Optimized-Product-Quantization","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/Optimized-Product-Quantization","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/Optimized-Product-Quantization","target":"/Vector-Quantization","text":"Vector Quantization"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Bayan-Abu-Shawar","text":"Bayan Abu Shawar"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Jo%C3%A3o-Sedoc","text":"João Sedoc"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Mean-Squared-Error","text":"Mean Squared Error"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/datasets","text":"datasets"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/IRIS-dialogue-system","text":"IRIS dialogue system"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","target":"/BERT","text":"BERT"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Yuiko-Tsunomori","text":"Yuiko Tsunomori"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Tetsuro-Takahashi","text":"Tetsuro Takahashi"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/Nobuhiro-Kaji","text":"Nobuhiro Kaji"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/PENMAN","target":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","text":"Promoting Graph Awareness in Linearized Graph-to-Text Generation"},{"source":"/PGD-Topology-Attack","target":"/Carlili-Wagner-Loss","text":"CW loss"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Sintiani-Teddy","text":"Sintiani Teddy"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Chai-Quek","text":"Chai Quek"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Edmun-M-K-Lai","text":"Edmun M-K Lai"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/November-9th-2020","text":"November 9th, 2020"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture","text":"Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)"},{"source":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","target":"/Widrow-Hoff","text":"Widrow-Hoff"},{"source":"/Path","target":"/Walk","text":"Walk"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Saizheng-Zhang","text":"Saizheng Zhang"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Emily-Dinan","text":"Emily Dinan"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jack-Urbanek","text":"Jack Urbanek"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Arthur-Szlam","text":"Arthur Szlam"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Douwe-Kiela","text":"Douwe Kiela"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","target":"/PersonaChat","text":"PersonaChat"},{"source":"/Principal-Neighbourhood-Aggregation","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Pro-GNN","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Abdelrhman-Saleh","text":"Abdelrhman Saleh"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Tovly-Deutsch","text":"Tovly Deutsch"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stephen-Casper","text":"Stephen Casper"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Yonatan-Belinkov","text":"Yonatan Belinkov"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Stuart-Shieber","text":"Stuart Shieber"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/June-16th-2020","text":"June 16th, 2020"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ParlAI","text":"ParlAI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Transformer","text":"Transformer"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/WikiText-103","text":"WikiText-103"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/GloVe","text":"GloVe"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/TREC","text":"TREC"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DialogueNLI","text":"DialogueNLI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Schema-Guided-Dialog-SGD","text":"Schema-Guided Dialog (SGD)"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/Winograd-NLI","text":"Winograd NLI"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/SNIPS","text":"SNIPS"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/ScenarioSA","text":"ScenarioSA"},{"source":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","target":"/DailyDialog","text":"DailyDialog"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Alexander-Hoyle","text":"Alexander Hoyle"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Ana-Marasovi%C4%87","text":"Ana Marasović"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Noah-Smith","text":"Noah Smith"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/January-7th-2021","text":"January 7th 2021"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Resource-Description-Framework","text":"Resource Description Framework"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Abstract-Meaning-Representations","text":"Abstract Meaning Representations"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/language-model","text":"language model"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Linearized-Graph","text":"Linearized Graph"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Spanning-Tree","text":"Spanning Tree"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/PENMAN","text":"PENMAN"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Permutation-Invariant","text":"Permutation Invariance"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/AMR17","text":"AMR17"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/WebNLG","text":"WebNLG"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Transformer","text":"Transformer"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Graph-Reordering","text":"Graph Reordering"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Scaffolding","text":"Scaffolding"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation","target":"/Masked-Graph-Modelling","text":"Masked Graph Modelling"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yu-Yan","text":"Yu Yan"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Weizhen-Qi","text":"Weizhen Qi"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Yeyun-Gong","text":"Yeyun Gong"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Dayiheng-Liu","text":"Dayiheng Liu"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Nan-Duan","text":"Nan Duan"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Jiusheng-Chen","text":"Jiusheng Chen"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ruofei-Zhang","text":"Ruofei Zhang"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/Ming-Zhou","text":"Ming Zhou"},{"source":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","target":"/June-2nd-2020","text":"June 2nd, 2020"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Saurabh-Garg","text":"Saurabh Garg"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Sivaraman-Balakrishnan","text":"Sivaraman Balakrishnan"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/May-11th-2021","text":"May 11th 2021"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"Randomly Assign, Train and Track"},{"source":"/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization","target":"/Randomly-Assign-Train-and-Track","text":"RATT"},{"source":"/RGCN-Filter","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/RL-S2V","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/RL-S2V","target":"/Reinforcement-Learning","text":"Reinforcement Learning"},{"source":"/RL-S2V","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/RW-based-Sampler","target":"/Random-Walk","text":"Random Walk"},{"source":"/Random-Walk","target":"/Degree","text":"Degree"},{"source":"/ReWatt","target":"/Black-box-attack","text":"Black-box attack"},{"source":"/ReWatt","target":"/Rewiring","text":"Rewiring"},{"source":"/Reading-List","target":"/Alan-Turing-The-Enigma","text":"Alan Turing - The Enigma"},{"source":"/Reading-List","target":"/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence","text":"Prediction Machines - The Simple Economics of Artificial Intelligence"},{"source":"/Reading-List","target":"/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid","text":"Gödel, Escher, Bach - an Eternal Golden Braid"},{"source":"/Reading-List","target":"/The-Book-of-Why-The-New-Science-of-Cause-and-Effect","text":"The Book of Why - The New Science of Cause and Effect"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Khaled-Koutini","text":"Khaled Koutini"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Hamid-Eghbal-zadeh","text":"Hamid Eghbal-zadeh"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Gerhard-Widmer","text":"Gerhard Widmer"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Computer-Vision","text":"Computer Vision"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Receptive-Field","text":"Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/TAU-Urban-Acoustic-Scenes-2018","text":"TAU Urban Acoustic Scenes 2018"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Maximum-Receptive-Field","text":"Maximum Receptive Field"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Filter-Damping","text":"Filter Damping"},{"source":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","target":"/Effective-Receptive-Field","text":"Effective Receptive Field"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Stephen-Roller","text":"Stephen Roller"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Emily-Dinan","text":"Emily Dinan"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Naman-Goyal","text":"Naman Goyal"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Da-Ju","text":"Da Ju"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Mary-Williamson","text":"Mary Williamson"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Yinhan-Liu","text":"Yinhan Liu"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jing-Xu","text":"Jing Xu"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Myle-Ott","text":"Myle Ott"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Kurt-Shuster","text":"Kurt Shuster"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Jason-Weston","text":"Jason Weston"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/June-23rd-2020","text":"June 23rd, 2020"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Transformer","text":"Transformer"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Fairseq","text":"Fairseq"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ParlAI","text":"ParlAI"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adafactor","text":"Adafactor"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Adam","text":"Adam"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Wizard-of-Wikipedia","text":"Wizard of Wikipedia"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Blended-Skill-Talk","text":"Blended Skill Talk"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Unlikelihood-Training","text":"Unlikelihood Training"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Meena","text":"Meena"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","target":"/embed","text":"embed"},{"source":"/Recursive-Graph-to-Graph-Transformer","target":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","text":"Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency Parsing with Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Alireza-Mohammadshahi","text":"Alireza Mohammadshahi"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/James-Henderson","text":"James Henderson"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/January-13th-2021","text":"January 13th 2021"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Recursive-Graph-to-Graph-Transformer","text":"Recursive Graph-to-Graph Transformer"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Dependency-Parsing","text":"Dependency Parsing"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Iterative-Refinement","text":"Iterative Refinement"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Universal-Dependency-Treebanks","text":"Universal Dependency Treebanks"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/Penn-Treebank","text":"Penn Treebank"},{"source":"/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement","target":"/German-CoNLL-2009-Treebank","text":"German CoNLL 2009 Treebank"},{"source":"/Relation-Extraction","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victor-Bapst","text":"Victor Bapst"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Alvaro-Sanchez-Gonzalez","text":"Alvaro Sanchez-Gonzalez"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Vinicius-Zambaldi","text":"Vinicius Zambaldi"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Mateusz-Malinowski","text":"Mateusz Malinowski"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrea-Tacchetti","text":"Andrea Tacchetti"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/David-Raposo","text":"David Raposo"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Adam-Santoro","text":"Adam Santoro"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ryan-Faulkner","text":"Ryan Faulkner"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Caglar-Gulcehre","text":"Caglar Gulcehre"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Francis-Song","text":"Francis Song"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Andrew-Ballard","text":"Andrew Ballard"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Justin-Gilmer","text":"Justin Gilmer"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/George-Dahl","text":"George Dahl"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Ashish-Vaswani","text":"Ashish Vaswani"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Kelsey-Allen","text":"Kelsey Allen"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Charles-Nash","text":"Charles Nash"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Victoria-Langston","text":"Victoria Langston"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Chris-Dyer","text":"Chris Dyer"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Nicolas-Heess","text":"Nicolas Heess"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Daan-Wierstra","text":"Daan Wierstra"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Pushmeet-Kohli","text":"Pushmeet Kohli"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Matt-Botvinick","text":"Matt Botvinick"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Oriol-Vinyals","text":"Oriol Vinyals"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Yujia-Li","text":"Yujia Li"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Razvan-Pascanu","text":"Razvan Pascanu"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/December-16th-2020","text":"December 16th 2020"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Feed-forward","text":"Feed-forward"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Convolution-Neural-Network","text":"Convolutional Layers"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Locality-Invariant","text":"Locality Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Translation-Invariant","text":"Translation Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Recurrent-Neural-Networks","text":"Recurrent layers"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Temporal-Invariant","text":"Temporal Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Permutation-Invariant","text":"Permutation Invariant"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Relational-inductive-biases-deep-learning-and-graph-networks","target":"/Graph-Neural-Networks","text":"Graph Neural Networks#Impossibility Results and Bottlenecks"},{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Audio-Tagging","text":"Audio Tagging"},{"source":"/Research-Ideas","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Research-Ideas","target":"/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks","text":"Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks"},{"source":"/Research-Ideas","target":"/Byte-Pair-Encoding","text":"Byte Pair Encoding"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Mode-Collapse","text":"Mode Collapse"},{"source":"/Research-Ideas","target":"/Hysteresis-Thresholding","text":"Hysteresis Thresholding"},{"source":"/Research-Ideas","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"},{"source":"/Research-Ideas","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/Research-Ideas","target":"/Question-Answering","text":"Question Answering"},{"source":"/Research-Ideas","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Research-Ideas","target":"/Inductive-Biases","text":"Inductive Biases"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/Transfer-Learning","text":"Transfer Learning"},{"source":"/Research-Ideas","target":"/Isotropy","text":"Isotropy"},{"source":"/Research-Ideas","target":"/Anisotropy","text":"Anisotropy"},{"source":"/Research-Ideas","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/Non-maximal-Suppression","text":"Non-maximal Suppression"},{"source":"/Research-Ideas","target":"/JSALT2020","text":"JSALT2020"},{"source":"/Research-Ideas","target":"/Evaluation-Metric","text":"Evaluation Metric"},{"source":"/Research-Ideas","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Research-Ideas","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Research-Ideas","target":"/Switchboard-Coherence","text":"Switchboard Coherence"},{"source":"/Research-Ideas","target":"/TF-IDF","text":"TF-IDF"},{"source":"/Research-Ideas","target":"/PCA","text":"PCA"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/BERT","text":"BERT"},{"source":"/Research-Ideas","target":"/t-SNE","text":"t-SNE"},{"source":"/Research-Ideas","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Research-Ideas","target":"/FED-metric","text":"FED metric"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Wenxuan-Wang","text":"Wenxuan Wang"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Zhaopeng-Tu","text":"Zhaopeng Tu"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/November-27th-2020","text":"November 27th, 2020"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/ablation","text":"ablation"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Contribution-in-Information-Flow","text":"Contribution in Information Flow"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/BLEU","text":"BLEU"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Criticality-in-Representation-Generalization","text":"Criticality in Representation Generalization"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Rethinking-the-Value-of-Transformer-Components","target":"/Transformer","text":"Transformer"},{"source":"/Rewinding","target":"/Lottery-Ticket-Hypothesis","text":"Lottery Ticket Hypothesis"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Max-Welling","text":"Max Welling"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/December-14th-2020","text":"December 14th 2020"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Convolution-Neural-Network","text":"Convolution Neural Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Neural-Network","text":"Neural Network"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Semi-Supervised","text":"Semi-Supervised"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"layers"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^41aec7"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"Graph Convolutional Network#^e0c9b8"},{"source":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Dat-Ngo","text":"Dat Ngo"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Hao-Hoang","text":"Hao Hoang"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Anh-Nguyen","text":"Anh Nguyen"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Tien-Ly","text":"Tien Ly"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/31-May-2021","text":"31-May-2021"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Constant-Q-transform","text":"Constant-Q-transform"},{"source":"/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES","target":"/Mel-Spectrograms","text":"Mel Spectrograms"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Ankur-Teredesai","text":"Ankur Teredesai"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Marzyeh-Ghassemi","text":"Marzyeh Ghassemi"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/July-22nd-2020","text":"July 22nd, 2020"},{"source":"/Saving-Lives-with-Interpretable-ML","target":"/Rich-Caruana","text":"Rich Caruana"},{"source":"/Security-and-Machine-Learning","target":"/Emre-Kiciman","text":"Emre Kiciman"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/July-21st-2020","text":"July 21st, 2020"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/ImageNet","text":"ImageNet"},{"source":"/Security-and-Machine-Learning","target":"/Dawn-Song","text":"Dawn Song"},{"source":"/Security-and-Machine-Learning","target":"/adversarial-attacks","text":"adversarial attacks"},{"source":"/Security-and-Machine-Learning","target":"/Duet","text":"Duet"},{"source":"/Security-and-Machine-Learning","target":"/noisy-gradient-descent","text":"noisy gradient descent"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/quantum-entropy-regularization","text":"quantum entropy regularization"},{"source":"/Security-and-Machine-Learning","target":"/Jerry-Li","text":"Jerry Li"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Security-and-Machine-Learning","target":"/Aleksander-Madry","text":"Aleksander Madry"},{"source":"/Semantic-Role-Labeling","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Chunqi-Wang","text":"Chunqi Wang"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Ji-Zhang","text":"Ji Zhang"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Haiqing-Chen","text":"Haiqing Chen"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/Semi-Autoregressive-Transformer-SAT","text":"Semi-Autoregressive Transformer (SAT)"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST02","text":"NIST02"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST03","text":"NIST03"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST04","text":"NIST04"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/NIST05","text":"NIST05"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2002E18","text":"LDC2002E18"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2003E14","text":"LDC2003E14"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2004T08","text":"LDC2004T08"},{"source":"/Semi-Autoregressive-Neural-Machine-Translation","target":"/LDC2005T0","text":"LDC2005T0"},{"source":"/Sepformer","target":"/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION","text":"ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION"},{"source":"/Sepformer","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Bei-Li","text":"Bei Li"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Ziyang-Wang","text":"Ziyang Wang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Hui-Liu","text":"Hui Liu"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Yufan-Jiang","text":"Yufan Jiang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Quan-Du","text":"Quan Du"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Tong-Xiao","text":"Tong Xiao"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Huizhen-Wang","text":"Huizhen Wang"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Jingbo-Zhu","text":"Jingbo Zhu"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/December-1st-2020","text":"December 1st, 2020"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Shallow-To-Deep-SDT-Algorithm","text":"Shallow-To-Deep (SDT) (Algorithm)"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/Learning-Rate","text":"Learning Rate"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","target":"/WMT14-En-Fr","text":"WMT14 En-Fr"},{"source":"/Signed-Graphs","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Simple-Graph","target":"/Degree","text":"Degree"},{"source":"/Simple-Graph","target":"/Adjacency-Matrix","text":"Adjacency Matrix"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Huy-Phan","text":"Huy Phan"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Lam-Pham","text":"Lam Pham"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Philipp-Koch","text":"Philipp Koch"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Maarten-De-Vos","text":"Maarten De Vos"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Ian-McLoughlin","text":"Ian McLoughlin"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/Alfred-Mertins","text":"Alfred Mertins"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/01-Jun-2021","text":"01-Jun-2021"},{"source":"/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification","target":"/LITIS-Rouen-dataset","text":"LITIS-Rouen dataset"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/JinYeong-Bak","text":"JinYeong Bak"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Alice-Oh","text":"Alice Oh"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/June-15th-2020","text":"June 15th, 2020"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/GloVe-Twitter-200d","text":"GloVe Twitter 200d"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Twitter-Conversation-Corpus-Bak-and-Oh-2019","text":"Twitter Conversation Corpus (Bak and Oh, 2019)"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/BLEU","text":"BLEU"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/ROUGE","text":"ROUGE"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/EMB","text":"EMB"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/RUBER","text":"RUBER"},{"source":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","target":"/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011","text":"Movie Scripts (Danescu-Niculescu-Mizil and Lee, 2011)"},{"source":"/Spectral-Graph-Convolutions","target":"/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS","text":"SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Spectral-Graph-Convolutions","target":"/Spectral-Graph","text":"Spectral Graph"},{"source":"/Spectral-Graph-Convolutions","target":"/Convolution","text":"Convolution"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Convolutions","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Spectral-Graph-Convolutions","target":"/Graph-Fourier-Transform","text":"Graph Fourier Transform"},{"source":"/Spectral-Graph-Convolutions","target":"/Chebyshev-Polynomial","text":"Chebyshev Polynomial"},{"source":"/Spectral-Graph-Convolutions","target":"/Eigendecomposition","text":"Eigendecomposition"},{"source":"/Spectral-Graph-Theory","target":"/Spectral-Theorem","text":"Spectral Theorem"},{"source":"/Spectral-Graph-Theory","target":"/Linear-Algebra","text":"Linear Algebra"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvalue","text":"Eigenvalue"},{"source":"/Spectral-Graph-Theory","target":"/Eigenvector","text":"Eigenvector"},{"source":"/Spectral-Graph-Theory","target":"/Laplacian-Matrix","text":"Laplacian Matrix"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Xingchen-Song","text":"Xingchen Song"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Guangsen-Wang","text":"Guangsen Wang"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Yiheng-Huang","text":"Yiheng Huang"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Zhiyong-Wu","text":"Zhiyong Wu"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Dan-Su","text":"Dan Su"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Helen-Meng","text":"Helen Meng"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/May-1st-2021","text":"May 1st 2021"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Speech-XLNet","text":"Speech-XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/XLNet","text":"XLNet"},{"source":"/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks","target":"/Huber-Loss","text":"Huber Loss"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Mathew-Monfort","text":"Mathew Monfort"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/SouYong-Jin","text":"SouYong Jin"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Alexander-Liu","text":"Alexander Liu"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/David-Harwath","text":"David Harwath"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Rogerio-Feris","text":"Rogerio Feris"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/James-Glass","text":"James Glass"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Aude-Oliva","text":"Aude Oliva"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/May-18th-2021","text":"May 18th 2021"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Spoken-Moments-dataset","text":"Spoken Moments dataset"},{"source":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","target":"/Adaptive-Mean-Margin","text":"Adaptive Mean Margin"},{"source":"/Spoken-Moments-dataset","target":"/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions","text":"Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions"},{"source":"/Spoken-Moments-dataset","target":"/Multi-Moments-in-Time","text":"Multi-Moments in Time"},{"source":"/Subgraph-wise-Sampling","target":"/Subgraph","text":"Subgraph"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Jan-Deriu","text":"Jan Deriu"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alvaro-Rodrigo","text":"Alvaro Rodrigo"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Arantxa-Otegi","text":"Arantxa Otegi"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Guillermo-Echegoyen","text":"Guillermo Echegoyen"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Sophie-Rosset","text":"Sophie Rosset"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Eneko-Agirre","text":"Eneko Agirre"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Mark-Cieliebak","text":"Mark Cieliebak"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/June-19th-2020","text":"June 19th, 2020"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Amazon-Mechanical-Turk","text":"Amazon Mechanical Turk"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Hidden-Markov-Models","text":"Hidden Markov Models"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Subject-Vector-Machines","text":"Subject Vector Machines"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conditional-Random-Fields","text":"Conditional Random Fields"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dynamic-Bayesian-Network","text":"Dynamic Bayesian Network"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Markov-Decision-Process","text":"Markov Decision Process"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Rule-Based-Approaches","text":"Rule-Based Approaches"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialogue-Efficiency","text":"Dialogue Efficiency"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Kappa-coefficient","text":"Kappa coefficient"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/PARAdigm-for-DIalog-System-Evaluation","text":"PARAdigm for DIalog System Evaluation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Success-Rate","text":"Task Success Rate"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Interaction-Quality","text":"Interaction Quality"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Neural-User-Simulator","text":"Neural User Simulator"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Agenda-based-User-Simulation","text":"Agenda based User Simulation"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MeMo-workbench","text":"MeMo workbench"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Concept-Error-Rates","text":"Concept Error Rates"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/BLEU","text":"BLEU"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Recurrent-Neural-Networks","text":"Recurrent Neural Networks"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ROUGE","text":"ROUGE"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Generative-Adversarial-Network","text":"Generative Adversarial Network"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Next-Utterance-Selection","text":"Next Utterance Selection"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Voted-Appropriateness","text":"Voted Appropriateness"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Weak-Agreement","text":"Weak Agreement"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/F-scores","text":"F-scores"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/datasets","text":"datasets"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Task-Oriented-Dialogue-Systems","text":"Task Oriented Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Question-Answering-Dialogue-Systems","text":"Question-Answering Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Ubuntu-Dialogue-Corpus","text":"Ubuntu Dialogue Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/MSDialog","text":"MSDialog"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/ibAbI","text":"ibAbI"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/bAbI","text":"bAbI"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/QuAC","text":"QuAC"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/CoQA","text":"CoQA"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Dialogue-Systems","text":"Conversational Dialogue Systems"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SwitchBoard","text":"SwitchBoard"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/British-National-Corpus","text":"British National Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/SubTle-Corpus","text":"SubTle Corpus"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/OpenSubtitles","text":"OpenSubtitles"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Cornell-Movie","text":"Cornell Movie"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Dialog-State-Tracking-Challenge","text":"Dialog State Tracking Challenge"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Conversational-Intelligence-Challenge-2","text":"Conversational Intelligence Challenge 2"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Alexa-Prize","text":"Alexa Prize"},{"source":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","target":"/Lifelong-Learning","text":"Lifelong Learning"},{"source":"/Syntax-GNN","target":"/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information","text":"Do Syntax Trees Help Pre-trained Transformers Extract Information"},{"source":"/Syntax-GNN","target":"/Multi-Head-Self-Attention","text":"Multi-Head Self-Attention"},{"source":"/Syntax-GNN","target":"/Transformer","text":"Transformer"},{"source":"/Syntax-GNN","target":"/Graph-Attention","text":"Graph Attention"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/G%C3%B6del-T-norm","text":"Gödel T-norm"},{"source":"/T-norm","target":"/Product-T-norm","text":"Product T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/%C5%81ukasiewicz-T-norm","text":"Łukasiewicz T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/Drastic-T-norm","text":"Drastic T-norm"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/T-norm","target":"/Nilpotent-Minimum","text":"Nilpotent Minimum"},{"source":"/T-norm","target":"/Hamacher-Product","text":"Hamacher Product"},{"source":"/T-norm","target":"/T-norm","text":"T-norm"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Xuenan-Xu","text":"Xuenan Xu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Heinrich-Dinkel","text":"Heinrich Dinkel"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Mengyue-Wu","text":"Mengyue Wu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Kai-Yu","text":"Kai Yu"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/May-3rd-2021","text":"May 3rd 2021"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"},{"source":"/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS","target":"/Audio-Grounding-dataset","text":"Audio Grounding dataset"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Shawn-Hershey","text":"Shawn Hershey"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Daniel-P-W-Ellis","text":"Daniel P W Ellis"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Eduardo-Fonseca","text":"Eduardo Fonseca"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Aren-Jansen","text":"Aren Jansen"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Caroline-Liu","text":"Caroline Liu"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/R-Channing-Moore","text":"R Channing Moore"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/Manoj-Plakal","text":"Manoj Plakal"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"},{"source":"/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION","target":"/AudioSet","text":"AudioSet"},{"source":"/TRACKE","target":"/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation","text":"A Transformer-based Audio Captioning Model with Keyword Estimation"},{"source":"/TRACKE","target":"/VGGish","text":"VGGish"},{"source":"/TRACKE","target":"/FastText","text":"FastText"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"},{"source":"/TRACKE","target":"/cross-entropy","text":"cross entropy"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Nitika-Mathur","text":"Nitika Mathur"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Timothy-Baldwin","text":"Timothy Baldwin"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Trevor-Cohn","text":"Trevor Cohn"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/June-17th-2020","text":"June 17th, 2020"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-I-Errors","text":"Type I Errors"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Type-II-Errors","text":"Type II Errors"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/WMT","text":"WMT"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/sacreBLEU","text":"sacreBLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/N-grams","text":"N-grams"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BERT","text":"BERT"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-2","text":"YiSi-2"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/Pearsons-Correlation-Coefficient","text":"Pearson's Correlation Coefficient"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/BLEU","text":"BLEU"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/TER","text":"TER"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/chrF","text":"chrF"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/YiSi-1","text":"YiSi-1"},{"source":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","target":"/ESIM","text":"ESIM"},{"source":"/Temporal-Random-Walk","target":"/Random-Walk","text":"Random Walk"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Matthias-Bethge","text":"Matthias Bethge"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/October-20th-2020","text":"October 20th, 2020"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/VGG19-Architecture","text":"VGG19 (Architecture)"},{"source":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","target":"/Gram-matrix","text":"Gram-matrix"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/September-24th-2020","text":"September 24th, 2020"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Markov-Random-Field","text":"Markov Random Field"},{"source":"/Texture-Synthesis-by-Non-parametric-Sampling","target":"/Image-Inpainting","text":"Image Inpainting"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Ryuichiro-Higashinaka","text":"Ryuichiro Higashinaka"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Kotaro-Funakoshi","text":"Kotaro Funakoshi"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Yuka-Kobayashi","text":"Yuka Kobayashi"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Michimasa-Inaba","text":"Michimasa Inaba"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/June-20th-2020","text":"June 20th, 2020"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Accuracy","text":"Accuracy"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Precision","text":"Precision"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Recall","text":"Recall"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/F-scores","text":"F-scores"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Jensen-Shannon-Divergence","text":"Jensen-Shannon Divergence"},{"source":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","target":"/Mean-Squared-Error","text":"Mean Squared Error"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Tianlong-Chen","text":"Tianlong Chen"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Jonathan-Frankle","text":"Jonathan Frankle"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Shiyu-Chang","text":"Shiyu Chang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Sijia-Liu","text":"Sijia Liu"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Yang-Zhang","text":"Yang Zhang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Zhangyang-Wang","text":"Zhangyang Wang"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Michael-Carbin","text":"Michael Carbin"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/July-30th-2020","text":"July 30th, 2020"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/BERT","text":"BERT"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Iterative-Magnitude-Pruning","text":"Iterative Magnitude Pruning"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/Rewinding","text":"Rewinding"},{"source":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","target":"/DistilBERT","text":"DistilBERT"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Marzieh-Fadaee","text":"Marzieh Fadaee"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Christof-Monz","text":"Christof Monz"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/May-27th-2020","text":"May 27th, 2020"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","target":"/Levenshtein-Distance","text":"Levenshtein Distance"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Hannah-Rashkin","text":"Hannah Rashkin"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Eric-Michael-Smith","text":"Eric Michael Smith"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Margaret-Li","text":"Margaret Li"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Y-Lan-Boureau","text":"Y-Lan Boureau"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/July-16th-2020","text":"July 16th, 2020"},{"source":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","target":"/Empathetic-Dialogues","text":"Empathetic Dialogues"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/BLEU","text":"BLEU"},{"source":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","target":"/ROUGE","text":"ROUGE"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Daniel-Adiwardana","text":"Daniel Adiwardana"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Minh-Thang-Luong","text":"Minh-Thang Luong"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Jamie-Hall","text":"Jamie Hall"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Noah-Fiedel","text":"Noah Fiedel"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Romal-Thoppilan","text":"Romal Thoppilan"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Zi-Yang","text":"Zi Yang"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Apoorv-Kulshreshtha","text":"Apoorv Kulshreshtha"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Gaurav-Nemade","text":"Gaurav Nemade"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Yifeng-Lu","text":"Yifeng Lu"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/June-25th-2020","text":"June 25th, 2020"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sensible-and-Specificity-Average-SSA","text":"Sensible and Specificity Average (SSA)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/embed","text":"embed"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mini-Turning-Benchmark-MTB","text":"Mini-Turning Benchmark (MTB)"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Meena","text":"Meena"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/transformer","text":"Transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Transformer","text":"Transformer"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/GPT-2","text":"GPT-2"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/DialogGPT","text":"DialogGPT"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Sample-and-Rank","text":"Sample-and-Rank"},{"source":"/Towards-a-Human-like-Open-Domain-Chatbot","target":"/Mitsuku","text":"Mitsuku"},{"source":"/Trail","target":"/Walk","text":"Walk"},{"source":"/TransE","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/TransE","target":"/Knowledge-Graphs-Embeddings","text":"Knowledge Graphs Embeddings"},{"source":"/TransE","target":"/Manhattan-Distance","text":"Manhattan Distance"},{"source":"/TransE","target":"/Euclidean-Distance","text":"Euclidean Distance"},{"source":"/TransE","target":"/KBGAN","text":"KBGAN"},{"source":"/TransE","target":"/Adversarial-Learning","text":"Adversarial Learning"},{"source":"/Translational-Models","target":"/Knowledge-Graph-Embeddings-and-Explainable-AI","text":"Knowledge Graph Embeddings and Explainable AI"},{"source":"/Translational-Models","target":"/RotatE","text":"RotatE"},{"source":"/Translational-Models","target":"/Hierarchy-Aware-Knowledge-Graph-Embedding","text":"Hierarchy-Aware Knowledge Graph Embedding"},{"source":"/Tree-LSTM","target":"/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs","text":"Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs"},{"source":"/Tree-LSTM","target":"/LSTM","text":"LSTM"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Chunting-Zhou","text":"Chunting Zhou"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Jiatao-Gu","text":"Jiatao Gu"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/August-13th-2020","text":"August 13th, 2020"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Multi-Modality","text":"Multi-Modality"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Europarl","text":"Europarl"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive","text":"Non-Autoregressive"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/KL-divergence","text":"KL-divergence"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Transformer","text":"Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Non-Autoregressive-Transformer","text":"Non-Autoregressive Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/FlowSeq","text":"FlowSeq"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/iNAT","text":"iNAT"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Levenshtein-Transformer-Architecture","text":"Levenshtein Transformer (Architecture)"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2013-En-De","text":"newstest2013 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/newstest2014-En-De","text":"newstest2014 En-De"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Knowledge-Distillation","text":"Knowledge Distillation"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Born-Again-Networks","text":"Born-Again Networks"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Mixture-of-Experts","text":"Mixture of Experts"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Complexity","text":"Complexity"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Faithfulness","text":"Faithfulness"},{"source":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","target":"/Sequence-Level-Interpolation","text":"Sequence-Level Interpolation"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Sascha-Hornauer","text":"Sascha Hornauer"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Ke-Li","text":"Ke Li"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Shabnam-Ghaffarzadegan","text":"Shabnam Ghaffarzadegan"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Liu-Ren","text":"Liu Ren"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/07-Jun-2021","text":"07-Jun-2021"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/Unsupervised-Discriminative-Learning-of-Sounds","text":"Unsupervised Discriminative Learning of Sounds"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-10","text":"ESC-10"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ESC-50","text":"ESC-50"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/UrbanSound8k","text":"UrbanSound8k"},{"source":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","target":"/ImageNet","text":"ImageNet"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Itxasne-Diez-Gaspon","text":"Itxasne Diez Gaspon"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Peio-Gonzalez","text":"Peio Gonzalez"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Ibon-Saratxaga","text":"Ibon Saratxaga"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING","text":"INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING"},{"source":"/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE","target":"/Multisystem-fusion-model-based-on-tag-relationship","text":"Multisystem fusion model based on tag relationship"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Jaehun-Kim","text":"Jaehun Kim"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"Harmonic Percussive Source Separation"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/EfficientNet","text":"EfficientNet"},{"source":"/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS","target":"/Harmonic-Percussive-Source-Separation","text":"HPSS"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Huang-Xie","text":"Huang Xie"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Okko-R%C3%A4s%C3%A4nen","text":"Okko Räsänen"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/05-Jan-2022","text":"05-Jan-2022"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Convolutional-Recurrent-Neural-Network","text":"CRNN"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/word2vec","text":"word2vec"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/skip-gram","text":"skip-gram"},{"source":"/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases","target":"/Automated-Audio-Captioning","text":"AAC"},{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION","text":"UNSUPERVISED DISCRIMINATIVE LEARNING OF SOUNDS FOR AUDIO EVENT CLASSIFICATION"},{"source":"/Unsupervised-Discriminative-Learning-of-Sounds","target":"/Short-Time-Fourier-Transform","text":"Short-Time Fourier Transform"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Shikib-Mehri","text":"Shikib Mehri"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Maxine-Eskenazi","text":"Maxine Eskenazi"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/June-25th-2020","text":"June 25th, 2020"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-metric","text":"FED metric"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/DialoGPT","text":"DialoGPT"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Partial-Scoring","text":"Partial Scoring"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/FED-dataset","text":"FED dataset"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Meena","text":"Meena"},{"source":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","target":"/Mitsuku","text":"Mitsuku"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Alexei-Baevski","text":"Alexei Baevski"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Steffen-Schneider","text":"Steffen Schneider"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Michael-Auli","text":"Michael Auli"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/April-30th-2021","text":"April 30th 2021"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Gumbel-Softmax","text":"Gumbel-Softmax"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/K-means-clustering","text":"K-means clustering"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/BERT","text":"BERT"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Letter-Error-Rate","text":"Letter Error Rate"},{"source":"/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS","target":"/Word-Error-Rate-WER","text":"Word Error Rate (WER)"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Laurens-van-der-Maaten","text":"Laurens van der Maaten"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Geoffrey-Hinton","text":"Geoffrey Hinton"},{"source":"/Visualizing-Data-using-t-SNE","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/SNE","text":"SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Crowding-Problem","text":"Crowding Problem"},{"source":"/Visualizing-Data-using-t-SNE","target":"/UNI-SNE","text":"UNI-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/t-SNE","text":"t-SNE"},{"source":"/Visualizing-Data-using-t-SNE","target":"/Isomap","text":"Isomap"},{"source":"/Visualizing-Data-using-t-SNE","target":"/LLE","text":"LLE"},{"source":"/WIKIHOP-dataset","target":"/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing","text":"Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing"},{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-Fr-En","text":"WMT14 Fr-En"},{"source":"/WMT","target":"/WMT14-De-En","text":"WMT14 De-En"},{"source":"/WMT","target":"/WMT14-En-De","text":"WMT14 En-De"},{"source":"/WMT","target":"/WMT16-De-En","text":"WMT16 De-En"},{"source":"/WMT","target":"/WMT16-En-De","text":"WMT16 En-De"},{"source":"/WMT","target":"/WMT17-En-De","text":"WMT17 En-De"},{"source":"/WMT","target":"/WMT18-En-De","text":"WMT18 En-De"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/An-Tran","text":"An Tran"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Konstantinos-Drossos","text":"Konstantinos Drossos"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Tuomas-Virtanen","text":"Tuomas Virtanen"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/February-9th-2021","text":"February 9th 2021"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/WaveTransformer","text":"WaveTransformer"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Automated-Audio-Captioning","text":"Automated Audio Captioning"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Recurrent-Neural-Networks","text":"RNNs"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Transformer","text":"Transformer"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/cross-entropy","text":"cross entropy"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/Clotho-dataset","text":"Clotho dataset"},{"source":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","target":"/BLEU","text":"BLEU"},{"source":"/WaveTransformer","target":"/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information","text":"WaveTransformer - A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/WaveNet","text":"WaveNet"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/LeakyReLU","text":"LeakyReLU"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Convolution-Neural-Network","text":"CNN"},{"source":"/WaveTransformer","target":"/Feed-forward","text":"Feed-forward"},{"source":"/WaveTransformer","target":"/Transformer","text":"Transformer"},{"source":"/Week-Summary-010620-210620","target":"/June-1st-2020","text":"June 1st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/June-21st-2020","text":"June 21st, 2020"},{"source":"/Week-Summary-010620-210620","target":"/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities","text":"Is this Dialogue Coherent - Learning from Dialogue Acts and Entities"},{"source":"/Week-Summary-010620-210620","target":"/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics","text":"The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition","text":"Learning not to Discriminate - Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition"},{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training","text":"ProphetNet - Predicting Future N-gram for Sequence-to-Sequence Pre-training"},{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"},{"source":"/Week-Summary-010620-210620","target":"/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems","text":"Evaluating dialogue breakdown detection in chat-oriented dialogue systems"},{"source":"/Week-Summary-010620-210620","target":"/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features","text":"Dialogue breakdown detection using BERT with traditional dialogue features"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Survey-on-Evaluation-Methods-for-Dialogue-Systems","text":"Survey on Evaluation Methods for Dialogue Systems"},{"source":"/Week-Summary-010620-210620","target":"/MultiWOZ-A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling","text":"MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"},{"source":"/Week-Summary-010620-210620","target":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","text":"YiSi - a Unified Semantic MT Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources"},{"source":"/Week-Summary-010620-210620","target":"/Misinformation-has-High-Perplexity","text":"Misinformation has High Perplexity"},{"source":"/Week-Summary-010620-210620","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/Week-Summary-010620-210620","target":"/Speaker-Sensitive-Response-Evaluation-Model-SSREM","text":"Speaker Sensitive Response Evaluation Model (SSREM)"},{"source":"/Week-Summary-010620-210620","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-010620-210620","target":"/Language-Models-are-Few-Shot-Learners","text":"Language Models are Few-Shot Learners"},{"source":"/Week-Summary-010620-210620","target":"/OpenAI","text":"OpenAI"},{"source":"/Week-Summary-010620-210620","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-010620-210620","target":"/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics","text":"Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics"},{"source":"/Week-Summary-010620-210620","target":"/BLEU","text":"BLEU"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-010620-210620","target":"/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4","text":"Overview of the Dialogue Breakdown Detection Challenge 4"},{"source":"/Week-Summary-021120-221120","target":"/November-2nd-2020","text":"November 2nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/November-22nd-2020","text":"November 22nd, 2020"},{"source":"/Week-Summary-021120-221120","target":"/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture","text":"PSECMAC - A Novel Self-Organizing Multiresolution Associative Memory Architecture"},{"source":"/Week-Summary-021120-221120","target":"/Kernel-CMAC-With-Improved-Capability","text":"Kernel CMAC With Improved Capability"},{"source":"/Week-Summary-021120-221120","target":"/Learning-Convergence-of-CMAC-Technique","text":"Learning Convergence of CMAC Technique"},{"source":"/Week-Summary-021120-221120","target":"/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output","text":"Improved MCMAC with Momentum, Neighborhood, and Averaged Trapezoidal Output"},{"source":"/Week-Summary-021120-221120","target":"/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence","text":"Hierarchically Clustered Adaptive Quantization CMAC and Its Learning Convergence"},{"source":"/Week-Summary-021120-221120","target":"/Generalizing-CMAC-Architecture-and-Training","text":"Generalizing CMAC Architecture and Training"},{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers","text":"Comparison of Convergence Properties of CMAC Neural Network and Traditional Adaptive Controllers"},{"source":"/Week-Summary-021120-221120","target":"/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control","text":"Comparison of CMAC Architectures for Neural Network Based Control"},{"source":"/Week-Summary-030820-160820","target":"/August-3rd-2020","text":"August 3rd, 2020"},{"source":"/Week-Summary-030820-160820","target":"/August-16th-2020","text":"August 16th, 2020"},{"source":"/Week-Summary-030820-160820","target":"/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming","text":"Imputer - Sequence Modelling via Imputation and Dynamic Programming"},{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Machine-Translation-with-Latent-Alignments","text":"Non-Autoregressive Machine Translation with Latent Alignments"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"},{"source":"/Week-Summary-030820-160820","target":"/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION","text":"NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/Discovering-and-Categorizing-Language-Biases-in-Reddit","text":"Discovering and Categorizing Language Biases in Reddit"},{"source":"/Week-Summary-030820-160820","target":"/Defining-and-Evaluating-Fair-Natural-Language-Generation","text":"Defining and Evaluating Fair Natural Language Generation"},{"source":"/Week-Summary-030820-160820","target":"/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION","text":"UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION"},{"source":"/Week-Summary-030820-160820","target":"/Big-Bird-Transformers-for-Longer-Sequences","text":"Big Bird - Transformers for Longer Sequences"},{"source":"/Week-Summary-030820-160820","target":"/Non-Autoregressive-Transformer-by-Position-Learning","text":"Non-Autoregressive Transformer by Position Learning"},{"source":"/Week-Summary-060720-190720","target":"/July-6th-2020","text":"July 6th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/July-19th-2020","text":"July 19th, 2020"},{"source":"/Week-Summary-060720-190720","target":"/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too","text":"Personalizing Dialogue Agents - I have a dog, do you have pets too"},{"source":"/Week-Summary-060720-190720","target":"/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation","text":"DialoGPT - Large-Scale Generative Pre-training for Conversational Response Generation"},{"source":"/Week-Summary-060720-190720","target":"/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset","text":"Towards Empathetic Open-domain Conversation Models - a New Benchmark and Dataset"},{"source":"/Week-Summary-060720-190720","target":"/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset","text":"DailyDialog - A Manually Labelled Multi-turn Dialogue Dataset"},{"source":"/Week-Summary-060720-190720","target":"/Modeling-Local-Coherence-An-Entity-Based-Approach","text":"Modeling Local Coherence - An Entity-Based Approach"},{"source":"/Week-Summary-060720-190720","target":"/Visualizing-Data-using-t-SNE","text":"Visualizing Data using t-SNE"},{"source":"/Week-Summary-071220-131220","target":"/December-7th-2020","text":"December 7th 2020"},{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"},{"source":"/Week-Summary-071220-131220","target":"/December-13th-2020","text":"December 13th 2020"},{"source":"/Week-Summary-071220-131220","target":"/Document-Graph-for-Neural-Machine-Translation","text":"Document Graph for Neural Machine Translation"},{"source":"/Week-Summary-141220-271220","target":"/December-14th-2020","text":"December 14th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"},{"source":"/Week-Summary-141220-271220","target":"/December-27th-2020","text":"December 27th 2020"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need","text":"Graph-Aware Transformer - Is Attention All Graphs Need"},{"source":"/Week-Summary-141220-271220","target":"/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS","text":"LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS"},{"source":"/Week-Summary-141220-271220","target":"/Graphite-Iterative-Generative-Modeling-of-Graphs","text":"Graphite - Iterative Generative Modeling of Graphs"},{"source":"/Week-Summary-141220-271220","target":"/GRAPH-ATTENTION-NETWORKS-Paper","text":"GRAPH ATTENTION NETWORKS (Paper)"},{"source":"/Week-Summary-141220-271220","target":"/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation","text":"A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation"},{"source":"/Week-Summary-141220-271220","target":"/Relational-inductive-biases-deep-learning-and-graph-networks","text":"Relational inductive biases, deep learning, and graph networks"},{"source":"/Week-Summary-141220-271220","target":"/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering","text":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Convolutional-Network","text":"GCN"},{"source":"/Week-Summary-141220-271220","target":"/Graph-Neural-Networks","text":"GNN"},{"source":"/Week-Summary-170820-230820","target":"/August-17th-2020","text":"August 17th, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/August-23rd-2020","text":"August 23rd, 2020"},{"source":"/Week-Summary-170820-230820","target":"/Paper-Levenshtein-Transformer","text":"(Paper) Levenshtein Transformer"},{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models","text":"Mask-Predict - Parallel Decoding of Conditional Masked Language Models"},{"source":"/Week-Summary-170820-230820","target":"/Multilingual-KERMIT-Its-Not-Easy-Being-Generative","text":"Multilingual KERMIT - It’s Not Easy Being Generative"},{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"},{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations","text":"Insertion Transformer - Flexible Sequence Generation via Insertion Operations"},{"source":"/Week-Summary-170820-230820","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-170820-230820","target":"/Mask-Predict","text":"Mask-Predict"},{"source":"/Week-Summary-170820-230820","target":"/Insertion-Transformer","text":"Insertion Transformer"},{"source":"/Week-Summary-170820-230820","target":"/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences","text":"KERMIT - Generative Insertion-Based Modeling for Sequences"},{"source":"/Week-Summary-180520-240520","target":"/May-18th-2020","text":"May 18th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/May-24th-2020","text":"May 24th, 2020"},{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"},{"source":"/Week-Summary-180520-240520","target":"/Poor-Mans-BERT-Smaller-and-Faster-Transformer-Models","text":"Poor Man's BERT - Smaller and Faster Transformer Models"},{"source":"/Week-Summary-180520-240520","target":"/Semi-Autoregressive-Neural-Machine-Translation","text":"Semi Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-180520-240520","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"},{"source":"/Week-Summary-180520-240520","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-180520-240520","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"},{"source":"/Week-Summary-180520-240520","target":"/Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model","text":"Breaking the Softmax Bottleneck - A High-Rank RNN Language Model"},{"source":"/Week-Summary-180520-240520","target":"/Softmax","text":"Softmax"},{"source":"/Week-Summary-200720-020820","target":"/July-20th-2020","text":"July 20th, 2020"},{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"},{"source":"/Week-Summary-200720-020820","target":"/August-2nd-2020","text":"August 2nd, 2020"},{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"},{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"source":"/Week-Summary-200720-020820","target":"/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks","text":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"source":"/Week-Summary-200720-020820","target":"/meta-learning","text":"meta-learning"},{"source":"/Week-Summary-200720-020820","target":"/BERT","text":"BERT"},{"source":"/Week-Summary-200720-020820","target":"/Do-Transformers-Need-Deep-Long-Range-Memory","text":"Do Transformers Need Deep Long-Range Memory"},{"source":"/Week-Summary-200720-020820","target":"/Transformer-XL","text":"Transformer-XL"},{"source":"/Week-Summary-210920-011120","target":"/September-21st-2020","text":"September 21st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/November-1st-2020","text":"November 1st, 2020"},{"source":"/Week-Summary-210920-011120","target":"/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper","text":"NEFCLASS - A Neuro-Fuzzy approach for the classification of data (Paper)"},{"source":"/Week-Summary-210920-011120","target":"/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003","text":"Interpretability Improvements to Find the Balance Interpretability-Accuracy in Fuzzy Modeling - An Overview (2003)"},{"source":"/Week-Summary-210920-011120","target":"/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES","text":"HEDGE ALGEBRAS - AN ALGEBRAIC APPROACH TO STRUCTURE OF SETS OF LINGUISTIC TRUTH VALUES"},{"source":"/Week-Summary-210920-011120","target":"/Generative-Pretraining-from-Pixels","text":"Generative Pretraining from Pixels"},{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-Using-Convolutional-Neural-Networks","text":"Texture Synthesis Using Convolutional Neural Networks"},{"source":"/Week-Summary-210920-011120","target":"/Image-Quilting-for-Texture-Synthesis-and-Transfer","text":"Image Quilting for Texture Synthesis and Transfer"},{"source":"/Week-Summary-210920-011120","target":"/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990","text":"Implementing fuzzy logic controllers using a neural network framework (1990)"},{"source":"/Week-Summary-210920-011120","target":"/Fuzzy-Sets-1965","text":"Fuzzy Sets (1965)"},{"source":"/Week-Summary-210920-011120","target":"/Color-Indexing","text":"Color Indexing"},{"source":"/Week-Summary-210920-011120","target":"/Face-Recognition-Using-Eigenfaces","text":"Face Recognition Using Eigenfaces"},{"source":"/Week-Summary-210920-011120","target":"/Mean-Shift-Analysis-and-Applications","text":"Mean Shift Analysis and Applications"},{"source":"/Week-Summary-210920-011120","target":"/Texture-Synthesis-by-Non-parametric-Sampling","text":"Texture Synthesis by Non-parametric Sampling"},{"source":"/Week-Summary-210920-011120","target":"/Compositional-rule-of-inference-as-an-analogical-scheme","text":"Compositional rule of inference as an analogical scheme"},{"source":"/Week-Summary-220620-050720","target":"/June-22nd-2020","text":"June 22nd, 2020"},{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"},{"source":"/Week-Summary-220620-050720","target":"/July-5th-2020","text":"July 5th, 2020"},{"source":"/Week-Summary-220620-050720","target":"/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons","text":"ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons"},{"source":"/Week-Summary-220620-050720","target":"/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols","text":"Towards Unified Dialogue System Evaluation - A Comprehensive Analysis of Current Evaluation Protocols"},{"source":"/Week-Summary-220620-050720","target":"/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT","text":"Unsupervised Evaluation of Interactive Dialog with DialoGPT"},{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"},{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"},{"source":"/Week-Summary-220620-050720","target":"/Overview-of-the-dialogue-breakdown-detection-challenge-3","text":"Overview of the dialogue breakdown detection challenge 3"},{"source":"/Week-Summary-220620-050720","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"},{"source":"/Week-Summary-220620-050720","target":"/Recipes-for-building-an-open-domain-chatbot-Generative-BST","text":"Recipes for building an open domain chatbot (Generative BST)"},{"source":"/Week-Summary-220620-050720","target":"/Towards-a-Human-like-Open-Domain-Chatbot","text":"Towards a Human-like Open-Domain Chatbot"},{"source":"/Week-Summary-231120-291120","target":"/November-23rd-2020","text":"November 23rd, 2020"},{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/Week-Summary-231120-291120","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/Week-Summary-231120-291120","target":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","text":"What Can We Do to Improve Peer Review in NLP"},{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"},{"source":"/Week-Summary-231120-291120","target":"/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION","text":"FROM UNSUPERVISED MACHINE TRANSLATION TO ADVERSARIAL TEXT GENERATION"},{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"},{"source":"/Week-Summary-231120-291120","target":"/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation","text":"Context-Aware Cross-Attention for Non-Autoregressive Translation"},{"source":"/Week-Summary-231120-291120","target":"/Rethinking-the-Value-of-Transformer-Components","text":"Rethinking the Value of Transformer Components"},{"source":"/Week-Summary-231120-291120","target":"/Catch-the-Tails-of-BERT","text":"Catch the ”Tails” of BERT"},{"source":"/Week-Summary-240820-300820","target":"/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation","text":"GLAT - Glancing Transformer for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow","text":"FlowSeq - Non-Autoregressive Conditional Sequence Generation with Generative Flow"},{"source":"/Week-Summary-240820-300820","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"},{"source":"/Week-Summary-240820-300820","target":"/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information","text":"Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information"},{"source":"/Week-Summary-240820-300820","target":"/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation","text":"A Study of Non-autoregressive Model for Sequence Generation"},{"source":"/Week-Summary-240820-300820","target":"/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning","text":"Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning"},{"source":"/Week-Summary-240820-300820","target":"/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation","text":"Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-240820-300820","target":"/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation","text":"Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation"},{"source":"/Week-Summary-250520-310520","target":"/May-25th-2020","text":"May 25th, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"},{"source":"/Week-Summary-250520-310520","target":"/May-31st-2020","text":"May 31st, 2020"},{"source":"/Week-Summary-250520-310520","target":"/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data","text":"Improving Non-autoregressive Neural Machine Translation with Monolingual Data"},{"source":"/Week-Summary-250520-310520","target":"/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention","text":"Faster Transformer Decoding - N-gram Masked Self-Attention"},{"source":"/Week-Summary-250520-310520","target":"/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models","text":"The Unreasonable Volatility of Neural Machine Translation Models"},{"source":"/Week-Summary-250520-310520","target":"/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions","text":"Are Transformers universal approximators of sequence-to-sequence functions"},{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"},{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"},{"source":"/Week-Summary-250520-310520","target":"/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP","text":"Language (Technology) is Power - A Critical Survey of Bias in NLP"},{"source":"/Week-Summary-250520-310520","target":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","text":"When Can Self-Attention Be Replaced by Feed Forward Layers"},{"source":"/Week-Summary-301120-061220","target":"/November-30th-2020","text":"November 30th, 2020"},{"source":"/Week-Summary-301120-061220","target":"/December-6th-2020","text":"December 6th 2020"},{"source":"/Week-Summary-301120-061220","target":"/December-7th-2020","text":"December 7th 2020"},{"source":"/Week-Summary-301120-061220","target":"/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING","text":"LANGUAGE MODEL IS ALL YOU NEED - NATURAL LANGUAGE UNDERSTANDING AS QUESTION ANSWERING"},{"source":"/Week-Summary-301120-061220","target":"/Shallow-to-Deep-Training-for-Neural-Machine-Translation","text":"Shallow-to-Deep Training for Neural Machine Translation"},{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"},{"source":"/Week-Summary-301120-061220","target":"/Efficient-Inference-For-Neural-Machine-Translation","text":"Efficient Inference For Neural Machine Translation"},{"source":"/Week-Summary-301120-061220","target":"/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State","text":"Contextual BERT - Conditioning the Language Model Using a Global State"},{"source":"/Week-Summary-310820-200920","target":"/August-30th-2020","text":"August 30th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/September-20th-2020","text":"September 20th, 2020"},{"source":"/Week-Summary-310820-200920","target":"/Neural-Machine-Translation-without-Embeddings","text":"Neural Machine Translation without Embeddings"},{"source":"/Week-Summary-310820-200920","target":"/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation","text":"Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Keita-Kurita","text":"Keita Kurita"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Paul-Michel","text":"Paul Michel"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Graham-Neubig","text":"Graham Neubig"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/June-1st-2020","text":"June 1st, 2020"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/RIPPLe","text":"RIPPLe"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/bi-level-optimization","text":"bi-level optimization"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Label-Flip-Rate","text":"Label Flip Rate"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/SST-2","text":"SST-2"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/OffenseEval","text":"OffenseEval"},{"source":"/Weight-Poisoning-Attacks-on-Pre-trained-Model","target":"/Enron","text":"Enron"},{"source":"/Weisfieler-Lehman-test","target":"/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures","text":"CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures"},{"source":"/Weisfieler-Lehman-test","target":"/Injective","text":"Injective"},{"source":"/Weisfieler-Lehman-test","target":"/Graph-Neural-Networks","text":"Graph Neural Networks"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Anna-Rogers","text":"Anna Rogers"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Isabelle-Augenstein","text":"Isabelle Augenstein"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/November-29th-2020","text":"November 29th, 2020"},{"source":"/What-Can-We-Do-to-Improve-Peer-Review-in-NLP","target":"/Peer-Review","text":"Peer Review"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Shucong-Zhang","text":"Shucong Zhang"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Erfan-Loweimi","text":"Erfan Loweimi"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Peter-Bell","text":"Peter Bell"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/Steve-Renals","text":"Steve Renals"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/May-29th-2020","text":"May 29th, 2020"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/WSJ","text":"WSJ"},{"source":"/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers","target":"/eval-2000-SWBD","text":"eval 2000 SWBD"},{"source":"/WikiText-103","target":"/Probing-Neural-Dialog-Models-for-Conversational-Understanding","text":"Probing Neural Dialog Models for Conversational Understanding"},{"source":"/Winograd-NLI","target":"/Winograd","text":"Winograd"},{"source":"/Winograd-NLI","target":"/Winogrande","text":"Winogrande"},{"source":"/Winograd-NLI","target":"/GLUE-Benchmark","text":"GLUE Benchmark"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Chi-kiu-Lo","text":"Chi-kiu Lo"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/June-18th-2020","text":"June 18th, 2020"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/Neural-Machine-Translation","text":"Neural Machine Translation"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-0","text":"YiSi-0"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-2","text":"YiSi-2"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/YiSi-1","text":"YiSi-1"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/BERT","text":"BERT"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/GloVe","text":"GloVe"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/word2vec","text":"word2vec"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/MATE","text":"MATE"},{"source":"/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources","target":"/chrF","text":"chrF"},{"source":"/datasets","target":"/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues","text":"(SPOLIN) Grounding Conversations with Improvised Dialogues"},{"source":"/diffpool","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/diffpool","target":"/Softmax","text":"Softmax"},{"source":"/gPool","target":"/Downsampling-based-Pooling","text":"Downsampling-based Pooling"},{"source":"/gPool","target":"/GCN-Filter","text":"GCN-Filter"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Hongyi-Zhang","text":"Hongyi Zhang"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Moustapha-Cisse","text":"Moustapha Cisse"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/David-Lopez-Paz","text":"David Lopez-Paz"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Classification","text":"Classification"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"Empirical Risk Minimization"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Empirical-Risk-Minimization","text":"EMR"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Vicinal-Risk-Minimization","text":"Vicinal Risk Minimization"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Generative-Adversarial-Network","text":"GAN"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Mixup","text":"Mixup"},{"source":"/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION","target":"/Occams-Razor","text":"Occam's Razor"},{"source":"/node2vec","target":"/DeepWalk","text":"DeepWalk"},{"source":"/node2vec","target":"/Random-Walk","text":"Random Walk"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Alexei-Baevski","text":"Alexei Baevski"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Henry-Zhou","text":"Henry Zhou"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Abdelrahman-Mohamed","text":"Abdelrahman Mohamed"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Michael-Auli","text":"Michael Auli"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/April-27th-2021","text":"April 27th 2021"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Self-Supervised-Learning","text":"Self-Supervised Learning"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Masked-Language-Modelling","text":"Masked Language Modelling"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Positional-Encodings","text":"Positional Encodings"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Product-Quantization","text":"Product Quantization"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriSpeech","text":"LibriSpeech"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/LibriVox","text":"LibriVox"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/Phoneme-Recoginition","text":"Phoneme Recoginition"},{"source":"/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations","target":"/TIMIT-dataset","text":"TIMIT dataset"}]}