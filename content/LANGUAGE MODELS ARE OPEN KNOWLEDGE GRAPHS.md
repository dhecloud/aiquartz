Author(s): [[Chenguang Wang]], [[Xiao Liu]], [[Dawn Song]]
Tags: #academic_papers, #language_model 
Read on: [[December 21st 2020]]
URL: https://arxiv.org/abs/2010.11967
# Main Contribution(s)
Converts [[language model]]s to [[Knowledge Graphs]] using a proposed [[Unsupervised]] approach called [[Match and Map]]
# Summary
![[Match and Map#LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS]]

### Experiments
![[Pasted image 20201221230131.png]] Results on [[TAC Knowledge Base Population]]

![[Pasted image 20201221230209.png]] Results on [[Wikidata]]

### Some analysis
1. [[Match and Map|MaMa]] is scalable to larger corpora, and larger models.
2. Larger corpora creates more complete [[Knowledge Graphs]]
3. 35.3% of unmapped facts are true on [[Wikidata]]
4. 45.5% of the untrue unmapped facts are due to incorrect [[Named Entity Recognition]] from [[spaCy]]
# Learning Gaps/Thoughts
# Simplify/Analogies