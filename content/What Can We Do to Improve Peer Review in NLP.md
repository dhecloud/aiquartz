Author(s): [[Anna Rogers]], [[Isabelle Augenstein]]
Tags: #Peer_Review, #academic_papers
Read on: [[November 29th, 2020]]
URL: https://arxiv.org/abs/2010.03863
# Main Contribution(s)
- Quantifies and analyses the pitfalls of peer review
# Summary
- Traditionally, [[Peer Review]] acts as a filter for high-quality impactful work. However, this does not hold in practice.
- Does not guarantee quality control for small errors or serious flaws. Cannot perform real quality control as that would have to ensure reproducibility. 
- Fails to detect impactful papers.
- Reviewers cope by relying on heuristics;
- Writing style. Language errors, non-standard style are interpreted as sloppiness. Biased towards North Americans
- SOTA. Does this paper beat SOTA
- Narrow Topics. Easier to publish on trendy topics
- Work not on English are harder to publish
- Already-famous work and work from well-known labs
- Complexity of solution. Complex solutions are more favored, though this mindset is flawed.
- Non-mainstream approaches.
- Resource papers are almost always instantly rejected
- Novel approaches are often rejected; less favored over incremental work
- Substitute questions. Any obvious ways to improve paper; If i did this study would i make the same choices?
- What can we do?
- Better reviewer matching to their field, to avoid resorting to heuristics
- More fine-grained tracks
- Review forms for different paper types
- Announcing editorial priorities
- Not asking reviewers for overall recommendation scores.
# Learning Gaps/Thoughts
-
# Simplify/Analogies
-
