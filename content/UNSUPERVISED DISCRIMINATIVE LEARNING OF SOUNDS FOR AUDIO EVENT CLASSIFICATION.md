Author(s): [[Sascha Hornauer]], [[Ke Li]], [[Stella X. Yu]], [[Shabnam Ghaffarzadegan]], [[Liu Ren]]
Tags: #academic_papers, #audio_tagging 
Read on: [[07-Jun-2021]]
URL: [\[2105.09279\] Unsupervised Discriminative Learning of Sounds for Audio Event Classification (arxiv.org)](https://arxiv.org/abs/2105.09279)
# Main Contribution(s)
Problem: Audio training usually utilizes pretraining from image, and this is time consuming
Solution: Propose a new approach called [[Unsupervised Discriminative Learning of Sounds]]
# Summary
![[Unsupervised Discriminative Learning of Sounds#UNSUPERVISED DISCRIMINATIVE LEARNING OF SOUNDS FOR AUDIO EVENT CLASSIFICATION]]

![[Pasted image 20210607142550.png]]Results on [[ESC-10]], [[ESC-50]], [[UrbanSound8k]]
They show that using only a small amount of sound data, they can gain early performance as the same network pre-trained on [[ImageNet]]
# Learning Gaps/Thoughts

# Simplify/Analogies