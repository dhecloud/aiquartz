<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>aibrain on</title><link>https://aibrain.dhecloud.xyz/</link><description>Recent content in aibrain on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://aibrain.dhecloud.xyz/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://aibrain.dhecloud.xyz/Paper-Levenshtein-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Paper-Levenshtein-Transformer/</guid><description>Author(s): [[Jiatao Gu]], [[Changhan Wang]], [[Jake Zhao Junbo]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #Sequence_Refinement, #academic_papers Read on: [[August 23rd, 2020]] URL: https://arxiv.org/abs/1905.11006</description></item><item><title/><link>https://aibrain.dhecloud.xyz/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SPOLIN-Grounding-Conversations-with-Improvised-Dialogues/</guid><description>Author(s): [[Hyundong Cho]], [[Jonathan May]] Tags: #datasets, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 22nd, 2020]] URL: http://arxiv.org/abs/2004.09544
Main Contribution(s) Introduce a corpus Selected Pairs Of Learnable Improvisation (SPOLIN) which is made from the &amp;ldquo;yes-and&amp;rdquo; principle in conversations and improv Summary Effective dialogue involves ==grounding==, the process of establishing mutual knowledge that is essential for communication between people Issues with open-domain neural dialogue system is that they ==lack coherence and interestingness, or generate non-committal generic statements like &amp;ldquo;I don&amp;rsquo;t know&amp;rdquo;== SPOLIN The Spontaneanation podcast is used as a source of yes-ands.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/10-things-you-should-know-about-dialogue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/10-things-you-should-know-about-dialogue/</guid><description>Speaker(s): [[Milica Gašić]] Tags: #Dialogue_Modelling, #seminar Held on: [[July 24th, 2020]] URL: https://www.clsp.jhu.edu/2020-jsalt-plenary-talks/
Humans do not make a strict distinction between task oriented and chat dialogue, while modelling approaches do.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/20NEWS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/20NEWS/</guid><description>18,846 (11,314 for training and 7,532 for testing) text documents associated with 20 classes</description></item><item><title/><link>https://aibrain.dhecloud.xyz/33bdea/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/33bdea/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/3F4758/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/3F4758/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/485f6f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/485f6f/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/515e70/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/515e70/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/8A3CC8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/8A3CC8/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/939aae/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/939aae/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/9aabd0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/9aabd0/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/9eb3c0a8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/9eb3c0a8/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/A-Novel-Graph-based-Multi-modal-Fusion-Encoder-for-Neural-Machine-Translation/</guid><description>Author(s): [[Yongjing Yin]], [[Fandong Meng]], [[Jinsong Su]], [[Chulun Zhou]], [[Zhengyuan Yang]], [[Jie Zhou]], [[Jiebo Luo]] Tags: #academic_papers, #Neural_Machine_Translation, #Graph_Neural_Networks, Read on: [[December 23rd 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/A-Primer-in-BERTology-What-We-Know-About-How-BERT-Works/</guid><description>Author(s): [[Anna Rogers]], [[Olga Kovaleva]], [[Anna Rumshisky]] Tags: #academic_papers, #critique, #BERT Read on: [[January 12th 2021]] URL: https://arxiv.org/abs/2002.12327
Main Contribution(s) Provides a comprehensive overview on [[BERT]] and the different approaches and tasks done on [[BERT]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/A-Robust-Framework-For-Acoustic-Scene-Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/A-Robust-Framework-For-Acoustic-Scene-Classification/</guid><description>Author(s): [[Lam Pham]], [[Ian McLoughlin]], [[Huy Phan]], [[Ramaswamy Palaniappan]] Tags: #academic_papers, #audio_tagging Read on: [[31-May-2021]] URL: [2002.04502] Robust Acoustic Scene Classification using a Multi-Spectrogram Encoder-Decoder Framework (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/A-Study-of-Non-autoregressive-Model-for-Sequence-Generation/</guid><description>Author(s): [[Yi Ren]], [[Jinglin Liu]], [[Xu Tan]], [[Zhou Zhao]], [[Sheng Zhao]], [[Tie-Yan Liu]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #Automatic_Speech_Recognition, #Text_to_Speech, #academic_papers Read on: [[August 25th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/A-Transformer-based-Audio-Captioning-Model-with-Keyword-Estimation/</guid><description>Author(s): [[Yuma Koizumi]], [[Ryo Masumura]], [[Kyosuke Nishida]], [[Masahiro Yasuda]], [[Shoichiro Saito]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 9th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Abdelrhman-Saleh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Abdelrhman-Saleh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ablation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ablation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Abstract-Meaning-Representations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Abstract-Meaning-Representations/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/academic-papers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/academic-papers/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Accelerating-Machine-Learning-with-Confidential-Computing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Accelerating-Machine-Learning-with-Confidential-Computing/</guid><description>Speaker(s): [[Alex Shamis]], [[Stavros Volos]], [[Antoine Delignat-Lavaud]], [[Raluca Ada Popa]], [[Emmett Witchel]] Tags: #seminar Held on: [[July 21st, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Accuracy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Accuracy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ACUTE-EVAL-Improved-Dialogue-Evaluation-with-Optimized-Questions-and-Multi-turn-Comparisons/</guid><description>Author(s): [[Margaret Li]], [[Jason Weston]], [[Stephen Roller]] Tags: #Evaluation_Metric, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 24th, 2020]] URL: http://arxiv.org/abs/1909.03087
Main Contribution(s) Presents a new evaluation method with a clear mechanism that provides fast, cheap iteration Compares the currently best performing retrieval and generation models on [[PersonaChat]] and [[Wizard of Wikipedia]] Summary Single-turn pairwise evaluation fail to take into account the multi-turn aspect Multi-turn [[Likert Scores]] require annotator to have a multi-turn conversation and then provide an integer score; but scores suffers from variance and bias from annotators [ACUTE-EVAL]([[ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons]]) evaluation metric Ask annotators to make ==binary judgements== between sampled pairs from the logs, and then collate results Experiments/Findings Compare 2 state of the art models, one Polyencoder, another by HuggingFace Find that retrieval models outperform generative models for both [[PersonaChat]] and [[Wizard of Wikipedia]] Find that ACUTE-EVAL can be a more sensitive test, which more often yield significance.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/ACUTE-Eval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ACUTE-Eval/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adafactor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adafactor/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adam/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adaptive-Character-of-Thought-ACT-Memory-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adaptive-Character-of-Thought-ACT-Memory-Model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adaptive-Mean-Margin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adaptive-Mean-Margin/</guid><description>[[Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions]] $$M_{xy} = \alpha(S(x_i,y_i) - \frac{1}{B-1}\sum_{j=1}^B I_{i\neq j}S(x_i,y_j))$$ where $\alpha$ is a dampening parameter to weigh the strength of the margin.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Aditya-Ramesh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Aditya-Ramesh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adjacency-Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adjacency-Matrix/</guid><description>Graphs of a graph represents the connectivity between two nodes. $A_{i,j}=1$ if $v_i$ is adjacent to $v_j$, otherwise 0.
This means that for an undirected graph, its correponding adjacency matrix is symmetric</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Adjacency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adjacency/</guid><description>[[Document Graph for Neural Machine Translation]] Links from current word to adjacent words</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Advancing-Visual-Intelligence-via-Neural-System-Design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Advancing-Visual-Intelligence-via-Neural-System-Design/</guid><description>Speaker(s): [[Hengshuang Zhao]] Tags: #seminar Held on: [[January 27th 2021]] URL: https://ntu-sg.zoom.us/webinar/register/WN_xADnCWfsSz64uF8QXcONZA
Challenges in [[Semantic Segmentation]]: mismatched relationships, confused categories and tiny objects.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/adversarial-attacks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/adversarial-attacks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adversarial-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adversarial-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Adversarial-Loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Adversarial-Loss/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Agenda-based-User-Simulation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Agenda-based-User-Simulation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Agglomerative-Hierarchical-Clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Agglomerative-Hierarchical-Clustering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ahmad-Rashid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ahmad-Rashid/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Akshay-Krishnamurthy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Akshay-Krishnamurthy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alan-Do-Omri/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alan-Do-Omri/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alan-Turing-The-Enigma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alan-Turing-The-Enigma/</guid><description>Author(s): [[Andrew Hodges]] Tags: #book Start-End Date: [[July 31st, 2020]] -</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Alec-Radford/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alec-Radford/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Aleksander-Madry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Aleksander-Madry/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alessandra-Cervone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alessandra-Cervone/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alex-P.-Pentland/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alex-P.-Pentland/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alex-Shamis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alex-Shamis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alexa-Prize/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alexa-Prize/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alexander-S.-Ecker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alexander-S.-Ecker/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alexei-A.-Efros/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alexei-A.-Efros/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Algebraic-Multiplicity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Algebraic-Multiplicity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ali-Razavi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ali-Razavi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alice-Oh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alice-Oh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alvaro-Rodrigo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alvaro-Rodrigo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Alyssa-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Alyssa-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Amanda-Askell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Amanda-Askell/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Amazon-Mechanical-Turk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Amazon-Mechanical-Turk/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Amit-Sharma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Amit-Sharma/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Amnesic-Probing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Amnesic-Probing/</guid><description>[[A Primer in BERTology - What We Know About How BERT Works]] Refers to removing certain information from a model to see how it changes performance</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Amr-Ahmed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Amr-Ahmed/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/An-Analysis-of-State-of-the-art-Activation-Functions-For-Supervised-Deep-Neural-Network/</guid><description>Author(s): [[Anh Nguyen]], [[Khoa Pham]], [[Dat Ngo]], [[Thanh Ngo]], [[Lam Pham]] Tags: #academic_papers Read on: [[31-May-2021]] URL: An Analysis of State-of-the-art Activation Functions For Supervised Deep Neural Network | DeepAI</description></item><item><title/><link>https://aibrain.dhecloud.xyz/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/An-Audio-Based-Deep-Learning-Framework-For-BBC-Television-Programme-Classification/</guid><description>Author(s): [[Lam Pham]], [[Chris Baume]], [[Qiuqiang Kong]], [[Tassadaq Hussain]], [[Wenwu Wang]], [[Mark D. Plumbley]] Tags: #academic_papers, #audio_tagging Read on: [[31-May-2021]] URL: An Audio-Based Deep Learning Framework ForBBC Television Programme Classification - NASA/ADS (harvard.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Analogical-Scheme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Analogical-Scheme/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Andrea-Madotto/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Andrea-Madotto/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Andrew-Hodges/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Andrew-Hodges/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Andrew-Ng/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Andrew-Ng/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Andrew-Prahl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Andrew-Prahl/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Anirudh-Ravula/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Anirudh-Ravula/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Anisotropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Anisotropy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ankit-Singh-Rawat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ankit-Singh-Rawat/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ankur-Bapna/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ankur-Bapna/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ankur-Teredesai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ankur-Teredesai/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ANLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ANLI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Anna-Rogers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Anna-Rogers/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Antoine-Delignat-Lavaud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Antoine-Delignat-Lavaud/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Antonio-Art%C3%A9s-Rodr%C3%ADguez/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Antonio-Art%C3%A9s-Rodr%C3%ADguez/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/An%C3%ADbal-R.-Figueiras-Vidal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/An%C3%ADbal-R.-Figueiras-Vidal/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Apoorv-Kulshreshtha/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Apoorv-Kulshreshtha/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Approximate-Rule-Based-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Approximate-Rule-Based-Systems/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Arantxa-Otegi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Arantxa-Otegi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ARC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ARC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Are-Transformers-universal-approximators-of-sequence-to-sequence-functions/</guid><description>Author(s): [[Chulhee Yun]], [[Srinadh Bhojanapalli]], [[Ankit Singh Rawat]], [[Sashank J. Reddi]], [[Sanjiv Kumar]] Tags: #critique, #transformer, #BERT, #academic_papers Read on: [[May 28th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ariel-Herbert-Voss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ariel-Herbert-Voss/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Arthur-Szlam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Arthur-Szlam/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Artificial-Intelligence-AI-in-Education/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Artificial-Intelligence-AI-in-Education/</guid><description>Speaker(s): [[Mike Timms]] Tags: #seminar Held on: [[August 28th, 2020]] URL: https://wis.ntu.edu.sg/webexe88/owa/REGISTER_NTU.REGISTER?EVENT_ID=OA20072318591930
[[Mike Timms]] [[Intelligent Tutoring Systems (ITS)]] model consists of 4 steps, but have been modernized to include more steps.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Arvind-Neelakantan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Arvind-Neelakantan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Asli-Celikyilmaz/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Asli-Celikyilmaz/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ATTENTION-IS-ALL-YOU-NEED-IN-SPEECH-SEPARATION/</guid><description>Author(s): [[Cem Subakan]], [[Mirco Ravanelli]], [[Samuele Cornell]], [[Mirko Bronzi]], [[Jianyuan Zhong]] Tags: #academic_papers, #speech_separation Read on: [[05-Feb-2022]] URL: https://arxiv.org/abs/2010.13154
Main Contribution(s) Problem: SOTA still uses RNN Solution: proposes the [[Sepformer]], which is basically the transformer for [[Speech Separation]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Attraction-Force-Field/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Attraction-Force-Field/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Audio-Caption-in-a-Car-Setting-with-a-Sentence-Level-Loss/</guid><description>Author(s): [[Xuenan Xu]], [[Heinrich Dinkel]], [[Mengyue Wu]], [[Kai Yu]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 14th 2021]] URL: https://arxiv.org/abs/1905.13448
Main Contribution(s) Uses a encoder-decoder model with a sentence level loss for [[Automated Audio Captioning]] in a car setting</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Audio-Captioning-Based-on-Combined-Audio-and-Semantic-Embeddings/</guid><description>Author(s): [[Ayşegül Özkaya Eren]], [[Mustafa Sert]] Tags: #academic_papers Read on: [[February 14th 2021]] URL: https://ieeexplore.ieee.org/document/9327916
Main Contribution(s) Uses a pretrained audio neural network as a feature extractor.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/AUDIO-CAPTIONING-BASED-ON-TRANSFORMER-AND-PRE-TRAINED-CNN/</guid><description>Author(s): [[Yusong Wu]], [[Kun Chen]], [[Ziyue Wang]], [[Xuan Zhang]], [[Fudong Nian]], [[Shengchen Li]], [[Xi Shao]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 14th 2021]] URL: http://dcase.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/AUDIO-CAPTIONING-USING-GATED-RECURRENT-UNITS/</guid><description>Author(s): [[Ayşegül Özkaya Eren]], [[Mustafa Sert]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 9th 2021]] URL: https://arxiv.org/abs/2006.03391
Main Contribution(s) Uses a combination of [[VGGish]] [[Embeddings]], Bi-[[Gated Recurrent Unit]]s, and [[word2vec]] embeddings for the purpose of [[Automated Audio Captioning|AAC]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Audio-Captioning-using-Pre-Trained-Large-Scale-Language-Model-Guided-by-Audio-based-Similar-Caption-Retrieval/</guid><description>Author(s): [[Yuma Koizumi]], [[Yasunori Ohishi]], [[Daisuke Niizumi]], [[Daiki Takeuchi]], [[Masahiro Yasuda]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 9th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Audio-Grounding-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Audio-Grounding-dataset/</guid><description>[[TEXT-TO-AUDIO GROUNDING - BUILDING CORRESPONDENCE BETWEEN CAPTIONS AND SOUND EVENTS]] ![[Pasted image 20210503163120.png]] Taken from [[AudioCaps]] and [[AudioSet]]. Only those with more than 4 sound tags are used from [[AudioCaps]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/AudioCaps-Generating-Captions-for-Audios-in-The-Wild/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/AudioCaps-Generating-Captions-for-Audios-in-The-Wild/</guid><description>Author(s): [[Chris Dongjoo Kim]], [[Byeongchang Kim]], [[Hyunmin Lee]], [[Gunhee Kim]] Tags: #academic_papers, #datasets, #Automated_Audio_Captioning Read on: [[February 10th 2021]] URL: https://www.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/AudioCaps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/AudioCaps/</guid><description>[[AudioCaps - Generating Captions for Audios in The Wild]] ![[Pasted image 20210210005803.png]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/AudioSet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/AudioSet/</guid><description>Two versions:
The original one with weak labels (temporally imprecise) AudioSet A smaller subset with strong precise labels. Download: Temporally-Strong Labels Download (May 2021)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Augmented-Reality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Augmented-Reality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-10th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-10th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-11th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-11th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-12th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-12th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-13th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-13th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-14th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-14th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-15th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-15th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-17th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-17th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-21st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-21st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-2nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-2nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-31st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-31st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-3rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-4th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-4th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-6th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-6th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-7th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-7th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/August-9th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/August-9th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Augustin-Chaintreau/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Augustin-Chaintreau/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Authors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Authors/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Auto-Encoders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Auto-Encoders/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Automated-Audio-Captioning-with-Recurrent-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Automated-Audio-Captioning-with-Recurrent-Neural-Networks/</guid><description>Author(s): [[Konstantinos Drossos]], [[Sharath Adavanne]], [[Tuomas Virtanen]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 9th 2021]] URL: https://arxiv.org/abs/1706.10006
Main Contribution(s) First paper to tackle [[Automated Audio Captioning|AAC]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Automated-Audio-Captioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Automated-Audio-Captioning/</guid><description>an intermodal translation task, where the system receives as an input an audio signal and outputs a textual description of the contents of the audio signal (i.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Automatic-Speech-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Automatic-Speech-Recognition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Averaging-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Averaging-Filter/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Avinava-Dubey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Avinava-Dubey/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/bAbI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/bAbI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bag-of-Feature-Models-Based-on-C-DNN-Network-for-Acoustic-Scene-Classification/</guid><description>Author(s): [[Lam Pham]], [[Ian McLoughlin]], [[Huy Phan]], [[Ramaswamy Palaniappan]], [[Yue Lang]] Tags: #academic_papers, #audio_tagging Read on: [[31-May-2021]] URL: AES E-Library » Bag-of-Features Models Based on C-DNN Network for Acoustic Scene Classification</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Balance-Theory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Balance-Theory/</guid><description>(Heider, 1946; Cartwright and Harary, 1956) suggests that &amp;ldquo;the friend of my friend is my friend&amp;rdquo; and “the enemy of my friend is my enemy”</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Basil-Abraham/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Basil-Abraham/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Batch-Normalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Batch-Normalization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bayan-Abu-Shawar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bayan-Abu-Shawar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bayes-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bayes-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bayes-Theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bayes-Theorem/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bayesian-Belief-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bayesian-Belief-Networks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bei-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bei-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Benjamin-Chess/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Benjamin-Chess/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Benjamin-Mann/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Benjamin-Mann/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bernadette-Bouchon-Meunier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bernadette-Bouchon-Meunier/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/BERT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/BERT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Besmira-Nushi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Besmira-Nushi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Best-Approximation-Theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Best-Approximation-Theorem/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Better-Roam-Research/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Better-Roam-Research/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Betweenness-Centrality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Betweenness-Centrality/</guid><description>based on number of paths passing through a node, unlike the above which are based on connections. It is defined as $$c_b(v_i)=\sum_{v_s\neq v_i \neq v_t} \frac{\sigma_{st}(v_i)}{\sigma_{st}}$$ where $\sigma_{st}$ is the total number of shortest paths from node $v_s$ to node $v_t$, while $\sigma_{st}(v_i)$ indicates the number of these paths passing through the node $v_i$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Beyond-Equal-Length-Snippets-How-Long-is-Sufficient-to-Recognize-an-Audio-Scene/</guid><description>Author(s): [[Huy Phan]], [[Oliver Y. Chen]], [[Philipp Koch]], [[Lam Pham]], [[Ian McLoughlin]], [[Alfred Mertins]], [[Maarten De Vos]] Tags: #academic_papers, #audio_tagging Read on: [[May 18th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Beyond-Fairness-Pushing-ML-Frontiers-for-Social-Equity/</guid><description>Speaker(s): [[Mary Gray]] (host), [[Rediet Abebe]], [[Irene Lo]], [[Augustin Chaintreau]] Tags: #Social_Good, #seminar Held on: [[July 21st, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/bi-level-optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/bi-level-optimization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/bias/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/bias/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Big-Bird-Transformers-for-Longer-Sequences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Big-Bird-Transformers-for-Longer-Sequences/</guid><description>Author(s): [[Manzil Zaheer]], [[Guru Guruganesh]], [[Avinava Dubey]], [[Joshua Ainslie]], [[Chris Alberti]], [[Santiago Ontanon]], [[Philip Pham]], [[Anirudh Ravula]], [[Qifan Wang]], [[Li Yang]], [[Amr Ahmed]] Tags: #transformer, #BERT, #academic_papers, #google Read on: [[August 11th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Big-Ideas-in-Causality-and-Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Big-Ideas-in-Causality-and-Machine-Learning/</guid><description>Speaker(s): [[Amit Sharma]], [[Susan Athey]], [[Elias Bareinboim]], [[Cheng Zhang]] Tags: #seminar Held on: [[July 21st, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/BigBird/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/BigBird/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bilateral-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bilateral-Filtering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bilinear-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bilinear-Models/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] Aims to use a multiplicative approach and to represent the relationships as matrics in teh vector space.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bilingual-Adversarial-Text-Generator-B-GAN-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bill-Dolan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bill-Dolan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/BiLSTM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/BiLSTM/</guid><description>Bidirectional [[LSTM]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Binary-Matrix-Operations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Binary-Matrix-Operations/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Binary-Tree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Binary-Tree/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bipartite-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bipartite-Graphs/</guid><description>![[Pasted image 20201203143532.png]]can be divded into two disjoint subsets. Formally, $$V = V_1 \cup V_2, V_1 \cap V_2 = \emptyset $$$$ v_e^1 \in V_1, v_e^2 \in V_2 \text{ for all }e=(v_e^1,v_e^2)\in E$$ Often used to capture interactions between different objects</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Black-box-attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Black-box-attack/</guid><description>Minimal information. Only allows to query from victim model.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Blended-Skill-Talk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Blended-Skill-Talk/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/BLEU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/BLEU/</guid><description>Note: BLEU scores are between 0-1. If scores appear as a double digit number, like 22.3, it means that it has been multipled by 100.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/block-input/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/block-input/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bo-An/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bo-An/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bo-Hsiang-Tseng/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bo-Hsiang-Tseng/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/book/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/book/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning/</guid><description>Author(s): [[Jean-Bastien Grill]], [[Florian Strub]], [[Florent Altche]], [[Corentin Tallec]], [[Pierre H. Richemond]], [[Elena Buchatskaya]], [[Carl Doersch]], [[Bernado Avila Pires]], [[Zhaohan Daniel Guo]], [[Mohammad Gheshlaghi Azar]], [[Bilal Piot]], [[Koray Kavukcuoglu]], [[Remi Munos]], [[Michal Valko]] Tags: #academic_papers Read on: [[01-Jun-2021]] URL: [2006.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Bootstrap-Your-Own-Latent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Bootstrap-Your-Own-Latent/</guid><description>[[Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning]] ![[Pasted image 20210601202347.png]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Born-Again-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Born-Again-Networks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/bottleneck-issues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/bottleneck-issues/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Breadth-First-Search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Breadth-First-Search/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Break-into-Natural-Language-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Break-into-Natural-Language-Processing/</guid><description>Speaker(s): [[Andrew Ng]], [[Kenneth Church]], [[Marti Hearst]], [[Łukasz Kaiser]], [[Younes Bensouda Mourri]] Tags: #seminar Held on: [[July 30th, 2020]], 1am URL: https://www.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/British-National-Corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/British-National-Corpus/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/buffer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/buffer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/c5d1d8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/c5d1d8/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Caiming-Xiong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Caiming-Xiong/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CAN-AUDIO-CAPTIONS-BE-EVALUATED-WITH-IMAGE-CAPTION-METRICS/</guid><description>Author(s): [[Zelin Zhou]], [[Zhiling Zhang]], [[Xuenan Xu]], [[Zeyu Xie]], [[Mengyue Wu]], [[Kenny Q. Zhu]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[05-Jan-2022]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Canny-Edge-Detector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Canny-Edge-Detector/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Carlili-Wagner-Loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Carlili-Wagner-Loss/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CART/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CART/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Casual-Language-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Casual-Language-Modelling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Catastrophic-Forgetting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Catastrophic-Forgetting/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Catch-the-Tails-of-BERT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Catch-the-Tails-of-BERT/</guid><description>Author(s): [[Ziyang Luo]] Tags: #BERT, #academic_papers Read on: [[November 26th, 2020]] URL: https://arxiv.org/abs/2011.04393
Main Contribution(s) Inspects the vector space of [[BERT]] and [[RoBERTa]] and finds some interesting quirks that the author terms to be tails.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CATEGORICAL-REPARAMETERIZATION-WITH-GUMBEL-SOFTMAX/</guid><description>Author(s): [[Eric Jang]], [[Shixiang Gu]], [[Ben Poole]] Tags: #academic_papers Read on: [[May 1st 2021]] URL: https://arxiv.org/abs/1611.01144
Main Contribution(s) Problem: Backpropagation cannot be done through samples Solution: [[Gumbel-Softmax]] is a reparameterization trick that allows gradients to propagate through a differentiable sample</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Catherine-Yeo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Catherine-Yeo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Cauchy-Schwarz-Inequality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cauchy-Schwarz-Inequality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Computational-Intelligence-Methods-and-Applications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Computational-Intelligence-Methods-and-Applications/</guid><description> [[CE7429 - Lecture 2]] [[CE7429 - Lecture 3]] [[CE7429 - Lecture 4]] [[CE7429 - Lecture 5]] [[CE7429 - Lecture 6]] [[CE7429 - Lecture 7]] [[CE7429 - Lecture 8]] [[CE7429 - Lecture 9]] [[CE7429 - Lecture 10]] [[CE7429 - Lecture 11]] [[CE7429 - Lecture 12]] [[CE7429 - Lecture 13]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-10/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-10/</guid><description> Date: [[September 8th, 2020]] [[Receiver Operating Characteristics (ROC)]] curve</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-11/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-11/</guid><description> Date: [[September 15th, 2020]] watched a video today????</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-12/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-12/</guid><description> Date: [[August 18th, 2020]] [[Rule-Based Approaches]] consists of rules and the inference to extract a conclusion [[Knowledge Based Agents]] requires knowledge representation - logic-based, graphic-based [[Memory]] is the capacity to retain information over time Sensory Short Term Long Term Implicit or procedural memory like riding a bicycle Explicit or declarative memory for facts and events (conscious recall) Symbolic memory for factual knowledge Episodic memory for personally experienced events</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-13/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-13/</guid><description>Date: [[September 22nd, 2020]] [[Semantic Memory Duration]] Related to [[Catastrophic Forgetting]]? [[Modal Memory Model (SOAR)]] Stimulus -&amp;gt; [[Sensory Memory]] -&amp;gt; [[Short Term Memory]] &amp;lt;-&amp;gt; [[Long Term Memory]] [[Adaptive Character of Thought (ACT) Memory Model]] [[Working Memory Model]] [[Chunking]] refers to the process of taking individual pieces of information and grouping them into larger units.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-2/</guid><description> Date: [[August 14th, 2020]] [[Computational Intelligence]] is a branch of science dealing with problems that cannot be solved using effective computational algorithms and we focus on human-brain inspired approaches using a repertoire of AI or ML tools to achieve human-like, interpretable decision process Biological inspirations help to formulate initial models: Neural networks design architecture Psychological inspirations in the form of larger brain structures are considered (connectionist models) Bio-medical inspirations: Swarm Algorithms, Immunological systems, etc Logic inspirations: Fuzzy, Crisp, Rough logic</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-3/</guid><description> Date: [[August 14th, 2020]] Features: measurements or evaluation of some object properties Feature Space representation: mapping into vectors. Can be symbolic or discrete [[Exploratory Data Analysis]]: visualize relationships in the data Using histograms or other plots [[Bayes Theorem]] $$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-4/</guid><description> Date: [[August 18th, 2020]] 2D projections - scatterplots correlations between variables clustering of different objects [[Starplots]] Helpful for small to moderate sized multivariate datasets &amp;lt;100 points</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-5/</guid><description> Date: [[August 21st, 2020]] [[Chernoff Faces]] Displays multivariate data with human faces [[Exploratory Data Analysis]] Distance in feature spaces Data standardization/normalization Standard Deviation [[Principal Component Analysis]] [[Mahalanobis Distance]] Invariant to linear transformation</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-6/</guid><description>Date: [[August 25th, 2020]] [[Principal Component Analysis]] problem Gives worst possible solution from the point of view of seeing the structure of the data Finds the most accurate data representation in a lower dimension Completely unsupervised, knows only about variance, but nothing about different classes of data [[Discriminant Component Analysis]] [[Fisher&amp;rsquo;s Discriminant Analysis]] [[Linear Discriminant Analysis]] explicitly attempts to model the difference between the classes of data.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-7/</guid><description>Date: [[August 28th, 2020]] [[Fisher&amp;rsquo;s Discriminant Analysis]] Takes into account within class scatter matrix [[Principal Component Analysis]] and [[Fisher&amp;rsquo;s Discriminant Analysis]] are linear [[Projection Pursuit]] may be linear or non-linear Used for visualization, dimensional reduction, and regression [[Independent Component Analysis]] is a method for finding underlying factors or components from multivariate statistical data.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-8/</guid><description>Date: [[September 1st, 2020]] [[Self-Organized Feature Mapping (SOFM)]] can be used as a projection from 3D to a lower dimension grid Competition: Use similarity of input data to their parameters Cooperation: Use neighborhood function to group Dynamics: Adaptation rule.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7429-Lecture-9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7429-Lecture-9/</guid><description>Date: [[September 4th, 2020]] Selecting a good model a priori knowledge might be needed Regularization to decrease variance Train/test/split [[cross validation]] [[Curse of Dimensionality]] High dimensions are almost always empty or sparse!</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7454-Deep-Learning-for-Data-Science-Lecture-Notes-Recent-Developments-in-Graph-Network-Architectures/</guid><description>Notes iteration: Semester 1 2020/21
[[Graph Neural Networks]] based on the [[Weisfieler-Lehman test|WL test]] ![[Graph Isomorphism#CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-SPECIAL-ADVANCED-TOPIC-DIGITAL-IMAGE-PROCESSING/</guid><description> [[CE7491 Lecture 1]] [[CE7491 Lecture 2]] [[CE7491 Lecture 3]] [[CE7491 Lecture 4]] [[CE7491 Lecture 5]] [[CE7491 Lecture 6]] [[CE7491 Lecture 7]] [[CE7491 Lecture 8]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-1/</guid><description> [[Field of View]]: maximum angle of the scene observed by the camera Depends on focal length of lens, size of imaging plan [[Depth of Field]]: range of depths that scene objects can be at, such that they remain in acceptable focus simultaneously Depends on focal length of lens, aperture size [[Gray-Level Indexing]]: improving image quality by using an assigning a pixel value to an index [[Image Dithering]] trades of spatial resolution for perceptual increase in pixel depth</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-2/</guid><description>Date: [[August 19th, 2020]] [[Point Processing]] Each new pixel depends only on itself [[Spatial Filtering]] Each new pixel depends on the neighboring pixels [[Image Negatives]] Inverting gray labels [[Contrast Stretching]] increases contrast of images captured under poor illumination, wrong camera setting, etc.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-3/</guid><description>Date: [[August 26th, 2020]] [[Spectral Power Distribution]] Plot of power against wavelight Grayscale cameras only have one response function Color sensation is a simplified human representation.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-4/</guid><description> Date: [[September 2nd, 2020]] Mainly basics about CNNs [[Pooling]] is useful for building inner activations that are slightly invariant to small changes in inputs</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-5/</guid><description>Date: [[September 9th, 2020]] [[Batch Normalization]] reduces internal covariate shift, improves optimization. Estimates Mean and Standard Deviation for each minibatch, but might not be possible during test time.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-6/</guid><description>Date: [[September 16th, 2020]] [[Region Proposal Network]] [[Faster R-CNN]] is a two stage object detector Run backbone network and region proposal network per image Crop features, predict object class, prediction bbox offset per region [[Image Restoration]] [[Super-Resolution]] produce a detailed realistic output image which is faithful to the low resolution image Allows for saving bandwidth Single image up-scaling is ill posed because there exists infinite high resolutions solutions for that low resolution image Example based methods learn mapping functions from external low and high resolution exemplar pairs [[Deconvolution (Transposed Convolution)]] same as normal convolution but in the backward direction (smaller to bigger dimension) Causes &amp;ldquo;checkerboard&amp;rdquo; artifacts in the upsampled image due to the uneven overlap when the kernel size is not divisible by the stride.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-7/</guid><description> Date: [[September 23rd, 2020]] Exploit [[Generative Adversarial Network]] priors for conditional [[Super-Resolution]] [[GAN-Inversion]] [[Self-Supervised Learning]] by solving jigsaw puzzles, counting, colorization</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CE7491-Lecture-8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CE7491-Lecture-8/</guid><description>Date: [[October 7th, 2020]] [[Image-to-Image Translation]] [[Deep Fakes]] - realistic images; manipulating physical attributes into those not previously observed before.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Cerebellar-Model-Articulation-Controller-CMAC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cerebellar-Model-Articulation-Controller-CMAC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chai-Quek/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chai-Quek/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Changhan-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Changhan-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Character-Error-Rate-CER/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Character-Error-Rate-CER/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Characteristic-Equation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Characteristic-Equation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Cheby-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cheby-Filter/</guid><description>The [[Poly-Filter]] is unable to create an [[Orthogonal Basis]] of the polynomial, thus increasing depedency of each coefficient on each other.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Chebyshev-Polynomial/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chebyshev-Polynomial/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Cheng-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cheng-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chernoff-Faces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chernoff-Faces/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chi-kiu-Lo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chi-kiu-Lo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ching-Tsan-Chiang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ching-Tsan-Chiang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chitwan-Saharia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chitwan-Saharia/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/chrF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/chrF/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chris-Alberti/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chris-Alberti/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chris-Bishop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chris-Bishop/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chris-Brockett/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chris-Brockett/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Christof-Monz/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Christof-Monz/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Christophe-Marsala/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Christophe-Marsala/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Christopher-Berner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Christopher-Berner/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Christopher-Hesse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Christopher-Hesse/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chromaticity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chromaticity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chulhee-Yun/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chulhee-Yun/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chun-Shin-Lin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chun-Shin-Lin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chunking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chunking/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chunqi-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chunqi-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Chunting-Zhou/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Chunting-Zhou/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ciprian-Chelba/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ciprian-Chelba/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Clemens-Winter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Clemens-Winter/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Clotho-An-Audio-Captioning-Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Clotho-An-Audio-Captioning-Dataset/</guid><description>Author(s): [[Konstantinos Drossos]], [[Samuel Lipping]], [[Tuomas Virtanen]] Tags: #academic_papers, #datasets, #Automated_Audio_Captioning Read on: [[February 10th 2021]] URL: https://arxiv.org/abs/1910.09387
Main Contribution(s) Proposes the [[Clotho dataset]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Clotho-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Clotho-dataset/</guid><description>Available at here and github. [[Automated Audio Captioning]] dataset, consisting of 4981 audio samples, and each audio sample has five captions (a total of 24905 captions).</description></item><item><title/><link>https://aibrain.dhecloud.xyz/clustering-coefficient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/clustering-coefficient/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Code-Mixing-Index-CMI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Code-Mixing-Index-CMI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Code-switching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Code-switching/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Color-Indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Color-Indexing/</guid><description>Author(s): [[Michael J. Swain]], [[Dana H. Ballard]] Tags: #Computer_Vision, #academic_papers Read on: [[September 25th, 2020]] URL: http://www.inf.ed.ac.uk/teaching/courses/av/LECTURE_NOTES/swainballard91.pdf
Main Contribution(s) Proposes [[Histogram Intersection]], [[Histogram Backprojection]] to develop visual skills for robots Summary [[Histogram Intersection]] $$\sum\limits_{j=1}^{n} min(I_j, M_j)$$ where I and M are a pair of histograms containing n bins Able to deal with: 1.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Comparison-of-CMAC-Architectures-for-Neural-Network-Based-Control/</guid><description>Author(s): [[L.G. Kraft]] Tags: #academic_papers, #Cerebellar_Model_Articulation_Controller_(CMAC) Read on: [[November 2nd, 2020]] URL: https://ieeexplore.ieee.org/document/203399
Main Contribution(s) Compares 2 architectures using the [CMAC]([[Cerebellar Model Articulation Controller (CMAC)]]) neural network Summary First method learns the inverse model of the system being controlled The second method uses the system tracking error to adjust network weights The error driven control structures seemed to provide better tracking performance based on the rms tracking error The network weights are modified according to $$m_{ij}(k+1) = m_{ij}(k) + B*[u(k)-m_{ij}(k)]$$ Learning Gaps/Thoughts Cant seem to find explanations about the direct inverse method Simplify/Analogies</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Comparison-of-Convergence-Properties-of-CMAC-Neural-Network-and-Traditional-Adaptive-Controllers/</guid><description>Author(s): [[L.G. Kraft]], [[David P. Campagna]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 2nd, 2020]] URL: https://ieeexplore.ieee.org/document/70450
Main Contribution(s) Compares the the [[Self-Tuning Regulator]], [[Lyapunov Model Reference (MRAC)]], and the [[Cerebellar Model Articulation Controller (CMAC)]] [[Neural Network]] method.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Complexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Complexity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Compositional-rule-of-inference-as-an-analogical-scheme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Compositional-rule-of-inference-as-an-analogical-scheme/</guid><description>Author(s): [[Bernadette Bouchon-Meunier]], [[Radko Mesiar]], [[Christophe Marsala]], [[Maria Rifqi]] Tags: #Fuzzy_Logic, #Reasoning, #academic_papers Read on: [[September 23rd, 2020]] URL: https://www.sciencedirect.com/science/article/abs/pii/S0165011402005675</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Compositional-Rule-of-Inference/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Compositional-Rule-of-Inference/</guid><description>Proposed by [[Lotfi Asker Zadeh]] in [[The Concept of a Linguistic Variable and its Application to Approximate Reasoning]], extended to many schemes.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Computational-Intelligence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Computational-Intelligence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Computer-Vision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Computer-Vision/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Concept-Error-Rates/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Concept-Error-Rates/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Condition-Number/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Condition-Number/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Conditional-Language-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Conditional-Language-Modelling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Conditional-Masked-prediction-with-Mixed-Attention-coMMA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Conditional-Masked-prediction-with-Mixed-Attention-coMMA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Conditional-Random-Fields/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Conditional-Random-Fields/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Confusion-Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Confusion-Matrix/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Connected-Component/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Connected-Component/</guid><description>![[Pasted image 20201203012520.png]]a subgraph that has at least one path between any pair of nodes; and the nodes in that component are not adjacent to any vertices in V</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Connectionist-Temporal-Classification-CTC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Connectionist-Temporal-Classification-CTC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Consistency-in-a-System-of-Equations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Consistency-in-a-System-of-Equations/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Context-Aware-Cross-Attention-for-Non-Autoregressive-Translation/</guid><description>Author(s): [[Liang Ding]], [[Longyue Wang]], [[Di Wu]], [[Dacheng Tao]], [[Zhaopeng Tu]] Tags: #Neural_Machine_Translation, #Non-Autoregressive, #academic_papers Read on: [[November 26th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Contextual-BERT-Conditioning-the-Language-Model-Using-a-Global-State/</guid><description>Author(s): [[Timo I. Denk]], [[Ana Peleteiro Ramallo]] Tags: #language_model, #BERT, #academic_papers Read on: [[December 2nd 2020]] URL: https://arxiv.org/abs/2010.15778
Main Contribution(s) Conditions [[BERT]] using a global state using a context vector Summary Typically [[BERT]] uses the [CLS] token which is assumed to aggregate global knowledge.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Contrast-Stretching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Contrast-Stretching/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Contribution-in-Information-Flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Contribution-in-Information-Flow/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Conversational-Dialogue-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Conversational-Dialogue-Systems/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Conversational-Intelligence-Challenge-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Conversational-Intelligence-Challenge-2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Convolution-Neural-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Convolution-Neural-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Convolutional-Neural-Networks-on-Graphs-with-Fast-Localized-Spectral-Filtering/</guid><description>Author(s): [[Michaël Defferrard]], [[Xavier Bresson]], [[Pierre Vandergheynst]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 15th 2020]] URL: https://arxiv.org/abs/1606.09375
Main Contribution(s) Provides a formulation of [[Convolution Neural Network]]s for [[Graph Neural Networks|GNN]] using [[Spectral Graph Theory]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Convolutional-Recurrent-Neural-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Convolutional-Recurrent-Neural-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CoQA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CoQA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Coreference/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Coreference/</guid><description>[[Document Graph for Neural Machine Translation]] Used to refer back to someone. add a edge if a word is a referent of another word.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Cornell-Movie/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cornell-Movie/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/cosine-similarity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/cosine-similarity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Counterfactual/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Counterfactual/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Counterfactuals-Critical-MultiAgent-Learning-CMAL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Counterfactuals-Critical-MultiAgent-Learning-CMAL/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Covid19-politifact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Covid19-politifact/</guid><description> Constructed by [[Misinformation has High Perplexity]] Contains non-scientific and political claims. For example, &amp;ldquo;For the coronavirus, the death rate in Texas, per capita of 29 million people, we’re one of the lowest in the country&amp;rdquo; These facts have the potential to bring about negative sociopolitical effects</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Covid19-scientific/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Covid19-scientific/</guid><description>Constructed by [[Misinformation has High Perplexity]] Myths and scientific truths are collected from reliable souurces like MedicalNewsToday, Centers for Disease Control and Prevention, World Health Organization For example, &amp;ldquo;drinking a bleach solution will prevent you from getting the COVID-19.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Covid19/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Covid19/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-SCENE-CLASSIFICATION-AND-DOMESTIC-AUDIO-TAGGING/</guid><description>Author(s): [[Thomas Lidy]], [[Alexander Schindler]] Tags: #academic_papers, #audio_tagging, Read on: [[April 27th 2021]] URL: https://www.semanticscholar.org/paper/CQT-BASED-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-AUDIO-Lidy/5214463663294fcf68668791a0e5c14b74dcab9f
Main Contribution(s) Finds that a [[Constant-Q-transform]] input improves results over [[Mel Spectrograms]] in [[Audio Tagging]] for urban sounds.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Criticality-in-Representation-Generalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Criticality-in-Representation-Generalization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/critique/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/critique/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CRNNS-FOR-URBAN-SOUND-TAGGING-WITH-SPATIOTEMPORAL-CONTEXT/</guid><description>Author(s): [[Augustin Arnault]], [[Nicolas Riche]] Tags: #academic_papers, #dcase2020_task5, #audio_tagging Read on: [[April 27th 2021]] URL: https://arxiv.org/abs/2008.10413
Main Contribution(s) Uses a [[Convolution Neural Network|CNN]] + [[Recurrent Neural Networks|RNNs]] like layers for urban sound tagging</description></item><item><title/><link>https://aibrain.dhecloud.xyz/cross-entropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/cross-entropy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/cross-validation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/cross-validation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/cross-attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/cross-attention/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Cross-Domain-Loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Cross-Domain-Loss/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Crowding-Problem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Crowding-Problem/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Curriculum-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Curriculum-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Curse-of-Dimensionality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Curse-of-Dimensionality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Linear-Algebra-for-Computing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Linear-Algebra-for-Computing/</guid><description>[[CZ1104 Lecture 6.1]] [[CZ1104 Lecture 6.2]] [[CZ1104 Lecture 6.3]] [[CZ1104 Lecture 7.1]] [[CZ1104 Lecture 7.2]] [[CZ1104 Lecture 8.1]] [[CZ1104 Lecture 8.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.1/</guid><description> [[Euclidean Distance]] of a vector is defined as $$\lVert v \rVert = \sqrt{v_1^2 + v_2^2 + &amp;hellip; + v_n^2}$$ if v is a vector in $$R^n$$ and if $$k$$ is any scalar, then $$\lVert v \rVert \geq 0$$ $$\lVert v \rVert = 0$$ __if and only if __ $$v = 0$$ $$\lVert kv \rVert = |k|\lVert v \rVert$$ A vector with [[Euclidean Distance]] of 1 is an [[Unit Vector]] To normalize a vector, we multiply a nonzero vector by the reciprocal of its length $$u = \frac{1}{\lVert v \rVert}v$$ To prove $$\lVert u \lVert = 1$$, simply show $$\lVert u \lVert^2 = 1$$ To find the distance between $$u$$ and $$v$$, it is the length aka [[Euclidean Distance]] between the two vectors $$\lVert u-v \lVert $$ [[Dot Product]] $$u \cdot v= \lVert u \rVert \lVert v \rVert \cos(\theta)$$ $$u \cdot v= u_1v_1 + u_2v_2 + &amp;hellip; + u_nv_n$$ (simplified) if $$u=v, \lVert v \lVert = \sqrt{v\cdot v}$$ Intuition: Tells you what amount of one vector goes in the direction of another When both vectors point in same general direction, dot product is positive When both vectors are pointing away from each other, dot product is negative When both vectors are perpendicular, dot product is 0 Properties of the Dot Product Symmetry: $$u \cdot v = v \cdot u$$ Distributive: $$u \cdot (v + w) = u \cdot v + u \cdot w$$ Homogeneity: $$k(u \cdot v) = (ku) \cdot v$$ Positivity: $$v \cdot v \geq 0$$ and $$v \cdot v = 0$$ if and only if $$v = 0 $$ $$Au \cdot v = u \cdot A^T v$$ and $$u \cdot Av = A^T u \cdot v$$ where $$A$$ is an $$n \times n$$ matrix and $$u, v$$ are $$n \times 1$$ matrices [[Cauchy-Schwarz Inequality]] if $$u$$ and $$v$$ are vectors in $$R^n$$, then $$|u \cdot v| \leq \lVert u \rVert \lVert v \rVert $$ Triangle inequality for vectors(left) and distances(right) if $$u$$ and $$v$$ are vectors in $$R^n$$, then $$\lVert u + v \rVert^2 + \lVert u - v \rVert^2 = 2(\lVert u \rVert^2+ \lVert v \rVert^2)$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.2/</guid><description>Two non zero vectors $$u$$ and $$v$$ are said to exhibit [[Orthogonality]] or to be perpendicular if $$u \cdot v =0$$ By this definition, the zero vector in $$R^n$$ is [[Orthogonality|orthogonal]] to every vector in $$R^n$$ $$\theta = \pi/2$$ if and only if $$u \cdot v = 0$$ [[Point Normal Equations]] line: $$a(x - x_0) + b(y-y_0)=0$$ if $$a$$ and $$b$$ are constants that are not both zero, then $$ax + by + c = 0$$ plane: $$a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$$ if $$a$$, $$b$$ and $$c$$ are constants that are not all zero, then $$ax + by + cz +d = 0$$ [[Standard Basis]] for $$R^n$$ Basically a one hot vector with only one &amp;lsquo;1&amp;rsquo; in each dimension [[Orthogonality|Orthogonal]] Projections if $$u$$ and $$a$$ are vectors in $$R^n$$, and if $$a \neq 0$$, then $$u$$ can be expressed in exactly one way in the form $$u = w_1 + w_2$$, where $$w_1$$ is a scalar multiple of $$a$$ and $$w_2$$ is [[Orthogonality|orthogonal]] to $$a$$ $$w_1 = proj_au = \frac{u \cdot a}{\lVert a \rVert^2} a$$ $$w_2 = u - proj_au = u- \frac{u \cdot a}{\lVert a \rVert^2} a$$ $$\lVert proj_au \rVert = \frac{|u \cdot a|}{\lVert a \rVert} = \lVert u \rVert |\cos \theta|$$ [[Pythagoras Theorem]] in $$R^n$$ If $$u$$ and $$v$$ are [[Orthogonality|orthogonal]] vectors in $$R^n$$ with the Euclidean inner product, then $$\lVert u + v \rVert^2 = \lVert u \rVert^2 + \lVert v \rVert^2$$ [[Orthogonality|Orthogonal]] Sets and [[Orthogonal Basis]] If $$S = {u_1, &amp;hellip; u_p}$$ is an [[Orthogonality|orthogonal]] set of nonzero vectors in $$R^n$$, then $$S$$ is linearly independent and hence is a basis for the subspace spanned by $$S$$ An [[Orthogonal Basis]] for a subspace $$W$$ of $$R^n$$ is a basis for $$W$$ that is also an [[Orthogonality|orthogonal]] set The weights in the linear combination $$y = c_1u_1 + &amp;hellip; + c_pu_p$$, where $${u_1, &amp;hellip;, u_p}$$ is an [[Orthogonal Basis]], can be easily found by $$c_j = \frac{y \cdot u_j}{u_j \cdot u_j}$$ An [[Orthonormal]] set is an [[Orthogonality|orthogonal]] set of unit vectors.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-6.3/</guid><description>[[Span]] $$Span{v_1, &amp;hellip; , v_p}$$ is the collection of all vectors that can be expressed in a linear combination [[Gram Schmidt]] from lay&amp;rsquo;s textbook To get the [[QR Factorization]], need to divide $$v_p$$ by its length from ucla.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-7.1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-7.1/</guid><description> [[Consistency in a System of Equations]] 3 possible cases: $$M \gg N$$ $$M \approx N$$ $$M \ll N$$ [[Least Squares Solution for Inconsistent Equations]] If $$A$$ is $$m \times n$$ and $$b$$ is in $$R^m$$, a least-squares solution of $$Ax = b$$ is an $$\hat{x}$$ in $$R^n$$ such that $$\lVert b - A\hat{x} \rVert \leq \lVert b - A \rVert$$ for all $$x$$ in $$R^n$$ [[Normal Equation] The set of least-squares solutions of $$Ax = b$$ coincides with the nonempty set of solutions of the normal equations $$A^TAx = A^Tb$$ Proven by the [[Orthogonal Decomposition Thereom]] [[Projection Matrix]] $$P = A(A^TA)^{-1}A^T$$ Properties: $$P^T = P$$ $$P^N = P$$ (Idempotent Property)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-7.2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-7.2/</guid><description> [[Binary Matrix Operations]] Commutative law of addition: $$[A] + [B] = [B] + [A]$$ if the sizes are the same Associative law of addition: $$[A] + ([B]+[C]) = ([A] + [B]) + [C]$$ if the sizes are the same Associative law of multiplication: $$ A = ([A][B])[C]$$ Distributive law: ([A]+[B])[C] = [A][C] + [B][C] $$AB \neq BA$$ in general [[Invertibility]] Only for square matrices $$AA^{-1} = I = A^{-1}A$$ $$det(A) \neq 0$$ $$A$$ is non-singular $$A$$ is invertible $$(A^{-1})^{-1} =A$$ if A is a square matrix $$(AB)^{-1} = B^{-1}A^{-1}$$ $$(A^{-1})^T = (A^T)^{-1}$$ Inverse is not distributive over addition $$(A+B)^{-1} \neq A^{-1} + B^{-1}$$ For [[Orthogonality|orthogonal]] matrix, $$A^{-1} = A^T$$ [[Trace]] of a matrix Sum of diagonal entries of A [[Determinant]] of a Matrix $$det(A) = $$ when A is singular (non-invertible) ie has dependent rows/columns $$det(AB) = det(A) \times det(B)$$ $$det(A^{-1}) = \frac{1}{det(A)}$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.1/</guid><description>An [[Eigenvector]] of an $$n \times n$$ matrix $$A$$ is a non zero vector $$x$$ such that $$Ax=\lambda x$$ for some scalar $$\lambda$$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.2/</guid><description>[[Symmetric]] matrices
$$A = A^T$$ Always [[Orthogonality|orthogonally]] [[Diagonalisable]] [[Spectral Theorem]]: An $n \times n$ [[Symmetric]] matrix $A$ has the following properties:</description></item><item><title/><link>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/CZ1104-Lecture-8.4/</guid><description>[[Singular Value Decomposition]]: For an $$m \times n$$ matrix for which the diagonal entries are the first $$r$$ singular values of A, there exists an $$m \times m$$ [[Orthogonality|orthogonal]] matrix $$U$$ and an $$n \times n$$ [[Orthogonality|orthogonal]] matrix $$V$$ such that $$A = U\Sigma V^T$$ columns of $$U$$ are the left singular values of $$A$$ columns of $$V$$ are the right singular vectors of A [[Matrix Approximation]] The optimal rank $$r$$ approximation, in a least squares sense, is given by the rank r SVD truncation $$\hat{X}$$: Given a matrix $$A ∈ R^{m \times n}$$ Number of linearly independent rows = Row Rank Number of linearly indepdent columns = Column rank Row rank = Column rank = Rank of Matrix $$A$$ Rank(A) = Number of non-zero singular values of A Rank(A) = Rank($$A^T$$) Matrix $$A$$ has full rank if its rank equals the largest possible matrix of the same dimensions, which is the lesser of the number of rows and columns.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/d1dbe2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/d1dbe2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Da-Ju/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Da-Ju/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dacheng-Tao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dacheng-Tao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DailyDialog-A-Manually-Labelled-Multi-turn-Dialogue-Dataset/</guid><description>Author(s): [[Yanran Li]], [[Hui Su]], [[Xiaoyu Shen]], [[Wenjie Li]], [[Ziqiang Cao]], [[Shuzi Niu]] Tags: #Conversational_Dialogue_Systems, #datasets, #academic_papers Read on: [[July 16th, 2020]] URL: http://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/DailyDialog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DailyDialog/</guid><description> According to [[Probing Neural Dialog Models for Conversational Understanding]] 14K train, 1K validation, 1K test multi-turn dialogs collected from an English Learning Website Higher Quality than datasets from Twitter or Reddit</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Dan-Klein/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dan-Klein/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dana-H.-Ballard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dana-H.-Ballard/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Daniel-Adiwardana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Daniel-Adiwardana/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Daniel-M.-Ziegler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Daniel-M.-Ziegler/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dario-Amodei/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dario-Amodei/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DATA-AUGMENTATION-BASED-SYSTEM-FOR-URBAN-SOUND-TAGGING/</guid><description>Author(s): [[Jisheng Bai]], [[Chen Chen]], [[Mou Wang]], [[Jiangfeng Chen]], [[Xiaolei Zhang]], [[Qingli Yan]] Tags: #academic_papers, #audio_tagging Read on: [[April 27th 2021]] URL: http://dcase.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/datasets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/datasets/</guid><description> Taken from [[(SPOLIN) Grounding Conversations with Improvised Dialogues]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/David-Luan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/David-Luan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/David-P.-Campagna/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/David-P.-Campagna/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/David-R.-So/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/David-R.-So/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dawn-Song/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dawn-Song/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dayiheng-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dayiheng-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/De-Morgans-Law/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/De-Morgans-Law/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/December-1st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/December-1st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Decision-Trees/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Decision-Trees/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Decoding-and-Diversity-in-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Decoding-and-Diversity-in-Machine-Translation/</guid><description>Author(s): [[Nicholas Roberts]], [[David Liang]], [[Graham Neubig]], [[Zachary C. Lipton]] Tags: #academic_papers, #Neural_Machine_Translation Read on: [[January 7th 2021]] URL: https://arxiv.org/abs/2011.13477</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Decoding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Decoding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Deconvolution-Transposed-Convolution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deconvolution-Transposed-Convolution/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Causal-Manipulation-Augmented-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Causal-Manipulation-Augmented-Model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Fakes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Fakes/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Feature-Embedding-and-Hierarchical-Classification-for-Audio-Scene-Classificatio/</guid><description>Author(s): [[Lam Pham]], [[Ian McLoughlin]], [[Huy Phan]], [[R. Palaniappan]], [[Alfred Mertins]] Tags: #academic_papers, #audio_tagging Read on: [[31-May-2021]] URL: https://www.researchgate.net/publication/339228084_Deep_Feature_Embedding_and_Hierarchical_Classification_for_Audio_Scene_Classification
Main Contribution(s) Problem: Audio is often complicated by presence of foreground sounds and interfereing noise Solution: Deep feature embedding learning and a hierarchical classification scheme</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-Frameworks-Applied-For-Audio-Visual-Scene-Classification/</guid><description>Author(s): [[Lam Pham]], [[Alexander Schindler]], [[Mina Schutz]], [[Jasmin Pielorz]], [[Sven Schlarb]], [[Ross King]] Tags: #academic_papers, #audio_visual Read on: [[01-Jun-2021]] URL: cant find</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-on-Graphs-book/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-on-Graphs-book/</guid><description>Author(s): [[Yao Ma]], [[Jiliang Tang]] Tags: #book Start-End date: [[December 1st 2020]] -
[[Deep Learning On Graphs Chapter 1 - Introduction]] [[Deep Learning On Graphs Chapter 2 - Foundations of Graphs]] [[Deep Learning On Graphs Chapter 3 - Foundations of Deep Learning]] [[Deep Learning On Graphs Chapter 4 - Graph Embedding]] [[Deep Learning On Graphs Chapter 5 - Graph Neural Networks]] [[Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks]] [[Deep Learning On Graphs Chapter 7 - Scalable Graph Neural Networks]] [[Deep Learning On Graphs Chapter 8 - Graph Neural Networks on Complex Graphs]] [[Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs]] [[Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-1-Introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-1-Introduction/</guid><description>Introduction Reasons to learn [[Deep Learning on Graphs]]: Many datasets can be representated explicitly as a graph A vast number of real world problems can be addressed as a small set of computation tasks on graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-10-Graph-Neural-Networks-in-Natural-Language-Processing/</guid><description>[[Graph Neural Networks|GNN]] has been used to enchane many NLP tasks such as [[Semantic Role Labeling]], [[Question Answering]], [[Relation Extraction]], [[Neural Machine Translation]], [[Graph to Sequence]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-2-Foundations-of-Graphs/</guid><description>Foundations of Graphs Graph Representations [[Simple Graph]] [[Adjacency Matrix]] [[Degree]] [[Neighbors]]
Connectivity [[Walk]]
[[Trail]] [[Path]] For a graph with [[Adjacency Matrix]] $A$, $A^n$ is used to denote the n-th power of the adjacency matrix.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-3-Foundations-of-Deep-Learning/</guid><description>skipped this chapter</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-4-Graph-Embedding/</guid><description>[[Graph Embbedding]] aims to map each node in a given graph to a low dimensional vector representation. There are two perspectives to viewing the graph: the original node-edge graph structure, and the embedding domain where each node is a continuous vector.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-5-Graph-Neural-Networks/</guid><description>Introduction Classical [[Neural Network]]s cannot be easily generalized to graph-structured graph as the graph structure is not a regular grid. Essentially, [[Graph Neural Networks]] are a form of [[Representation learning]] on graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-6-Robust-Graph-Neural-Networks/</guid><description>[[Graph Neural Networks]] inherit both advantages and disadvantages of traditional [[Neural Network]]s.
[[adversarial attacks]] fall into several attack types:
[[Evasion Attack]] [[Poisoning Attack]] These attacks can be done by: Modifying Node Features Adding or deleting edges Injecting fake nodes Attackers aim to either:</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-7-Scalable-Graph-Neural-Networks/</guid><description>[[Graph Neural Networks]] suffers from severe scalability issue. [[Stochastic Gradient Descent]] is not as straightforward as training samples are still conneted to other labeled/unlabeled samples in the graph.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-8-Graph-Neural-Networks-on-Complex-Graphs/</guid><description>skimmed through most of it.
[[Meta-Path Schema]] is used to split [[Heterogeneous Graphs]] into several [[Homogeneous]] [[Simple Graph]]. [[Graph Filter]]s are applied to these split graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Deep-Learning-On-Graphs-Chapter-9-Beyond-GNNs-More-Deep-Models-on-Graphs/</guid><description>[[Auto-Encoders]] have been extended to graph structured data for node [[Representation learning]]. There are two types of [[Graph Auto-Encoders]] for learning low dimensional node reprsentations.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/DeepWalk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DeepWalk/</guid><description>This algorithm was presented in 2014 and is an well-established algorithm for [[Graph Neural Networks]]. It consists of a mapping function, extractor, reconstructor, and objective.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Defining-and-Evaluating-Fair-Natural-Language-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Defining-and-Evaluating-Fair-Natural-Language-Generation/</guid><description>Author(s): [[Catherine Yeo]], [[Alyssa Chen]] Tags: #Fair_AI, #academic_papers Read on: [[August 11th, 2020]] URL: http://arxiv.org/abs/2008.01548
Main Contribution(s) Introduce a framework of fairness for NLG followed by an evaluation of gender biases in [[GPT-2]] and [[XLNet]] Summary Posits that a fair language generation system should output similar results given similar individual inputs !</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Degree-Centrality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Degree-Centrality/</guid><description>calculated based on how many nodes are connected to it. It is defined as $$c_d(v_i) = d(v_i) = \sum_{j=1}^N A_{i,j}$$ However it treats all neighbours equally.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Degree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Degree/</guid><description>of a node is the number of nodes that are adjacent to $v_i$ $$d(v_i) = \sum_{v_j \in V}{1_E({v_i,v_j})}$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Dependency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dependency/</guid><description>[[Document Graph for Neural Machine Translation]] Given a dependency tree of the sentence and a word $x_i^m$, we add a graph edge $(x_i^m,x_j^m)$ if $x_i^m$ word is a headword of $x_j^m$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Depth-of-Field/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Depth-of-Field/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Depth-First-Search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Depth-First-Search/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Description-Embodied-Knowledge-Representation-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Description-Embodied-Knowledge-Representation-Learning/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] Uses [[TransE]] to learn a structure-based representation. A description-based representation is also learnt using additional information via [[Convolution Neural Network]]s.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Determinant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Determinant/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Detlef-Nauck/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Detlef-Nauck/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Di-Wu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Di-Wu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Diagonalisable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Diagonalisable/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dialog-State-Tracking-Challenge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dialog-State-Tracking-Challenge/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DialogGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DialogGPT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DialoGPT-Large-Scale-Generative-Pre-training-for-Conversational-Response-Generation/</guid><description>Author(s): [[Yizhe Zhang]], [[Siqi Sun]], [[Michel Galley]], [[Yen-Chun Chen]], [[Chris Brockett]], [[Xiang Gao]], [[Jianfeng Gao]], [[Jingjing Liu]], [[Bill Dolan]] Tags: #language_model, #Dialogue_Modelling, #transformer, #Conversational_Dialogue_Systems, #academic_papers Read on: [[July 18th, 2020]] URL: http://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/DialoGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DialoGPT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dialogue-Act/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dialogue-Act/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dialogue-breakdown-detection-using-BERT-with-traditional-dialogue-features/</guid><description>Author(s): [[Hiroaki Sugiyama]] Tags: #Conversational_Dialogue_Systems, #BERT, #academic_papers Read on: [[June 20th, 2020]] URL: http://workshop.colips.org/wochat/@iwsds2019/documents/dbdc4-hiroaki-sugiyama.pdf
Main Contribution(s) Use BERT with traditional dialogue features to predict breakdown detection in [DBDC4]([[The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics]]) Summary Other than using the [CLS] token, they also used the word vectors along with 2 separate BERT models - a dialogue act estimator and a dialogue act predictor BERT almost with other features worked the best Learning Gaps None, but i am very curious if the training was done properly.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Dialogue-Efficiency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dialogue-Efficiency/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dialogue-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dialogue-Modelling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DialogueNLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DialogueNLI/</guid><description> (Welleck et al., 2018) Dialogue entailment/contradiction/unrelated</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Diameter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Diameter/</guid><description>of a [[Connected Graph]] is defined as $$diameter(G) = \max_{v_s,v_t\in V}\min_{p\in P_st}|p|$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/diffpool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/diffpool/</guid><description>uses the [[GCN-Filter]] followed by a [[Softmax]] to determine the nodes to keep.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Discovering-and-Categorizing-Language-Biases-in-Reddit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Discovering-and-Categorizing-Language-Biases-in-Reddit/</guid><description>Author(s): Tags: #critique, #academic_papers, #bias Read on: [[August 12th, 2020]] URL: http://arxiv.org/abs/2008.02754
Main Contribution(s) Uses static embeddings like [[word2vec]] to discover language biases in subreddits Summary Identify and categorize gender bias in r/TheRedPill, r/dating_advice, religion biases in r/atheism, and ethnicity biases in r/The_Donald skip-gram model of 200 dimensions is trained, then clustered using [[K-means clustering]] The clusters are assigned labels which are either positive or negative Most female-biased words are more frequently used than male-biased words Bias distribution is weaker than r/TheRedPill.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Discrete-Dynamic-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Discrete-Dynamic-Graphs/</guid><description>an extension of [[Dynamic Graphs]] but instead contains snapshots of each observations when it is not possible to record the emerging timestamp.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Discriminant-Component-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Discriminant-Component-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DistilBERT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DistilBERT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Distributive-Law/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Distributive-Law/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Do-sound-event-representations-generalize-to-other-audio-tasks-A-case-study-in-audio-transfer-learning/</guid><description>Author(s): [[Anurag Kumar]], [[Yun Wang]], [[Vamsi Krishna Ithapu]], [[Christian Fuegen]] Tags: #academic_papers Read on: [[15-Jul-2021]] URL: arxv
Main Contribution(s) Problem: Examine transfer learning on audio Solution: -</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Do-Syntax-Trees-Help-Pre-trained-Transformers-Extract-Information/</guid><description>Author(s): [[Devendra Singh Sachan]], [[Yuhao Zhang]], [[Peng Qi]], [[William Hamilton]] Tags: #academic_papers, #BERT, #Graph_Neural_Networks, Read on: [[January 5th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Do-Transformers-Need-Deep-Long-Range-Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Do-Transformers-Need-Deep-Long-Range-Memory/</guid><description>Author(s): [[Jack W. Rae]], [[Ali Razavi]] Tags: #transformer, #language_model, #academic_papers Read on: [[July 31st, 2020]] URL: http://arxiv.org/abs/2007.03356
Main Contribution(s) Show that long range memory is not needed at every layer of the [[Transformer-XL]], only in later layers Show that layer position of long range memory matters Summary Replace long range memory of $$d = 1024$$ with short-range memory $$d = 128$$ The number of model parameters is independent of the memory size, so number of parameters remains the same There are three ways the LRMs are changed: Interleaved with equal spacing First layer of the network Latter layer(s) Results Model with 12 long range memory at the lower layers of the network is worse than a model with a single long range memory Position of long range memory matters Better not to place long range memory in shallow layers Learning Gaps Need a refresher on [[Transformer-XL]] Simplify/Analogies Long range memory is not needed in earlier layers, but is required in the later stages</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Document-Graph-for-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Document-Graph-for-Neural-Machine-Translation/</guid><description>Author(s): [[Mingzhou Xu]], [[Liangyou Li]], [[Derek F. Wong]], [[Qun Liu]], [[Lidia S. Chao]] Tags: #academic_papers, #Neural_Machine_Translation Read on: [[December 12th 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Dorin-Comaniciu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dorin-Comaniciu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dot-Product/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dot-Product/</guid><description> Also known as Euclidean Inner Product</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Douwe-Kiela/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Douwe-Kiela/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dragan-Gasevic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dragan-Gasevic/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Drastic-T-norm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Drastic-T-norm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/DROP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/DROP/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Duet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Duet/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dynamic-Bayesian-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dynamic-Bayesian-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dynamic-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dynamic-Graphs/</guid><description>simply a graph with timestamps. There are two mapping functions which map each node and each edge to their emerging timestamps</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Dynamic-Programming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dynamic-Programming/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Dynamic-Time-Warping-DTW/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Dynamic-Time-Warping-DTW/</guid><description>$$\text{dis}(a,b) = \frac{\max(a,b)}{\min(a,b)} -1$$ Finds the optimal alginment between two sequences such that the sum of the distance between the algined elements is minimized.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/e4e9ec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/e4e9ec/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/e4e9ee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/e4e9ee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/e5e9f2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/e5e9f2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/e7eff3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/e7eff3/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/e9ebef/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/e9ebef/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ec6f35/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ec6f35/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ECC-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ECC-Filter/</guid><description>When there is enough edge information and the number of edge types is finite, this filter is designed.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ece-Kamar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ece-Kamar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ed5845/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ed5845/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Edge-Flow-Propagation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Edge-Flow-Propagation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Edge-based-Sampler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Edge-based-Sampler/</guid><description>A [[Subgraph-wise Sampling]] method which randomly samples according to a following distribution given budget $m$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Edmun-M-K-Lai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Edmun-M-K-Lai/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eduard-Hovy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eduard-Hovy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/eee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/eee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Effective-Receptive-Field/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Effective-Receptive-Field/</guid><description>[[Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks]] Calculated by backpropagating a gradient signal from the output of the second last layer to the input.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/EFFECTS-OF-WORD-FREQUENCY-BASED-PRE-AND-POST-PROCESSINGS-FOR-AUDIO-CAPTIONING/</guid><description>Author(s): [[Daiki Takeuchi]], [[Yuma Koizumi]], [[Yasunori Ohishi]], [[Noboru Harada]], [[Kunio Kashino]] Tags: #academic_papers, #Automated_Audio_Captioning, #dcase2020_task6 Read on: [[May 11th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Efficient-Inference-For-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Efficient-Inference-For-Neural-Machine-Translation/</guid><description>Author(s): [[Yi-Te Hsu]], [[Sarthak Garg]], [[Yi-Hsiu Liao]], [[Ilya Chatsviorkin]]
Tags: #academic_papers Read on: [[December 3rd 2020]] URL: https://arxiv.org/abs/2010.02416
Main Contribution(s) Proproses a deep encoder and shallow decoder architecture which can achieve up to 109% and 84% speedup on CPU and GPU respectively and reduce the number of parameters by 25% while maintaining the same translation quality in terms of [[BLEU]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Eigen-Space/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eigen-Space/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eigendecomposition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eigendecomposition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/EigenPooling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/EigenPooling/</guid><description>uses spectral clustering methods and gets non-overlapping clusters, which are the supernodes. The graph structure is created using the intra-cluster and inter-cluster [[Adjacency Matrix]] for the input graph.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Eigenvalue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eigenvalue/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eigenvector-Centrality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eigenvector-Centrality/</guid><description>calculates the centrality scores by getting the largest [[Eigenvalue]] and [[Eigenvector]]. Specifically, $$\lambda \cdot c_e = A \cdot c_e$$ where $c_e$ is an eigenvector of the [[Adjacency Matrix]] $A$ with its corresponding eigenvalue $\lambda$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Eigenvector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eigenvector/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Elias-Bareinboim/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Elias-Bareinboim/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/EMB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/EMB/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/embed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/embed/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Embeddings/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Emily-Dinan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Emily-Dinan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Emmett-Witchel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Emmett-Witchel/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Empathetic-Dialogues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Empathetic-Dialogues/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Empirical-Risk-Minimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Empirical-Risk-Minimization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Emre-Kiciman/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Emre-Kiciman/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eneko-Agirre/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eneko-Agirre/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Energy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Energy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Enhong-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Enhong-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Enron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Enron/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Entity-Grid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Entity-Grid/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Entity-GCN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Entity-GCN/</guid><description>[[Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing]] Mentions of entities are identified from the supporting document, and each mention becomes a node.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Entropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Entropy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Environmental-Sound-Classification-with-Parallel-Temporal-spectral-Attention/</guid><description>Author(s): [[Helin Wang]], [[Yuexian Zou]], [[Dading Chong]], [[Wenwu Wang]] Tags: #academic_papers, #audio_tagging Read on: [[May 11th 2021]] URL: https://arxiv.org/abs/1912.06808
Main Contribution(s) Problem: Importance of different frequency bands is not considered when training Solution: Use both Temporal and Spectral attention</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Equivariant-Functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Equivariant-Functions/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] ![[Pasted image 20201215224148.png]] Preserves [[Permutation Invariant]] in [[Graph Neural Networks]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Equivariant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Equivariant/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Erd%C5%91s-R%C3%A9nyi-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Erd%C5%91s-R%C3%A9nyi-model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Erfan-Loweimi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Erfan-Loweimi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eric-Michael-Smith/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eric-Michael-Smith/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Eric-Sigler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Eric-Sigler/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ESIM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ESIM/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Euclidean-Distance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Euclidean-Distance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Europarl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Europarl/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/eval-2000-SWBD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/eval-2000-SWBD/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Evaluating-dialogue-breakdown-detection-in-chat-oriented-dialogue-systems/</guid><description>Author(s): [[Yuiko Tsunomori]], [[Ryuichiro Higashinaka]], [[Tetsuro Takahashi]], [[Michimasa Inaba]] Tags: #academic_papers, #Conversational_Dialogue_Systems, #Evaluation_Metric Read on: [[June 21st, 2020]] URL: http://workshop.colips.org/wochat/</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Evaluation-Metric/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Evaluation-Metric/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Evasion-Attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Evasion-Attack/</guid><description>Model parameters of victim model cannot be changed</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Expectation-Mean/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Expectation-Mean/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Exploratory-Data-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Exploratory-Data-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/EXPLORING-MODALITY-AGNOSTIC-REPRESENTATIONS-FOR-MUSIC-CLASSIFICATION/</guid><description>Author(s): [[Ho-Hsiang Wu]], [[Magdalena Fuentes]], [[Juan P. Bello]] Tags: #academic_papers, #audio_tagging, Read on: [[08-Jun-2021]] URL: [2106.01149] Exploring modality-agnostic representations for music classification (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/exposure-bias/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/exposure-bias/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/F-scores/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/F-scores/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/f3f6f7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/f3f6f7/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/f7f8f8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/f7f8f8/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/f7f8fa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/f7f8fa/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/f7f9fb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/f7f9fb/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Face-Recognition-Using-Eigenfaces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Face-Recognition-Using-Eigenfaces/</guid><description>Author(s): [[Matthew A. Turk]], [[Alex P. Pentland]] Tags: #Face_Recognition, #Computer_Vision, #academic_papers Read on: [[September 25th, 2020]] URL: https://ieeexplore.ieee.org/document/139758
Main Contribution(s) Use [[Eigenvector]]s of face images to perform classification Summary Decompose the training set into its set of [[Eigenvalue]]s which are termed eigenfaces here.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Face-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Face-Recognition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Facebook-AI-Research/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Facebook-AI-Research/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Facial-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Facial-Recognition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fair-AI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fair-AI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fairseq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fairseq/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Faithfulness/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Faithfulness/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fast-Gradient-Sign-Method/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fast-Gradient-Sign-Method/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Faster-R-CNN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Faster-R-CNN/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Faster-Transformer-Decoding-N-gram-Masked-Self-Attention/</guid><description>Author(s): [[Ciprian Chelba]], [[Mia Chen]], [[Ankur Bapna]], [[Noam Shazeer]] Tags: #Decoding, #Natural_Language_Generation, #academic_papers Read on: [[May 26th, 2020]] URL: https://arxiv.org/abs/2001.04589</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Features/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Features/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FED-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FED-dataset/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FED-metric/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FED-metric/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/fertilities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/fertilities/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FEVER/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FEVER/</guid><description> Fact Extraction and Verification (FEVER) (Thorne et al., 2018)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/ff4747/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ff4747/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ff474770/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ff474770/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ff6956/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ff6956/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ff913c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ff913c/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/fff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/fff/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Field-of-View/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Field-of-View/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Filter-Damping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Filter-Damping/</guid><description>[[Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks]] Applies an element-wise multiplication of the kernel with a constant matrix.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fine-Tuning-by-Curriculum-Learning-for-Non-Autoregressive-Neural-Machine-Translation/</guid><description>Author(s): [[Junliang Guo]], [[Xu Tan]], [[Linli Xu]], [[Tao Qin]], [[Enhong Chen]], [[Tie-Yan Liu]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 24th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Fishers-Discriminant-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fishers-Discriminant-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FLAMBE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FLAMBE/</guid><description> https://arxiv.org/abs/2006.10814</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Flat-Graph-Pooling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Flat-Graph-Pooling/</guid><description>Generate a single node and directly generates a graph-level representation from the node representation.
Some operations include [[Max Pooling]], [[Average Pooling]], similar to that from classical [[Neural Network]]s.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FlowSeq-Non-Autoregressive-Conditional-Sequence-Generation-with-Generative-Flow/</guid><description>Author(s): [[Xuezhe Ma]], [[Chunting Zhou]], [[Xian Li]], [[Graham Neubig]], [[Eduard Hovy]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 24th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/FlowSeq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FlowSeq/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fluency-ENhanced-Sentence-bert-Evaluation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fluency-ENhanced-Sentence-bert-Evaluation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FNet-Mixing-Tokens-with-Fourier-Transforms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FNet-Mixing-Tokens-with-Fourier-Transforms/</guid><description>Author(s): [[James Lee-Thorp]], [[Joshua Ainslie]], [[Ilya Eckstein]], [[Santiago Ontanon]] Tags: #academic_papers, #transformer Read on: [[01-Jun-2021]] URL: [2105.03824] FNet: Mixing Tokens with Fourier Transforms (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Four-Fundamental-Subspaces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Four-Fundamental-Subspaces/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Francisco-Herrera/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Francisco-Herrera/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Francisco-J.-Gonzalez-Serrano/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Francisco-J.-Gonzalez-Serrano/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/FROM-UNSUPERVISED-MACHINE-TRANSLATION-TO-ADVERSARIAL-TEXT-GENERATION/</guid><description>Author(s): [[Ahmad Rashid]], [[Alan Do-Omri]], [[Md. Akmal Haidar]], [[Qun Liu]], [[Mehdi Rezagholizadeh]] Tags: #Neural_Machine_Translation, #Generative_Adversarial_Network_(GAN), #academic_papers Read on: [[November 27th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Frontiers-in-Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Frontiers-in-Machine-Learning/</guid><description>The first virtual Frontiers in Machine Learning event took place from [[July 20th, 2020]] - [[July 23rd, 2020]]. This four-day virtual conference brought together academics, researchers, and PhD Students.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Deductive-Reasoning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Deductive-Reasoning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Logic-Controllers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Logic-Controllers/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Logic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Logic/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Perceptron/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Perceptron/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Rule-Based-Classification-System/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Rule-Based-Classification-System/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Set/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Set/</guid><description>A pair $$(U, m)$$ where $$U$$ is a set and $$m:U \rightarrow [0,1]$$ a membership function The value $$m(x)$$ is called the grade of membership of $$x$$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Fuzzy-Sets-1965/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Fuzzy-Sets-1965/</guid><description>Author(s): [[Lotfi Asker Zadeh]] Tags: #Fuzzy_Logic, #academic_papers Read on: [[September 29th, 2020]] URL: https://www.sciencedirect.com/science/article/pii/S001999586590241X
Main Contribution(s) Original paper that proposes [[Fuzzy Logic]] and formulates them Summary A [[Fuzzy Set]] $$A$$ in $$X$$ is characterized by a membership (characteristic) function which associates with each point in $$X$$ a real number in the interval [0,1], with the value of $$f_a(x)$$ at $$x$$ representing the grade of membership of $$x$$ in $$A$$ Definitions Complement $$f_{A^\prime} = 1 - f_A$$ Containment $$A \subset B \iff f_a \leq f_b $$ Union $$f_c(x) = Max [f_a(x), f_b(x)]$$ Intersection $$f_c(x) = Min [f_a(x), f_b(x)]$$ Convexity - A fuzzy set $$A$$ is convex if and only if the sets $$\Gamma _\alpha$$ defined by $$\Gamma _\alpha = {x | f_A(x) \geq \alpha}$$ are convex for all $$\alpha$$ in the interval (0,1) Boundedness.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GAN-Inversion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GAN-Inversion/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GAT-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GAT-Filter/</guid><description>Uses the [[self-attention]] mechanism, and the [[LeakyReLU]] as the nonlinear activation function.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Gated-Recurrent-Unit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gated-Recurrent-Unit/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gaurav-Nemade/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gaurav-Nemade/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GCN-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GCN-Filter/</guid><description>A simplified form of [[Cheby-Filter]] where $K=1$ (1-hop) and approximating $\lambda \approx 2$. $\lambda$ refers to the eignvalue of the [[Laplacian Matrix]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Generalized-Modus-Ponens/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generalized-Modus-Ponens/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/generalized-attention-mechanism/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/generalized-attention-mechanism/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Generalized-CMAC-GCMAC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generalized-CMAC-GCMAC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Generalizing-CMAC-Architecture-and-Training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generalizing-CMAC-Architecture-and-Training/</guid><description>Author(s): [[Francisco J. Gonzalez-Serrano]], [[Aníbal R. Figueiras-Vidal]] , [[Antonio Artés Rodríguez]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 2nd, 2020]] URL: https://ieeexplore.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Generative-Adversarial-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generative-Adversarial-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Generative-Flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generative-Flow/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Generative-Pretraining-from-Pixels/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Generative-Pretraining-from-Pixels/</guid><description>Author(s): [[Mark Chen]], [[Alec Radford]], [[Rewon Child]], [[Jeffrey Wu]], [[Heewoo Jun]], [[Prafulla Dhariwal]], [[David Luan]], [[Ilya Sutskever]] Tags: #Computer_Vision, #transformer, #academic_papers Read on: [[October 19th, 2020]] URL: https://cdn.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Geoffrey-Hinton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Geoffrey-Hinton/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Geometric-Multiplicity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Geometric-Multiplicity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/geometry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/geometry/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gerard-Goggin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gerard-Goggin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GGNN-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GGNN-Filter/</guid><description>Uses the [[Gated Recurrent Unit]] to work with graphs with directed edges and different edges type.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Girish-Sastry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Girish-Sastry/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Giuseppe-Riccardi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Giuseppe-Riccardi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Glancing-Transformer-GLAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Glancing-Transformer-GLAT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GLAT-Glancing-Transformer-for-Non-Autoregressive-Neural-Machine-Translation/</guid><description>Author(s): [[Lihua Qian]], [[Hao Zhou]], [[Yu Bao]], [[Mingxuan Wang]], [[Lin Qiu]], [[Weinan Zhang]], [[Yong Yu]], [[Lei Li]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 25th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GloVe-Twitter-200d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GloVe-Twitter-200d/</guid><description> [[GloVe]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GloVe/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GloVe/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GLUE-Benchmark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GLUE-Benchmark/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/google/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/google/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/gPool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/gPool/</guid><description>performs [[Downsampling-based Pooling]] by calculating an importance measure using the node features and a learnt vector. A gating system is also used to control the information flow from the input features to the new features.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GPT-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GPT-2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/GPT-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GPT-3/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Graclus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graclus/</guid><description>a greedy algorithm to compute successive coarser versions of a given graph</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graham-Neubig/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graham-Neubig/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gram-Schmidt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gram-Schmidt/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gram-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gram-matrix/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Adversarial-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Adversarial-Learning/</guid><description>A [[Graph Adversarial Defense]] method which incorporates adversarial samples into the training procedure to improve the robustness of the models.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GRAPH-ATTENTION-NETWORKS-Paper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GRAPH-ATTENTION-NETWORKS-Paper/</guid><description>Author(s): [[Petar Veličković]], [[Guillem Cucurull]], [[Arantxa Casanova]], [[Adriana Romero]], [[Pietro Liò]], [[Yoshua Bengio]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 22nd 2020]] URL: http://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Attention/</guid><description>[[Deep Learning On Graphs Chapter 6 - Robust Graph Neural Networks]] A [[Graph Adversarial Defense]] defense method which identifies the adversarial attacks during the training stage and gives them less attention while training the model</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Auto-Encoders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Auto-Encoders/</guid><description>[[Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs]] There are two types of autoencoders:</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Convolutional-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Convolutional-Network/</guid><description>[[SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS]] The layer wise propagation wise is defined as: $$H^{l+1} = \sigma(\tilde{D}^{-\frac{1}{2} }\tilde{A}\tilde{D}^{-\frac{1}{2}} H^{(l)}W^{(l)})$$ where</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Embbedding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Embbedding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Fourier-Transform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Fourier-Transform/</guid><description>a variant of the [[Fourier Transform]] and is defined as $$\hat{f}[l] = &amp;lt;f,u_l&amp;gt; = \sum_{i_i}^N f[i]u_l[i]$$ where $u_l$ is the l-th eigenvector of the [[Laplacian Matrix]] of the graph.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Isomorphism-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Isomorphism-Networks/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] Networks with the aim of checking for [[Graph Isomorphism]] between a pair of graph.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Isomorphism/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Isomorphism/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] ![[Pasted image 20201215215447.png]] Two graphs exhibit [[Isomorphism]] if there exists an index permutation between the nodes that preserves node adjacencies Determining if two graphs are isomorphic is [[NP-Intermediate]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Neural-Networks/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] Properties: Rank-2 Tensors Can be represented as list of edges (ideal for sparse graph), or a matrix.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Pooling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Pooling/</guid><description>[[Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering]] ![[Pasted image 20201215132826.png]] [[Pooling]] is done on graphs in this paper by artifically inflating the dimensions of the graph but adding fake nodes with a neutral value.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Positional-Encodings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Positional-Encodings/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] Properties: Unique representation for each node.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Purification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Purification/</guid><description>A [[Graph Adversarial Defense]] method which tries to detect the adversarial attacks and remove them from the attacked graph to generate a clean graph</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Reordering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Reordering/</guid><description>[[Promoting Graph Awareness in Linearized Graph-to-Text Generation]] A task to reconstruct the original graph from a randomized-order or reconfigured-order graph.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Signal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Signal/</guid><description>![[Pasted image 20201203142729.png]] consists of a graph and a mapping function which maps the nodes to real values.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Structure-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Structure-Learning/</guid><description>A [[Graph Adversarial Defense]] method which aims to learn a clean graph from the attacked graph while jointly training the graph neural network model</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Substructure-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Substructure-Networks/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] ![[Pasted image 20201215230817.png]] Deals with higher order interactions such as [[Cycles]], [[Cliques]], [[Clusters]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-to-Sequence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-to-Sequence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Aware-Transformer-Is-Attention-All-Graphs-Need/</guid><description>Author(s): [[Sanghyun Yoo]], [[Young-Seok Kim]], [[Kang Hyun Lee]], [[Kuhwan Jeong]], [[Junhwi Choi]], [[Hoshik Lee]], [[Young Sang Choi]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 20th 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GRaph-Aware-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GRaph-Aware-Transformer/</guid><description>[[Graph-Aware Transformer - Is Attention All Graphs Need]] ![[Pasted image 20201220233001.png]]The [[Transformer]] is modifed to take graphs as input. Each node is treated as a token.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-LSTM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-LSTM/</guid><description>[[Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs]] Refer to [[Tree-LSTM]] for operations There are no natural ordering for trees like in generic graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-to-Sequence-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-to-Sequence-Neural-Machine-Translation/</guid><description>Author(s): [[Sufeng Duan]], [[Hai Zhao]], [[Rui Wang]] Tags: #academic_papers, #Neural_Machine_Translation, #Graph_Neural_Networks Read on: [[January 4th 2021]] URL: https://arxiv.org/abs/2009.07489
Main Contribution(s) Proposes the [[Graph-Transformer]] by capturing information of subgraphs of different orders in every layer.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graph-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graph-Transformer/</guid><description>[[Graph-to-Sequence Neural Machine Translation]] ![[Pasted image 20210104233240.png]] There are three levels for the subgraph order
High order, which uses [[Multi-Head Self-Attention]] Middle order, which uses two groups of [[Multi-Head Self-Attention]] Low order, which does not contain any [[Multi-Head Self-Attention]], and uses a [[Feed-forward]] layer instead.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GraphAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GraphAT/</guid><description>[[Graph Adversarial Learning]] method which incorporates node features based adversarial samples into the training procedure of the classification model.
Motivation is that one important assumption is that neighboring nodes tend to be similar with each other.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graphite-Iterative-Generative-Modeling-of-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graphite-Iterative-Generative-Modeling-of-Graphs/</guid><description>Author(s): [[Aditya Grover]], [[Aaron Zweig]], [[Stefano Ermon]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 22nd 2020]] URL: https://arxiv.org/abs/1803.10459
Main Contribution(s) Proposes [[Graphite]], which uses [[Variational Auto-Encoder]]s along with [[Graph Neural Networks|GNN]] for [[Unsupervised]] [[Representation learning]] of large graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graphite-AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graphite-AE/</guid><description>[[Auto-Encoders]] version of [[Graphite]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graphite-VAE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graphite-VAE/</guid><description>[[Variational Auto-Encoder]] version of [[Graphite]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Graphite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Graphite/</guid><description>[[Graphite - Iterative Generative Modeling of Graphs]] Combines [[Probabilistic Modeling]] and [[Representation learning]] for Graphs.
![[Pasted image 20201222030547.png]]Aims to learn a parameterized distribution over [[Adjacency Matrix]]s.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/GraphSAGE-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/GraphSAGE-Filter/</guid><description>Uses a pipeline to aggregate information $$N_s(v_i) = \text{SAMPLE}(N(v_i),S)$$$$f^\prime_{N_{S{(v_i)}}} = \text{AGGREGATE}({F_j, \forall v_j \in N_S(v_i) })$$ $$F^\prime_i = \sigma([F_i ,f^\prime_{N_{s(v_i)}}]) \Theta$$ There are several aggregator functions, such as element-wise mean, [[LSTM]], [[Pooling]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Grassmanns-Law/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Grassmanns-Law/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gray-box-attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gray-box-attack/</guid><description>No access to architecture, parameters. Only access to training data</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Gray-Level-Indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gray-Level-Indexing/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gretchen-Krueger/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gretchen-Krueger/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Guiding-Non-Autoregressive-Neural-Machine-Translation-Decoding-with-Reordering-Information/</guid><description>Author(s): [[Qiu Ran]], [[Yankai Lin]], [[Peng Li]], [[Jie Zhou]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[May 23rd, 2020]] Reread on: [[August 25th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Guillermo-Echegoyen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Guillermo-Echegoyen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Guru-Guruganesh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Guru-Guruganesh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Gurunath-Reddy-Madhumani/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Gurunath-Reddy-Madhumani/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/G%C3%A1bor-Horv%C3%A1th/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/G%C3%A1bor-Horv%C3%A1th/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/G%C3%B6del-T-norm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/G%C3%B6del-T-norm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/G%C3%B6del-Escher-Bach-an-Eternal-Golden-Braid/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Haiqing-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Haiqing-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hal-Daum%C3%A9-III/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hal-Daum%C3%A9-III/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hamacher-Product/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hamacher-Product/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hamming-Distance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hamming-Distance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hanna-Wallach/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hanna-Wallach/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hannah-Rashkin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hannah-Rashkin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hanqing-Lu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hanqing-Lu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hao-Zhou/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hao-Zhou/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Harmonic-Percussive-Source-Separation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Harmonic-Percussive-Source-Separation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Harris-Chan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Harris-Chan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/HEDGE-ALGEBRAS-AN-ALGEBRAIC-APPROACH-TO-STRUCTURE-OF-SETS-OF-LINGUISTIC-TRUTH-VALUES/</guid><description>Author(s): [[Nguyen Cat Ho]], [[Wolfgang Wechler]] Tags: #Fuzzy_Logic, #Linguistic_Variable, #academic_papers Read on: [[September 24th, 2020]] URL: https://www.sciencedirect.com/science/article/abs/pii/016501149090002N
Main Contribution(s) Show that any sets of linguistic values of linguistic variables can be axiomatized, which leads to a notion of hedge algebras.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Heewoo-Jun/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Heewoo-Jun/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Heterogeneous-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Heterogeneous-Graphs/</guid><description>consists of nodes, edges, but each node and each edge are associated with a type. Therefore there are two mapping functions to map nodes and edges to their types.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hidden-Markov-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hidden-Markov-Models/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchical-Clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchical-Clustering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchical-Softmax/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchical-Softmax/</guid><description>![[Pasted image 20201204011202.png]]Nodes in a graph are assigned to the leaves of a [[Binary Tree]]. The probability $p(v_{con}|v_{cen})$ can be modelled through the path to the target node using a series of binary classifiers that takes the embedding vector of the center node.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchical-Structural-Similarity-Measure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchical-Structural-Similarity-Measure/</guid><description>used to quantify [[Structural Role]] in a graph. $R_k(v)$ is the set of nodes $k$-hop away from node $v$. Then, $R_k(v)$ is ordered according to their degree to form $s(R_k(v))$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchically-Clustered-Adaptive-Quantization-CMAC-HCAQ-CMAC-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchically-Clustered-Adaptive-Quantization-CMAC-and-Its-Learning-Convergence/</guid><description>Author(s): [[Sintiani Teddy]], [[Edmun M-K Lai]], [[Chai Quek]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 8th, 2020]] URL: https://www.researchgate.net/publication/5797287_Hierarchically_Clustered_Adaptive_Quantization_CMAC_and_Its_Learning_Convergence
Main Contribution(s) Introduces [[Hierarchical Clustering]] for [[Cerebellar Model Articulation Controller (CMAC)]] to allocate more memory cells to these regions, hence improving efficiency and generalization Summary Uniform quantization for inputs might result in suboptimal memory space utilization.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hierarchy-Aware-Knowledge-Graph-Embedding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hierarchy-Aware-Knowledge-Graph-Embedding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/High-Boost-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/High-Boost-Filtering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hiroaki-Sugiyama/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hiroaki-Sugiyama/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Histogram-Backprojection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Histogram-Backprojection/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Histogram-Equalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Histogram-Equalization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Histogram-Intersection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Histogram-Intersection/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Homer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Homer/</guid><description> https://arxiv.org/abs/1911.05815</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Homogeneous/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Homogeneous/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hough-Transform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hough-Transform/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/How-Contextual-are-Contextualized-Word-Representations-Comparing-the-Geometry-of-BERT-ELMo-and-GPT-2-Embeddings/</guid><description>Author(s): [[Kawin Ethayarajh]] Tags: #academic_papers, #critique, #BERT, #transformer, #Embeddings Read on: [[October 11th, 2019]] URL: https://arxiv.org/abs/1909.00512
Main Contribution(s) Summary Analyses contextual word embeddings behind language models like [[BERT]] and [[GPT-2]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hui-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hui-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hui-Su/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hui-Su/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Huizhen-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Huizhen-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hypergraphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hypergraphs/</guid><description>![[Pasted image 20201203144620.png]]can encode higher order relations (not simply pairwise information via edges). It is formally defined as $G={V,E,W}$ where $W$ is a diagonal matrix denoting the weight of the hyperedges.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Hysteresis-Thresholding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hysteresis-Thresholding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Hyundong-Cho/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Hyundong-Cho/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ibAbI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ibAbI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ilya-Sutskever/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ilya-Sutskever/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Captioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Captioning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Dithering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Dithering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Inpainting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Inpainting/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Negatives/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Negatives/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Quilting-for-Texture-Synthesis-and-Transfer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Quilting-for-Texture-Synthesis-and-Transfer/</guid><description>Author(s): [[Alexei A. Efros]], [[William T. Freeman]] Tags: #Texture_Synthesis, #Computer_Vision, #academic_papers Read on: [[October 10th, 2020]] URL: https://people.eecs.berkeley.edu/~efros/research/quilting/quilting.pdf
Main Contribution(s) Proposes a simple overlap error metric that allows to fast texture synthesis Summary Uses the Minimum Error Bounding Cut is defined by $$E_{ij} = e_{ij} + min(E_{i-1, j-1}, E_{i-1,j}, E_{i-1,j+1})$$ which finds the minimal vertical cut through the surface for all possible paths Learning Gaps/Thoughts</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-Restoration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-Restoration/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Image-to-Image-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Image-to-Image-Translation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ImageNet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ImageNet/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Imitation-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Imitation-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Implementing-fuzzy-logic-controllers-using-a-neural-network-framework-1990/</guid><description>Author(s): [[Ronald R. Yager]] Tags: #Fuzzy_Logic, #academic_papers Read on: [[September 23rd, 2020]] URL: https://www.sciencedirect.com/science/article/abs/pii/S0165011499800098
Main Contribution(s) Implements [[Fuzzy Logic Controllers]] using [[Neural Network]]s Summary [[Fuzzy Logic Controllers]] takes in specific settings and readings and outputs a specific crisp value.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Importance-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Importance-Sampling/</guid><description>A shared distribution, which is defined over the entire node set $V$, is utilized to sample a shared set of nodes</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Importance-Weighted-Decoding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Importance-Weighted-Decoding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Improved-MCMAC-with-Momentum-Neighborhood-and-Averaged-Trapezoidal-Output/</guid><description>Author(s): [[Kai Keng Ang]], [[Chai Quek]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 8th, 2020]] URL: https://www.semanticscholar.org/paper/Improved-MCMAC-with-momentum%2C-neighborhood%2C-and-Ang-Quek/4156678b6386c35e7bed3019fa082bf572d1f83a
Main Contribution(s) Improves the learning algorithm of the [[Modified CMAC (MCMAC) (Architecture)]] Summary [[Modified CMAC (MCMAC) (Architecture)]] is similar to [[Cerebellar Model Articulation Controller (CMAC)]], except that the quantized closed loop error are the indices to the memory array.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Improving-Non-autoregressive-Neural-Machine-Translation-with-Monolingual-Data/</guid><description>Author(s): [[Jiawei Zhou]], [[Phillip Keung]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[May 25th, 2020]] Reread on: [[August 25th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Imputer-Sequence-Modelling-via-Imputation-and-Dynamic-Programming/</guid><description>Author(s): [[William Chan]], [[Chitwan Saharia]], [[Geoffrey Hinton]], [[Mohammad Norouzi]], [[Navdeep Jaitly]] Tags: #Speech_Recognition, #Non-Autoregressive, #academic_papers Read on: [[August 15th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Imputer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Imputer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/iNAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/iNAT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/INCORPORATING-AUXILIARY-DATA-FOR-URBAN-SOUND-TAGGING/</guid><description>Author(s): [[Turab Iqbal]], [[Yin Cao]], [[Mark D. Plumbley]], [[Wenwu Wang]] Tags: #academic_papers, #audio_tagging, #dcase2020_task5 Read on: [[April 27th 2021]] URL: http://dcase.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Incremental-Intersection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Incremental-Intersection/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Independent-Component-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Independent-Component-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Inductive-Biases/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Inductive-Biases/</guid><description>[[Relational inductive biases, deep learning, and graph networks]] An inductive bias allows a learning algorithm to prioritize one solution (or interpretation) over another, independent of the observed data</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Information-Retrieval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Information-Retrieval/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Information-Theoretic-Probing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Information-Theoretic-Probing/</guid><description>[[Information-Theoretic Probing]] Theorizes a quantity of information based on the measurement of a certain property</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Injective/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Injective/</guid><description>maps distinct elements of its domain to distinct elements of its codomain. ie. every element of the function&amp;rsquo;s codomain is the image of at most one element of its domain</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations/</guid><description>Author(s): [[Mitchell Stern]], [[William Chan]], [[Jamie Kiros]], [[Jakob Uszkoreit]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 18th, 2020]] URL: https://arxiv.org/abs/1902.03249</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Insertion-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Insertion-Transformer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Integrated-Gradient-Guided-Attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Integrated-Gradient-Guided-Attack/</guid><description>Gradient information is used as scores to guide the attack. Aims to impair node classification performance. Attacker can add or remove edges.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Intelligent-Tutoring-Systems-ITS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Intelligent-Tutoring-Systems-ITS/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Inter-sentential-Relations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Inter-sentential-Relations/</guid><description>[[Document Graph for Neural Machine Translation]] allow links from one sentence to another following sentence. In this paper [[Lexical Consistency]] and [[Coreference]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Interaction-Quality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Interaction-Quality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/intercom-container/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/intercom-container/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Interpretability-Improvements-to-Find-the-Balance-Interpretability-Accuracy-in-Fuzzy-Modeling-An-Overview-2003/</guid><description>Author(s): [[Jorge Casillas]], [[Oscar Cordon]], [[Francisco Herrera]], [[Luis Magdalena]] Tags: #Fuzzy_Logic, #academic_papers Read on: [[September 29th, 2020]] URL: https://www.semanticscholar.org/paper/Interpretability-Improvements-to-Find-the-Balance-Casillas-Cord%C3%B3n/280b8c1a88cc682dae73699be87de2f53302a61e
Main Contribution(s) Provides an overview of [[Linguistic [[Fuzzy Logic]]]] and [[Precise [[Fuzzy Logic]]]] before 2003 Summary Trade off between [[Interpretability]] and [[Accuracy]] [[Principle of Incompatibility]] by [[Lotfi Asker Zadeh]] - As the complexity of a system increases, our ability to make precise and yet significant statements about its behavior diminishes until a threshold is reached beyond which precision and significance (or relevance) become almost mutually exclusive characteristics [[Linguistic [[Fuzzy Logic]]]] or Rule-Based System, also known as Mamdani-type FRBS IF $$X_1 &amp;hellip; X_n$$ is $$A_1 &amp;hellip; A_n$$, THEN, $$Y_1 &amp;hellip; Y_m $$ is $$B_1 &amp;hellip; B_m$$ Requires a rule base, and a data (knowledge) base Suffers from exponential growth in size when dealing with high dimensional data With more dimensions, every linguistic rule also lose part of its description ability since the understanding of the condition to activate the rule becomes more difficult.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Interpretability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Interpretability/</guid><description> Interpretability means that the cause and effect can be determined. https://datascience.stackexchange.com/questions/70164/what-is-the-difference-between-explainable-and-interpretable-machine-learning Definition seems quite inconsistent</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Intra-sentential-Relations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Intra-sentential-Relations/</guid><description>[[Document Graph for Neural Machine Translation]] provide links between words in a sentence. In this paper, [[Adjacency]] and [[Dependency]] are considered</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Inverse-Graph-Fourier-Transform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Inverse-Graph-Fourier-Transform/</guid><description>defined as $$f[i] = \sum_{l=1}^N \hat{f}[l]u_l[i]$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Inverse-Square-Root-Linear-Unit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Inverse-Square-Root-Linear-Unit/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Invertibility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Invertibility/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/INVESTIGATING-LOCAL-AND-GLOBAL-INFORMATION-FOR-AUTOMATED-AUDIO-CAPTIONING-WITH-TRANSFER-LEARNING/</guid><description>Author(s): [[Xuenan Xu]], [[Heinrich Dinkel]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[May 3rd 2021]] URL: https://arxiv.org/abs/2102.11474
Main Contribution(s) Problem: Encoder has to learn all concepts for audio captioning Solution: proposes to use two source tasks to train for audio captioning</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Investigating-Pretrained-Language-Models-for-Graph-to-Text-Generation/</guid><description>Author(s): [[Leonardo F.R. Ribeiro]], [[Martin Schmitt]], [[Hinrich Schütze]], [[Iryna Gurevych]] Tags: #academic_papers, #Graph_Neural_Networks, #transformer, #Graph_to_Text Read on: [[January 6th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Irene-Lo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Irene-Lo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IRIS-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IRIS-dataset/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IRIS-dialogue-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IRIS-dialogue-system/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Is-this-Dialogue-Coherent-Learning-from-Dialogue-Acts-and-Entities/</guid><description>Author(s): [[Alessandra Cervone]], [[Giuseppe Riccardi]] Tags: #academic_papers, #datasets, #Conversational_Dialogue_Systems, #Evaluation_Metric Read on: [[June 21st, 2020]] URL: http://arxiv.org/abs/2006.10157
Main Contribution(s) Propose a [[Switchboard Coherence]] corpus made from [[SwitchBoard]] Models combining both dialogue acts and entity information yield the best performance for response selection and turn coherence rating Summary Augment data by generate negative samples of dialogue acts Internal swap - random turn swapped from same conversation External swap - random turn selected from other conversations [[Switchboard Coherence]] Workers were asked to rate on a scale of 1-3 how much each response makes sense as the next natural turn in the dialogue.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Isabelle-Augenstein/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Isabelle-Augenstein/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Isomap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Isomap/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Isotropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Isotropy/</guid><description>[[How Contextual are Contextualized Word Representations - Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings]] Refers to embeddings occupying a wide area in vector space</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Iterative-Magnitude-Pruning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Iterative-Magnitude-Pruning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Iterative-Refinement-in-the-Continuous-Space-for-Non-Autoregressive-Neural-Machine-Translation/</guid><description>Author(s): [[Jason Lee]], [[Raphael Shu]], [[Kyunghyun Cho]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #Iterative_Refinement, #academic_papers Read on: [[September 18th, 2020]] URL: https://arxiv.org/abs/2009.07177
Main Contribution(s) Proposes an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous (embedding) space.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Iterative-Refinement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Iterative-Refinement/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IWSLT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IWSLT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IWSLT14-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IWSLT14-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IWSLT16-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IWSLT16-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/IWSLT16-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/IWSLT16-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/I%C3%B1igo-Casanueva/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/I%C3%B1igo-Casanueva/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jack-Clark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jack-Clark/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jack-Urbanek/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jack-Urbanek/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jack-W.-Rae/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jack-W.-Rae/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jake-Zhao-Junbo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jake-Zhao-Junbo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jakob-Uszkoreit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jakob-Uszkoreit/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/James-Bradbury/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/James-Bradbury/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jamie-Hall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jamie-Hall/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jamie-Kiros/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jamie-Kiros/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jan-Deriu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jan-Deriu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jane-Shen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jane-Shen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Janice-Lee-Ser-Huey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Janice-Lee-Ser-Huey/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jared-Kaplan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jared-Kaplan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jason-Lee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jason-Lee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jason-Weston/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jason-Weston/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jeffrey-Wu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jeffrey-Wu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jensen-Shannon-Divergence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jensen-Shannon-Divergence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jerry-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jerry-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ji-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ji-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jiajun-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jiajun-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jianfeng-Gao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jianfeng-Gao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jiangtao-Feng/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jiangtao-Feng/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jiatao-Gu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jiatao-Gu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jiawei-Zhou/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jiawei-Zhou/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jie-Jiang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jie-Jiang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jie-Zhou/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jie-Zhou/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jing-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jing-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jing-Xu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jing-Xu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jingbo-Zhu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jingbo-Zhu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jingjing-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jingjing-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jinglin-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jinglin-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/JinYeong-Bak/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/JinYeong-Bak/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jiusheng-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jiusheng-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jonathan-Frankle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jonathan-Frankle/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jonathan-May/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jonathan-May/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jorge-Casillas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jorge-Casillas/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Joshua-Ainslie/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Joshua-Ainslie/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Jo%C3%A3o-Sedoc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Jo%C3%A3o-Sedoc/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/JSALT2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/JSALT2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-13th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-13th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-14th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-14th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-21st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-21st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-31st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-31st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-3rd-2020/</guid><description>Main [[Takeaway(s)]] from [[Zhou Yu]]&amp;rsquo;s plenary talk at [[JSALT2020]] She thinks in bigger pictures; encoders/decoders architecture which are task agnostic.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/July-5th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-5th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-6th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-6th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-7th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-7th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-8th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-8th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/July-9th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/July-9th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-15th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-15th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-17th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-17th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-1st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-1st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-21st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-21st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-25th-2020/</guid><description> /</description></item><item><title/><link>https://aibrain.dhecloud.xyz/June-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-2nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-2nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/June-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/June-3rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Junliang-Guo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Junliang-Guo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/K-means-clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/K-means-clustering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kai-Keng-Ang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kai-Keng-Ang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/kanban/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/kanban/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kappa-coefficient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kappa-coefficient/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Katja-Hofmann/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Katja-Hofmann/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Katz-Centrality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Katz-Centrality/</guid><description>a variant of the [[Eigenvector Centrality]], but includes a small constant for the central node. It is defined as $$(I - \alpha\cdot A)c_k = \beta$$ $$c_k = (I - \alpha\cdot A)^{-1}\beta$$where $beta$ is the vector containing the constant term for all nodes.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Keita-Kurita/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Keita-Kurita/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kelvin-Guu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kelvin-Guu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kenneth-Church/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kenneth-Church/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/KERMIT-Generative-Insertion-Based-Modeling-for-Sequences/</guid><description>Author(s): [[William Chan]], [[Nikita Kitaev]], [[Kelvin Guu]], [[Mitchell Stern]], [[Jakob Uszkoreit]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 20th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Kernel-CMAC-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kernel-CMAC-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kernel-CMAC-With-Improved-Capability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kernel-CMAC-With-Improved-Capability/</guid><description>Author(s): [[Gábor Horváth]], [[Tamás Szabó]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 9th, 2020]] URL: https://ieeexplore.ieee.org/document/1379999
Main Contribution(s) Proposes a new interpolation model, the [[Kernel CMAC (Architecture)]] Summary Takes inspiration from the kernel trick of the [[Subject Vector Machines]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/KL-divergence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/KL-divergence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Knowledge-Based-Agents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Knowledge-Based-Agents/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Knowledge-Distillation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Knowledge-Distillation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Knowledge-Graph-Embeddings-and-Explainable-AI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Knowledge-Graph-Embeddings-and-Explainable-AI/</guid><description>Author(s): [[Federico Bianchi]], [[Gaetano Rossiello]], [[Luca Constabello]], [[Matteo Palmonari]], [[Pasquale Minervini]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 28th 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Knowledge-Graphs-Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Knowledge-Graphs-Embeddings/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] Definition ![[Pasted image 20201228185847.png]] Refers to the vector representation of the elements that form [[Knowledge Graphs]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Knowledge-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Knowledge-Graphs/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] used to denote relationships that connect entities with literals, using an [[Ontology]]. [[Knowledge Graphs]]are often visualized using an [[Adjacency Matrix]] or tensor, where $T \in \mathbb{R}^{N\times R\times N}$ where $N$ is the number of entities and $R$ is the number of relationships.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kontextuell-Encoder-Representations-Made-by-Insertion-Transformations-KERMIT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kotaro-Funakoshi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kotaro-Funakoshi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kurt-Shuster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kurt-Shuster/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kurtosis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kurtosis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Kyunghyun-Cho/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Kyunghyun-Cho/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/L.G.-Kraft/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/L.G.-Kraft/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Label-Flip-Rate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Label-Flip-Rate/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LAMBADA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LAMBADA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Language-Technology-is-Power-A-Critical-Survey-of-Bias-in-NLP/</guid><description>Author(s): [[Su Lin Blodgett]], [[Solon Barocas]], [[Hal Daumé III]], [[Hanna Wallach]] Tags: #bias, #critique, #academic_papers Read on: [[May 30th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LANGUAGE-MODEL-IS-ALL-YOU-NEED-NATURAL-LANGUAGE-UNDERSTANDING-AS-QUESTION-ANSWERING/</guid><description>Author(s): [[Mahdi Namazifar]], [[Alexandros Papangelis]], [[Gokhan Tur]], [[Dilek Hakkani-Tür]] Tags: #language_model, #Question-Answering_Dialogue_Systems, #Natural_Langauge_Understanding, #academic_papers Read on: [[December 1st 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/language-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/language-model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Language-Models-are-Few-Shot-Learners/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Language-Models-are-Few-Shot-Learners/</guid><description>Author(s): [[Tom B. Brown]], [[Benjamin Mann]], [[Nick Ryder]], [[Melanie Subbiah]], [[Jared Kaplan]], [[Prafulla Dhariwal]], [[Arvind Neelakantan]], [[Pranav Shyam]], [[Girish Sastry]], [[Amanda Askell]], [[Sandhini Agarwal]], [[Ariel Herbert-Voss]], [[Gretchen Krueger]], [[Tom Henighan]], [[Rewon Child]], [[Aditya Ramesh]], [[Daniel M.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LANGUAGE-MODELS-ARE-OPEN-KNOWLEDGE-GRAPHS/</guid><description>Author(s): [[Chenguang Wang]], [[Xiao Liu]], [[Dawn Song]] Tags: #academic_papers, #language_model Read on: [[December 21st 2020]] URL: https://arxiv.org/abs/2010.11967
Main Contribution(s) Converts [[language model]]s to [[Knowledge Graphs]] using a proposed [[Unsupervised]] approach called [[Match and Map]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Laplacian-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laplacian-Filter/</guid><description>[[Laplace operator]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Laplacian-Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laplacian-Matrix/</guid><description>Wikipedia Can be used to calculate number of [[Spanning Tree]]s for a graph. Can be used to construct low dimensional embeddings for [[Machine Learning]] applications.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Laplacian-of-Gaussian-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laplacian-of-Gaussian-Filter/</guid><description>Uses the [[Laplace operator]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Laplacian-Positional-Encodings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laplacian-Positional-Encodings/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Large-Scale-Information-Network-Embedding-LINE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Large-Scale-Information-Network-Embedding-LINE/</guid><description>Similar to [[node2vec]], but chooses to reconstruct the set of edges $E$ (as opposed to the list of co-occurrences $I$ ).</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Latent-Alignment-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Latent-Alignment-Models/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Latent-Space/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Latent-Space/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Laurence-Liew/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laurence-Liew/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Laurens-van-der-Maaten/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Laurens-van-der-Maaten/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Layer-wise-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Layer-wise-Sampling/</guid><description>Sample once for each graph layer</description></item><item><title/><link>https://aibrain.dhecloud.xyz/LDC2002E18/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LDC2002E18/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LDC2003E14/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LDC2003E14/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LDC2004T08/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LDC2004T08/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LDC2005T0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LDC2005T0/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Learning-Convergence-of-CMAC-Technique/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Learning-Convergence-of-CMAC-Technique/</guid><description>Author(s): [[Chun-Shin Lin]], [[Ching-Tsan Chiang]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 8th, 2020]] URL: https://dl.acm.org/doi/abs/10.1109/72.641451
Main Contribution(s) Explores and investigates the CMAC learning convergence Summary Two types of convergences: 1.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Learning-not-to-Discriminate-Task-Agnostic-Learning-for-Improving-Monolingual-and-Code-switched-Speech-Recognition/</guid><description>Author(s): [[Gurunath Reddy Madhumani]], [[Sanket Shah]], [[Basil Abraham]], [[Vikas Joshi]], [[Sunayana Sitaram]] Tags: #Code-switching, #Speech_Recognition, #Adversarial_Learning, #academic_papers Read on: [[June 17th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Learning-Rate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Learning-Rate/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Learning-to-Recover-from-Multi-Modality-Errors-for-Non-Autoregressive-Neural-Machine-Translation/</guid><description>Author(s): [[Qiu Ran]], [[Yankai Lin]], [[Peng Li]], [[Jie Zhou]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[June 15th, 2020]] Reread on: [[August 25th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Learning-Without-Forgetting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Learning-Without-Forgetting/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Least-Squares-Solution-for-Inconsistent-Equations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Least-Squares-Solution-for-Inconsistent-Equations/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Least-Squares/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Least-Squares/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lecture-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lecture-1/</guid><description> Date: [[August 12th, 2020]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Lei-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lei-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Leon-A.-Gatys/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Leon-A.-Gatys/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Levenshtein-Distance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Levenshtein-Distance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Levenshtein-Transformer-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Levenshtein-Transformer-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lexical-Consistency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lexical-Consistency/</guid><description>[[Document Graph for Neural Machine Translation]] Considers repeated and similar words across sentences. Add edges if exact same words or a pair of words has the same lemma.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Leyendecker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Leyendecker/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Li-Yang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Li-Yang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Liang-Ding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Liang-Ding/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LIAR-Politifact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LIAR-Politifact/</guid><description>According to [[Misinformation has High Perplexity]] LIAR is a publicly available dataset collected from the Politifact website, which consists of 12.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/LibriSpeech/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LibriSpeech/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lifelong-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lifelong-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lihua-Qian/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lihua-Qian/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Likert-Scores/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Likert-Scores/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lin-Qiu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lin-Qiu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Linear-Discriminant-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linear-Discriminant-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Linearized-Graph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linearized-Graph/</guid><description>[[Promoting Graph Awareness in Linearized Graph-to-Text Generation]] ![[Pasted image 20210107220318.png]] A graph in textual format</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Linguistic-Fuzzy-Logic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linguistic-Fuzzy-Logic/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Linguistic-Hedges/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linguistic-Hedges/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Linguistic-Variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linguistic-Variable/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Linli-Xu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Linli-Xu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/LLE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/LLE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Local-Entropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Local-Entropy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Long-Term-Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Long-Term-Memory/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Longteng-Guo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Longteng-Guo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Longyue-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Longyue-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lotfi-Asker-Zadeh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lotfi-Asker-Zadeh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lottery-Ticket-Hypothesis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lottery-Ticket-Hypothesis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Luis-F.-DHaro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Luis-F.-DHaro/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Luis-Magdalena/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Luis-Magdalena/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Luke-Zettlemoyer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Luke-Zettlemoyer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Luminance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Luminance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Lyapunov-Model-Reference-MRAC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Lyapunov-Model-Reference-MRAC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Machine-Learning-Conversations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Machine-Learning-Conversations/</guid><description>Speaker(s): [[Susan Dumais]], [[Katja Hofmann]], [[Akshay Krishnamurthy]], [[Asli Celikyilmaz]], [[Dan Klein]] Tags: #seminar Held on: [[July 20th, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Machine-Learning-Reliability-and-Robustness/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Machine-Learning-Reliability-and-Robustness/</guid><description>Speaker(s): [[Besmira Nushi]] (host), [[Thomas Dietterich]], [[Ece Kamar]], [[Suchi Saria]] Tags: #seminar Held on: [[July 22nd, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Machine-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mahalanobis-Distance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mahalanobis-Distance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Manhattan-Distance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Manhattan-Distance/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Manzil-Zaheer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Manzil-Zaheer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Margaret-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Margaret-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Maria-Rifqi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Maria-Rifqi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Marjan-Ghazvininejad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Marjan-Ghazvininejad/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mark-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mark-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mark-Cieliebak/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mark-Cieliebak/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Markov-Decision-Process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Markov-Decision-Process/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Markov-Random-Field/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Markov-Random-Field/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mars-theme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mars-theme/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Marti-Hearst/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Marti-Hearst/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mary-Gray/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mary-Gray/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mary-Williamson/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mary-Williamson/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Marzieh-Fadaee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Marzieh-Fadaee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Marzyeh-Ghassemi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Marzyeh-Ghassemi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mask-Predict-Parallel-Decoding-of-Conditional-Masked-Language-Models/</guid><description>Author(s): [[Marjan Ghazvininejad]], [[Omer Levy]], [[Yinhan Liu]], [[Luke Zettlemoyer]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 22nd, 2020]] URL: https://arxiv.org/abs/1904.09324</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mask-Predict/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mask-Predict/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Masked-Graph-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Masked-Graph-Modelling/</guid><description>[[Promoting Graph Awareness in Linearized Graph-to-Text Generation]] 15% masking for each word. All tokens, edge labels, semantic nodes have the chance of being masked.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Masked-Language-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Masked-Language-Modelling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Match-and-Map/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Match-and-Map/</guid><description>[[LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS]] ![[Pasted image 20201221225601.png]]!Consists of two stages:
Match: Generates a set of candidate facts from a textual corpus.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MATE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MATE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mateusz-Litwin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mateusz-Litwin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Matrix-Approximation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Matrix-Approximation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Matthew-A.-Turk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Matthew-A.-Turk/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Matthias-Bethge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Matthias-Bethge/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Maximum-Mutual-Information-MMI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Maximum-Mutual-Information-MMI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Maximum-Receptive-Field/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Maximum-Receptive-Field/</guid><description>[[Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks]] $$RF_n = RF_{n-1} + (k_n -1) \cdot S_n$$ $$S_n = S_n-1 \cdot s_n$$ where $s_n$, $k_n$ are stride and kernal size of layer $n$, and $S_n$ is the cumulative stride from layer $n$ to the input layer</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Maxine-Eskenazi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Maxine-Eskenazi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/May-31st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/May-31st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Md.-Akmal-Haidar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Md.-Akmal-Haidar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Reciprocal-Rank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Reciprocal-Rank/</guid><description>$$\text{MRR} = \frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{rank_i}$$ where $rank_i$ refers to the rank position of the first relevant document for the i-th query</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Shift-Analysis-and-Applications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Shift-Analysis-and-Applications/</guid><description>Author(s): [[Dorin Comaniciu]], [[Peter Meer]] Tags: #academic_papers Read on: [[September 24th, 2020]] URL: https://ieeexplore.ieee.org/document/790416/
Main Contribution(s) Proposes to use the [[Mean Shift Estimate]] of the gradient to perform processing in the spatial-range domain: filtering, and segmentation Summary The sample mean shift Always points to the direction of the maximum increase in density, hence can define a path leading to a local density maximum.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Shift-Estimate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Shift-Estimate/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Shift-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Shift-Filtering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Shift-Segmentation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Shift-Segmentation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mean-Squared-Error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mean-Squared-Error/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mechanism-Design-for-Social-Good/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mechanism-Design-for-Social-Good/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Median-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Median-Filtering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Meena/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Meena/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mehdi-Rezagholizadeh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mehdi-Rezagholizadeh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Melanie-Subbiah/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Melanie-Subbiah/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Melvin-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Melvin-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MeMo-workbench/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MeMo-workbench/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Memory/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Message-Passing-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Message-Passing-Networks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Meta-Reinforcement-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Meta-Reinforcement-Learning/</guid><description> [[Reinforcement Learning]] and [[meta-learning]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/meta-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/meta-learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Metattack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Metattack/</guid><description>[[Gray-box attack]] which aims to reduce the overall node classification performance. It is a [[Poisoning Attack]], and the attacker is formulated as a [[bi-level optimization]] problem.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/METEOR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/METEOR/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mia-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mia-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Michael-Carbin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Michael-Carbin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Michael-J.-Swain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Michael-J.-Swain/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Micha%C3%ABl-Defferrard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Micha%C3%ABl-Defferrard/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Michel-Galley/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Michel-Galley/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Michimasa-Inaba/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Michimasa-Inaba/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mike-Timms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mike-Timms/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Milica-Ga%C5%A1i%C4%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Milica-Ga%C5%A1i%C4%87/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MineRL-competition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MineRL-competition/</guid><description> challenge to mine diamond which requires several complex steps</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ming-Zhou/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ming-Zhou/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mingxuan-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mingxuan-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Minh-Thang-Luong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Minh-Thang-Luong/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mini-Turning-Benchmark-MTB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mini-Turning-Benchmark-MTB/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mirella-Lapata/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mirella-Lapata/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Misinformation-has-High-Perplexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Misinformation-has-High-Perplexity/</guid><description>Author(s): [[Nayeon Lee]], [[Yejin Bang]], [[Andrea Madotto]], [[Pascale Fung]] Tags: #critique, #Evaluation_Metric, #Covid19, #datasets, #academic_papers Read on: [[June 16th, 2020]] URL: http://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mitchell-Stern/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mitchell-Stern/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mitsuku/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mitsuku/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mixture-of-Experts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mixture-of-Experts/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mixture-of-Softmaxes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mixture-of-Softmaxes/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/mixup-BEYOND-EMPIRICAL-RISK-MINIMIZATION/</guid><description>Author(s): [[Hongyi Zhang]], [[Moustapha Cisse]], [[Yann N. Dauphin]], [[David Lopez-Paz]] Tags: #academic_papers Read on: [[April 27th 2021]] URL: https://arxiv.org/abs/1710.09412
Main Contribution(s) Proposees [[Mixup]], a data augmentation tactic for [[Classification]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mixup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mixup/</guid><description>[[mixup - BEYOND EMPIRICAL RISK MINIMIZATION]] Done by
$$ \tilde{x} = \lambda x_i + (1-\lambda)x_j $$ $$ \tilde{y} = \lambda y_i + (1-\lambda)y_j $$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MLDAEEE-Deep-Learning-Week-2020-Industry-Night-How-AI-Will-Transform-the-Post-COVID-World/</guid><description>Speaker(s): [[Simon See]], [[Pan Yaozhang]], [[Jane Shen]], [[Laurence Liew]], [[Yap Kim Hui]], [[Sim Kai]] Tags: #seminar Held on: [[October 12th, 2020]] URL: http://www.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mo-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mo-Filter/</guid><description>Taken from the [[Mixture Model Network (MoNet)]] framework. A pseudo-coordinate is introduced to denote the relevant relation between a pair of nodes, based on their [[Degree]]s.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mockingjay-Unsupervised-Speech-Representation-Learning-with-Deep-Bidirectional-Transformer-Encoders/</guid><description>Author(s): [[Andy T. Liu]], [[Shu-wen Yang]], [[Po-Han Chi]], [[Po-chun Hsu]], [[Hung-yi Lee]] Tags: #academic_papers Read on: [[May 11th 2021]] URL:</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Modal-Memory-Model-SOAR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Modal-Memory-Model-SOAR/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mode-Collapse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mode-Collapse/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Modeling-Local-Coherence-An-Entity-Based-Approach/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Modeling-Local-Coherence-An-Entity-Based-Approach/</guid><description>Author(s): [[Regina Barzilay]], [[Mirella Lapata]] Tags: #academic_papers, #Machine_Learning, #Features Read on: [[July 6th, 2020]] URL: https://people.csail.mit.edu/regina/my_papers/coherence.pdf
Main Contribution(s) Propose a novel framework, the [[Entity Grid]] for representation and measuring local coherence Summary Another type of feature extraction which relies on a little bit of dependency parsing (subject verb object) Creates a sparse matrix, with their grid cells corresponding to grammatical roles: subjects (s), objects (o), or neither (x) There is a simplified version of the matrix with only present (x) and not present (-) This allows us to encode a sequence with entity occurrences like a one-hot vector.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Models-of-Self-Organization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Models-of-Self-Organization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Modified-CMAC-MCMAC-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Modified-CMAC-MCMAC-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Modularity-Maximization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Modularity-Maximization/</guid><description>defined as $$Q=\frac{1}{2\cdot \text{vol(G)}}\sum_{ij}(A_{i,j} - \frac{d(v_i)d(v_j)}{\text{vol}(G)})h_ih_j$$ where $d(v_i)$ is the degree of node $v_i$. $h_i = 1$ if node $v_i$ belongs to the first community, otherwise -1.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Modus-Ponens/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Modus-Ponens/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mohammad-Norouzi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mohammad-Norouzi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Moments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Moments/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Monte-Carlo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Monte-Carlo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Moore-Penrose-Pseudoinverse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Moore-Penrose-Pseudoinverse/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Mountain-theme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Mountain-theme/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Movie-Scripts-Danescu-Niculescu-Mizil-and-Lee-2011/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MSCOCO/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MSCOCO/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MSDialog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MSDialog/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Multi-Agent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multi-Agent/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Multi-dimensional-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multi-dimensional-Graphs/</guid><description>consists of multiple relations between a pair of nodes. Therefore, there are multiple sets of edges which each describes the relations between the nodes.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Multi-Modality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multi-Modality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MULTI-TASK-REGULARIZATION-BASED-ON-INFREQUENT-CLASSES-FOR-AUDIO-CAPTIONING/</guid><description>Author(s): [[Emre Cakir]], [[Konstantinos Drossos]], [[Tuomas Virtanen]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[May 11th 2021]] URL: https://arxiv.org/abs/2007.04660
Main Contribution(s) Problem: Functional words are frequent, but informative content words are infrequent Solution: Weigh each word contribution according to each occurence, and use a side task to detect words using a separate decoder</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MULTI-VIEW-AUDIO-AND-MUSIC-CLASSIFICATION/</guid><description>Author(s): [[Huy Phan]], [[Huy Le Nguyen]], [[Oliver Y. Chen]], [[Lam Pham]], [[Philipp Koch]], [[Ian McLoughlin]], [[Alfred Mertins]] Tags: #academic_papers, #audio_tagging Read on: [[31-May-2021]] URL: [2103.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Multi30k/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multi30k/</guid><description>[[A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation]] Each image is paired with one English description and human translations into German and French.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Multilingual-KERMIT-Its-Not-Easy-Being-Generative/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multilingual-KERMIT-Its-Not-Easy-Being-Generative/</guid><description>Author(s): [[Harris Chan]], [[Jamie Kiros]], [[William Chan]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 21st, 2020]] URL: https://pgr-workshop.github.io/img/PGR027.pdf
Main Contribution(s) Applies the [KERMIT]([[Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)]]) to multilingual data, the [[Multi30k]] dataset Demonstrates unconditional multilingual generation using the joint [KERMIT]([[Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)]]) model Summary [[Multi30k]] 29000 parallel training sentences in English, French, Czech, German Trains [KERMIT]([[Kontextuell Encoder Representations Made by Insertion Transformations (KERMIT)]]) in bilingual, multi-target, joint settings.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Multiple-Regression-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multiple-Regression-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Multisystem-fusion-model-based-on-tag-relationship/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Multisystem-fusion-model-based-on-tag-relationship/</guid><description>Author(s): [[Zhuangzhuang Liu]], [[Junyan Fang]], [[Xiaofeng Hong]], [[Gang Liu]] Tags: #academic_papers, #dcase2020_task5, #audio_tagging Read on: [[April 27th 2021]] URL: http://dcase.community/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results#technical-reports</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MultiWOZ--A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MultiWOZ--A-Large-Scale-Multi-Domain-Wizard-of-Oz-Dataset-for-Task-Oriented-Dialogue-Modelling/</guid><description>Author(s): [[Paweł Budzianowski]], [[Tsung-Hsien Wen]], [[Bo-Hsiang Tseng]], [[Iñigo Casanueva]], [[Stefan Ultes]], [[Osman Ramadan]], [[Milica Gašić]] Tags: #Conversational_Dialogue_Systems, #datasets, #academic_papers Read on: [[June 18th, 2020]] URL: http://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MultiWOZ-1.0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MultiWOZ-1.0/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/MultiWOZ-2.1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MultiWOZ-2.1/</guid><description> (Eric et al., 2019)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/MusCaps-Generating-Captions-for-Music-Audio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/MusCaps-Generating-Captions-for-Music-Audio/</guid><description>Author(s): [[Ilaria Manco]], [[Emmanouil Benetos]], [[Elio Quinton]], [[Gyorgy Fazekas]] Tags: #academic_papers Read on: [[May 10th 2021]] URL: https://arxiv.org/abs/2104.11984
Main Contribution(s) Problem: Current approaches to music description rely on single of multi-label classification Solution: [[Music Captioning]], a subset of [[Automated Audio Captioning]], extracts high level music concepts and maps them to the text modality</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Myle-Ott/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Myle-Ott/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/N-grams/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/N-grams/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Naman-Goyal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Naman-Goyal/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Named-Entity-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Named-Entity-Recognition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nan-Duan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nan-Duan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nash-Equilibrium/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nash-Equilibrium/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Natural-Language-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Natural-Language-Processing/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Navdeep-Jaitly/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Navdeep-Jaitly/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nayeon-Lee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nayeon-Lee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NEFCLASS-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NEFCLASS-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NEFCLASS-A-Neuro-Fuzzy-approach-for-the-classification-of-data-Paper/</guid><description>Author(s): [[Detlef Nauck]], [[Rudolf Kruse]] Tags: #Fuzzy_Logic, #academic_papers Read on: [[October 31st, 2020]] URL: https://www.researchgate.net/publication/221000724_NEFCLASS_-_a_neuro-fuzzy_approach_for_the_classification_of_data
Main Contribution(s) Proposes [[NEFCLASS (Architecture)]], a neuro-fuzzy system for the classification of data, which is extended from a fuzzy perceptron.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Negative-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Negative-Sampling/</guid><description>Inspired by [[Noise Contrasitive Estimation (NCE)]] which approximately maximizes the log probability of the [[Softmax]], [[Negative Sampling]] samples $k$ nodes that do not appear in the context window of the center node.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Neighborhood-Explosion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neighborhood-Explosion/</guid><description>refers to the issue of exponentially growing neighborhood in [[Graph Neural Networks]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Neighbors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neighbors/</guid><description>of a node is the set of all nodes adjacent to that node</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Nettack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nettack/</guid><description>[[Gray-box attack]] which aims to generate adversarial graphs for the node classifcation task. A single node is selected to be the target.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Neural-Machine-Translation-without-Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neural-Machine-Translation-without-Embeddings/</guid><description>Author(s): [[Uri Shaham]], [[Omer Levy]] Tags: #Neural_Machine_Translation, #Embeddings, #academic_papers Read on: [[September 19th, 2020]] URL: https://arxiv.org/abs/2008.09396
Main Contribution(s) Represents sequences as bytes and remove the embedding component Summary Represents text as a sequence of bytes based on UTF-8 encoding Remove the input and output trainable token embedding layers Remove the dropout layers in the encoder input and decoder output as one-hot vectors works similarly to dropout by deleting significant pants of the model&amp;rsquo;s distribution.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neural-Machine-Translation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Neural-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neural-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Neural-User-Simulator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Neural-User-Simulator/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/News-Crawl-2007-English/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/News-Crawl-2007-English/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/News-Crawl-2007-French/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/News-Crawl-2007-French/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/News-Crawl-2010-English/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/News-Crawl-2010-English/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/News-Crawl-2010-French/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/News-Crawl-2010-French/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newsdev2016-En-Ro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newsdev2016-En-Ro/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newsdev2016-Ro-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newsdev2016-Ro-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2013-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2013-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2013-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2013-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2014-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2014-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2014-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2014-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2016-En-Ro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2016-En-Ro/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/newstest2016-Ro-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/newstest2016-Ro-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Next-Utterance-Selection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Next-Utterance-Selection/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nguyen-Cat-Ho/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nguyen-Cat-Ho/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nick-Ryder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nick-Ryder/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nikita-Kitaev/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nikita-Kitaev/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nilpotent-Minimum/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nilpotent-Minimum/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST02/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST02/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST03/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST03/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST04/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST04/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST05/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST05/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST06/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST06/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NIST08/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NIST08/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nitika-Mathur/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nitika-Mathur/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Noah-Fiedel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Noah-Fiedel/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Noam-Shazeer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Noam-Shazeer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nobuhiro-Kaji/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nobuhiro-Kaji/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/node2vec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/node2vec/</guid><description>Similar to [[DeepWalk]], but uses a biased second order [[Random Walk]]. The walk takes 2 parameters $p$ and $q$ is defined as: $$\alpha_{pq}(v^{(t+1)}|v^{(t-1)},v^{(t)} = \begin{cases} \frac{1}{p},&amp;amp; \text{if dis}(v^{t-1},v^{t+1})=0\ 1,&amp;amp; \text{if dis}(v^{t-1},v^{t+1})=1\ \frac{1}{q},&amp;amp; \text{if dis}(v^{t-1},v^{t+1})=2 \end{cases}$$ where $\text{if dis}(v^{t-1},v^{t+1})$ is the length of the shortest path between teh two nodes.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/noisy-gradient-descent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/noisy-gradient-descent/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Noisy-Parallel-Decoding-NPD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Noisy-Parallel-Decoding-NPD/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Autoregressive-Image-Captioning-with-Counterfactuals-Critical-Multi-Agent-Learning/</guid><description>Author(s): [[Longteng Guo]], [[Jing Liu]], [[XinXin Zhu]], [[Xingjian He]], [[Jie Jiang]], [[Hanqing Lu]] Tags: #Non-Autoregressive, #Image_Captioning, #academic_papers Read on: [[August 24th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Autoregressive-Machine-Translation-with-Latent-Alignments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Autoregressive-Machine-Translation-with-Latent-Alignments/</guid><description>Author(s): [[Chitwan Saharia]], [[William Chan]], [[Saurabh Saxena]], [[Mohammad Norouzi]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 14th, 2020]] URL: https://arxiv.org/abs/2004.07437</description></item><item><title/><link>https://aibrain.dhecloud.xyz/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NON-AUTOREGRESSIVE-NEURAL-MACHINE-TRANSLATION/</guid><description>Author(s): [[Jiatao Gu]], [[James Bradbury]], [[Caiming Xiong]], [[Victor O.K. Li]], [[Richard Socher]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 14th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Autoregressive-Transformer-by-Position-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Autoregressive-Transformer-by-Position-Learning/</guid><description>Author(s): [[Yu Bao]], [[Hao Zhou]], [[Jiangtao Feng]], [[Mingxuan Wang]], [[Shujian Huang]], [[Jiajun Chen]], [[Lei Li]] Tags: #Non-Autoregressive, #Paraphrase_Generation, #Neural_Machine_Translation, #academic_papers Read on: [[August 14th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Autoregressive-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Autoregressive-Transformer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Autoregressive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Autoregressive/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-Gaussianity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-Gaussianity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Non-maximal-Suppression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Non-maximal-Suppression/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Normal-Distribution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Normal-Distribution/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-10th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-10th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-11th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-11th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-12th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-12th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-13th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-13th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-14th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-14th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-15th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-15th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-17th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-17th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-1st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-1st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-2nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-2nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-3rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-4th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-4th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-5th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-5th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-6th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-6th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-7th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-7th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-8th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-8th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/November-9th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/November-9th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nox/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nox/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/NP-Intermediate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NP-Intermediate/</guid><description>not known if a polynomial time algorithm exists, or the problem is NP-hard.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/NTU-AI+X-Symposium-AI-for-Social-Good/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/NTU-AI+X-Symposium-AI-for-Social-Good/</guid><description>Speaker(s): [[Bo An]], [[Shane A. Synder]], [[Janice Lee Ser Huey]], [[Gerard Goggin]], [[Andrew Prahl]], [[Melvin Chen]], [[Qian Hangwei]] Tags: #Social_Good, #seminar Held on: [[November 17th, 2020]] URL: https://ntu-sg.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Nucleus-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nucleus-Sampling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Null-Space-kernel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Null-Space-kernel/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Null-Space/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Null-Space/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Nullity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Nullity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ocean-theme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ocean-theme/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-10th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-10th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-11th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-11th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-12th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-12th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-13th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-13th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-15th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-15th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-17th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-17th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-1st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-1st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-21st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-21st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-2nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-2nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-31st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-31st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-3rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-4th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-4th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-5th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-5th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-6th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-6th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-7th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-7th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-8th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-8th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/October-9th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/October-9th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/OffenseEval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/OffenseEval/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Omer-Levy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Omer-Levy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ontology/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ontology/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] A formal specification of the meaning of types and relationships expressed as a set of logical constraints and rules, which support automated reasoning</description></item><item><title/><link>https://aibrain.dhecloud.xyz/OpenAI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/OpenAI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/OpenSubtitles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/OpenSubtitles/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Optimized-Product-Quantization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Optimized-Product-Quantization/</guid><description>Author(s): [[Tiezheng Ge]], [[Kaiming He]], [[Qifa Ke]], [[Jian Sun]] Tags: #academic_papers Read on: [[May 1st 2021]] URL: http://kaiminghe.com/cvpr13/index.html
Main Contribution(s) Problem: [[Product Quantization]] is not optimized yet in terms of performance Solution: Minimizes quantization distortions by 1.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Orthogonal-Basis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Orthogonal-Basis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Orthogonal-Vector-Conjecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Orthogonal-Vector-Conjecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Orthogonality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Orthogonality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Oscar-Cordon/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Oscar-Cordon/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Osman-Ramadan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Osman-Ramadan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Over-Squashing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Over-Squashing/</guid><description>information from the exponentially growing recipetive field is compressed into fixed length vectors.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Overview-of-the-dialogue-breakdown-detection-challenge-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Overview-of-the-dialogue-breakdown-detection-challenge-3/</guid><description>Author(s): [[Ryuichiro Higashinaka]], [[Kotaro Funakoshi]], [[Michimasa Inaba]], [[Yuiko Tsunomori]], [[Tetsuro Takahashi]], [[Nobuhiro Kaji]] Tags: #datasets, #survey, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 22nd, 2020]] URL: http://workshop.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Overview-of-the-Dialogue-Breakdown-Detection-Challenge-4/</guid><description>Author(s): [[Ryuichiro Higashinaka]], [[Luis F. D’Haro]], [[Bayan Abu Shawar]], [[Rafael E. Banchs]], [[Kotaro Funakoshi]], [[Michimasa Inaba]], [[Yuiko Tsunomori]], [[Tetsuro Takahashi]], [[João Sedoc]] Tags: #datasets, #survey, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 20th, 2020]] URL: http://workshop.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/PA-GNN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PA-GNN/</guid><description>Aims to learn mechanism that can assign low attention scores to adversarial edges by transfering knowledge from clean graphs</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Pan-Yaozhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pan-Yaozhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PARAdigm-for-DIalog-System-Evaluation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PARAdigm-for-DIalog-System-Evaluation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Paraphrase-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Paraphrase-Generation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ParlAI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ParlAI/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Partial-Scoring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Partial-Scoring/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pascale-Fung/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pascale-Fung/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Path/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Path/</guid><description>a [[Walk]] whose nodes are distinct.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Paul-Michel/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Paul-Michel/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pawe%C5%82-Budzianowski/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pawe%C5%82-Budzianowski/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PCA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PCA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pearl-Causal-Hierarchy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pearl-Causal-Hierarchy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pearsons-Correlation-Coefficient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pearsons-Correlation-Coefficient/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Peer-Review/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Peer-Review/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Peng-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Peng-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PENMAN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PENMAN/</guid><description>[[Promoting Graph Awareness in Linearized Graph-to-Text Generation]] ![[Pasted image 20210107221222.png]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Permutation-Invariant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Permutation-Invariant/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PersonaChat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PersonaChat/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Personalizing-Dialogue-Agents-I-have-a-dog-do-you-have-pets-too/</guid><description>Author(s): [[Saizheng Zhang]], [[Emily Dinan]], [[Jack Urbanek]], [[Arthur Szlam]], [[Douwe Kiela]], [[Jason Weston]] Tags: #datasets, #Conversational_Dialogue_Systems, #academic_papers Read on: [[July 16th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Peter-Bell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Peter-Bell/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Peter-Lee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Peter-Lee/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Peter-Meer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Peter-Meer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PGD-Topology-Attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PGD-Topology-Attack/</guid><description>Attacker is only allowed to modify the graph structures but not the node features. Aims to find a set of edges for which when removed, will lead to bad prediction performance.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Philip-Pham/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Philip-Pham/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Phillip-Keung/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Phillip-Keung/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/PIQA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PIQA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Point-Normal-Equations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Point-Normal-Equations/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Point-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Point-Processing/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Poisoning-Attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Poisoning-Attack/</guid><description>Attacks before the model is trained. Training data is poisoned.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Poly-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Poly-Filter/</guid><description>Models the filter with a K-order truncated polynomial to reduce the number of hops from the target node.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Pooling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pooling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Position-Non-Autoregressive-Transformers-PNAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Position-Non-Autoregressive-Transformers-PNAT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Prafulla-Dhariwal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Prafulla-Dhariwal/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pranav-Shyam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pranav-Shyam/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Precise-Fuzzy-Logic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Precise-Fuzzy-Logic/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Precision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Precision/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Prediction-Machines-The-Simple-Economics-of-Artificial-Intelligence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Principal-Component-Analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Principal-Component-Analysis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Principal-Neighbourhood-Aggregation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Principal-Neighbourhood-Aggregation/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] ![[Pasted image 20201215223415.png]] Intended to increase the expressivity power of aggregators.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Principle-of-Incompatibility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Principle-of-Incompatibility/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pro-GNN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pro-GNN/</guid><description>Aims to learn a new [[Adjacency Matrix]] $S$, which is close to the original adjacency matrix $A$, while being low-rank and also ensuring feature smoothing.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Probing-Neural-Dialog-Models-for-Conversational-Understanding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Probing-Neural-Dialog-Models-for-Conversational-Understanding/</guid><description>Author(s): [[Abdelrhman Saleh]], [[Tovly Deutsch]], [[Stephen Casper]], [[Yonatan Belinkov]], [[Stuart Shieber]] Tags: #critique, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 16th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Product-T-norm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Product-T-norm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Projection-Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Projection-Matrix/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Projection-Pursuit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Projection-Pursuit/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Promoting-Graph-Awareness-in-Linearized-Graph-to-Text-Generation/</guid><description>Author(s): [[Alexander Hoyle]], [[Ana Marasović]], [[Noah Smith]] Tags: #academic_papers, #Graph_to_Text, #Graph_Neural_Networks Read on: [[January 7th 2021]] URL: https://arxiv.org/abs/2012.15793
Main Contribution(s) Introduces the use of linearized graph inputs to pretrained [[Transformer]]s, and introduces several objectives.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Properties/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Properties/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ProphetNet-Predicting-Future-N-gram-for-Sequence-to-Sequence-Pre-training/</guid><description>Author(s): [[Yu Yan]], [[Weizhen Qi]], [[Yeyun Gong]], [[Dayiheng Liu]], [[Nan Duan]], [[Jiusheng Chen]], [[Ruofei Zhang]], [[Ming Zhou]] Tags: #summarization, #academic_papers Read on: [[June 2nd, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/PSECMAC-A-Novel-Self-Organizing-Multiresolution-Associative-Memory-Architecture/</guid><description>Author(s): [[Sintiani Teddy]], [[Chai Quek]], [[Edmun M-K Lai]] Tags: #Cerebellar_Model_Articulation_Controller_(CMAC), #academic_papers Read on: [[November 9th, 2020]] URL: https://ieeexplore.ieee.org/abstract/document/4469949/
Main Contribution(s) proposes the [[Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)]] that non uniformly allocates its computing cells Summary The [[Pseudo-Self Evolving CMAC (PSECMAC) (Architecture)]] is a single layered self-organizing multiresolution computation model of the cerebellum.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pseudo-Self-Evolving-CMAC-PSECMAC-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pyramid-Scene-Parsing-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pyramid-Scene-Parsing-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Pythagoras-Theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Pythagoras-Theorem/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Qian-Hangwei/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Qian-Hangwei/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Qifan-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Qifan-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Qiu-Ran/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Qiu-Ran/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/QM9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/QM9/</guid><description>QM9 is a dataset that provides geometric, energetic, electronic and thermodynamic properties of roughly 130K molecules with up to nine heavy atoms, yielding 12 regression tasks.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/QR-Factorization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/QR-Factorization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/QuAC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/QuAC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Quan-Du/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Quan-Du/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Quantitative-Color-Specification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Quantitative-Color-Specification/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/quantum-entropy-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/quantum-entropy-regularization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Question-Answering-Dialogue-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Question-Answering-Dialogue-Systems/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Qun-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Qun-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Quoc-V.-Le/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Quoc-V.-Le/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Quora-Question-Pairs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Quora-Question-Pairs/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RACE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RACE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Radko-Mesiar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Radko-Mesiar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Rafael-E.-Banchs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rafael-E.-Banchs/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Raluca-Ada-Popa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Raluca-Ada-Popa/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Random-Forest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Random-Forest/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Random-Walk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Random-Walk/</guid><description>Formally defined as $$p(v^{(t+1)}|v^{(t)}) = \begin{cases} \frac{1}{d(v^{(t)})},&amp;amp; \text{if }v^{(t+1)}\in N(v^{(t)})\ 0,&amp;amp;\text{otherwise} \end{cases}$$ where $d(v^{(t)})$ is the [[Degree]] of node $v^{t}$ and $N(v^{(t)})$ is the set of neighbours of node $v^{t}$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Randomly-Assign-Train-and-Track/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Randomly-Assign-Train-and-Track/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Raphael-Shu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Raphael-Shu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RATT-Leveraging-Unlabeled-Data-to-Guarantee-Generalization/</guid><description>Author(s): [[Saurabh Garg]], [[Sivaraman Balakrishnan]], [[J. Zico Kolter]], [[Zachary C. Lipton]] Tags: #academic_papers Read on: [[May 11th 2021]] URL: https://arxiv.org/abs/2105.00303</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ravenclaw-dialogue-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ravenclaw-dialogue-system/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Reading-List/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Reading-List/</guid><description>Theory and History [[Alan Turing - The Enigma]] [[Prediction Machines - The Simple Economics of Artificial Intelligence]] [[Gödel, Escher, Bach - an Eternal Golden Braid]] [[The Book of Why - The New Science of Cause and Effect]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Reasoning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Reasoning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Recall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Recall/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Receiver-Operating-Characteristics-ROC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Receiver-Operating-Characteristics-ROC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Receptive-Field-Regularization-Techniques-for-Audio-Classification-and-Tagging-with-Deep-Convolutional-Neural-Networks/</guid><description>Author(s): [[Khaled Koutini]], [[Hamid Eghbal-zadeh]], [[Gerhard Widmer]] Tags: #academic_papers Read on: [[01-Jun-2021]] URL: [2105.12395] Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Recipes-for-building-an-open-domain-chatbot-Generative-BST/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Recipes-for-building-an-open-domain-chatbot-Generative-BST/</guid><description>Author(s): [[Stephen Roller]], [[Emily Dinan]], [[Naman Goyal]], [[Da Ju]], [[Mary Williamson]], [[Yinhan Liu]], [[Jing Xu]], [[Myle Ott]], [[Kurt Shuster]], [[Eric Michael Smith]], [[Y-Lan Boureau]], [[Jason Weston]] Tags: #Conversational_Dialogue_Systems, #academic_papers, #Dialogue_Modelling, #Facebook_AI_Research Read on: [[June 23rd, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Reconstruction-Loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Reconstruction-Loss/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Recurrent-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Recurrent-Neural-Networks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Recursive-Graph-to-Graph-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Recursive-Graph-to-Graph-Transformer/</guid><description>[[Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency Parsing with Iterative Refinement]] ![[Pasted image 20210127170000.png]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Recursive-Non-Autoregressive-Graph-to-Graph-Transformer-for-Dependency-Parsing-with-Iterative-Refinement/</guid><description>Author(s): [[Alireza Mohammadshahi]], [[James Henderson]] Tags: #academic_papers Read on: [[January 13th 2021]] URL: https://arxiv.org/abs/2003.13118
Main Contribution(s) Proposes the [[Recursive Graph-to-Graph Transformer]] for [[Iterative Refinement]] of arbitary graphs and apply it to [[Dependency Parsing]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Rediet-Abebe/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rediet-Abebe/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Regina-Barzilay/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Regina-Barzilay/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Region-Proposal-Network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Region-Proposal-Network/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/REINFORCE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/REINFORCE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Reinforcement-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Reinforcement-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Relation-Extraction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Relation-Extraction/</guid><description>[[Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing]] The task of relation extraction is to discern whether a relation exists between two entities (i.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Relational-inductive-biases-deep-learning-and-graph-networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Relational-inductive-biases-deep-learning-and-graph-networks/</guid><description>Author(s): [[Peter W. Battaglia]], [[Jessica B. Hamrick]], [[Victor Bapst]], [[Alvaro Sanchez-Gonzalez]], [[Vinicius Zambaldi]], [[Mateusz Malinowski]], [[Andrea Tacchetti]], [[David Raposo]], [[Adam Santoro]], [[Ryan Faulkner]], [[Caglar Gulcehre]], [[Francis Song]], [[Andrew Ballard]], [[Justin Gilmer]], [[George Dahl]], [[Ashish Vaswani]], [[Kelsey Allen]], [[Charles Nash]], [[Victoria Langston]], [[Chris Dyer]], [[Nicolas Heess]], [[Daan Wierstra]], [[Pushmeet Kohli]], [[Matt Botvinick]], [[Oriol Vinyals]], [[Yujia Li]], [[Razvan Pascanu]] Tags: #academic_papers, #Graph_Neural_Networks , #critique Read on: [[December 16th 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Representation-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Representation-learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Research-Ideas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Research-Ideas/</guid><description>DCASE team
[[Receptive Field Regularization Techniques for Audio Classification and Tagging with Deep Convolutional Neural Networks]]. Apply filter damping to [[Audio Tagging]] [[Automated Audio Captioning|AAC]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Resource-Description-Framework/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Resource-Description-Framework/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Rethinking-the-Value-of-Transformer-Components/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rethinking-the-Value-of-Transformer-Components/</guid><description>Author(s): [[Wenxuan Wang]], [[Zhaopeng Tu]] Tags: #transformer, #critique, #ablation, #academic_papers Read on: [[November 27th, 2020]] URL: https://arxiv.org/abs/2011.03803
Main Contribution(s) Performs [[ablation]] on each transformer components to understand how critical it is to its performance.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/ReWatt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ReWatt/</guid><description>[[Black-box attack]]. Argues that deleting and adding edges are not unnoticeable enough. [[Rewiring]] operation proposed.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Rewinding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rewinding/</guid><description>In the research area of [[Lottery Ticket Hypothesis]], rewinding refers to rewinding the weights of a network being pruned to a certain iteration, rather than resetting the weights all together.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Rewiring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rewiring/</guid><description>A rewiring operation $a = (v_{fir}, v_{sec}, v_{thi})$ involves three nodes, where $vsec \in N(v_{fir})$ and $v_{thi} \in N^2(v_{fir})/N(v_{fir})$ with $N^2(v_{fir})$ denoting the 2-hop neighbors of the node $v_i$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Rewon-Child/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rewon-Child/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RGCN-Filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RGCN-Filter/</guid><description>Uses multivariate Gaussian distribution instead of plain vectors to model the hidden representation. It is built from the [[GCN-Filter]] and penalises nodes with larger variances with smaller attention scores.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Rich-Caruana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rich-Caruana/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Richard-Socher/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Richard-Socher/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/right-sidebar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/right-sidebar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RIPPLe/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RIPPLe/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RL-S2V/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RL-S2V/</guid><description>[[Black-box attack]] model trained using [[Reinforcement Learning]]. Only modified the graph structure, and not the node features. Attacking procedure is modeled as a Finite [[Markov Decision Process]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/RoBERTa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RoBERTa/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Roll-in-Policy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Roll-in-Policy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Romal-Thoppilan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Romal-Thoppilan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ronald-R.-Yager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ronald-R.-Yager/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/ROUGE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ROUGE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RUBER/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RUBER/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Rudolf-Kruse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rudolf-Kruse/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Rule-Based-Approaches/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Rule-Based-Approaches/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ruofei-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ruofei-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/RW-based-Sampler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/RW-based-Sampler/</guid><description>Uniformly samples a set of root nodes. Then from each root node, generate a [[Random Walk]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ryuichiro-Higashinaka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ryuichiro-Higashinaka/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/sacreBLEU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/sacreBLEU/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Saizheng-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Saizheng-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sam-McCandlish/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sam-McCandlish/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sample-and-Rank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sample-and-Rank/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sandhini-Agarwal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sandhini-Agarwal/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sanjiv-Kumar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sanjiv-Kumar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sanket-Shah/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sanket-Shah/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Santiago-Ontanon/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Santiago-Ontanon/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sashank-J.-Reddi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sashank-J.-Reddi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Saurabh-Saxena/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Saurabh-Saxena/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Saving-Lives-with-Interpretable-ML/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Saving-Lives-with-Interpretable-ML/</guid><description>Speaker(s): [[Rich Caruana]], [[Ankur Teredesai]], [[Marzyeh Ghassemi]] Tags: #seminar Held on: [[July 22nd, 2020]] URL: event page, youtube
Talk 1: Saving Lives with Interpretable ML, by [[Rich Caruana]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/ScenarioSA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/ScenarioSA/</guid><description> (Zhang et al., 2019) Sentiment classification</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Schema-Guided-Dialog-SGD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Schema-Guided-Dialog-SGD/</guid><description> (Rastogi et al., 2019)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Scott-Gray/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Scott-Gray/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Security-and-Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Security-and-Machine-Learning/</guid><description>Speaker(s): [[Emre Kiciman]], [[Aleksander Madry]], [[Dawn Song]], [[Jerry Li]] Tags: #seminar Held on: [[July 21st, 2020]] URL: event page, youtube</description></item><item><title/><link>https://aibrain.dhecloud.xyz/self-attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/self-attention/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Self-BLEU/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Self-BLEU/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Self-Organized-Feature-Mapping-SOFM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Self-Organized-Feature-Mapping-SOFM/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/self-similarity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/self-similarity/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Self-Supervised-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Self-Supervised-Learning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Self-Tuning-Regulator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Self-Tuning-Regulator/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Semantic-Memory-Duration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Semantic-Memory-Duration/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Semantic-Role-Labeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Semantic-Role-Labeling/</guid><description>[[Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing]] ![[Pasted image 20201212184411.png]] aims to discover the latent predicate argument structure of a sentence</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Semi-Autoregressive-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Semi-Autoregressive-Neural-Machine-Translation/</guid><description>Author(s): [[Chunqi Wang]], [[Ji Zhang]], [[Haiqing Chen]] Tags: #Non-Autoregressive, #Neural_Machine_Translation, #academic_papers Read on: [[August 23rd, 2020]] URL: https://arxiv.org/abs/1808.08583
Main Contribution(s) Introduces the [[Semi-Autoregressive Transformer (SAT)]] Summary [[Semi-Autoregressive Transformer (SAT)]] Uses a relaxed causal mask to perform more than a single token prediction.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Semi-Autoregressive-Transformer-SAT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Semi-Autoregressive-Transformer-SAT/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS/</guid><description>Author(s): [[Thomas N. Kipf]], [[Max Welling]] Tags: #academic_papers, #Graph_Neural_Networks Read on: [[December 14th 2020]] URL: https://arxiv.org/abs/1609.02907
Main Contribution(s) Proposes [[Graph Convolutional Network]], an efficient variant of [[Convolution Neural Network]]s which operate directly on graphs.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/seminar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/seminar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sensible-and-Specificity-Average-SSA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sensible-and-Specificity-Average-SSA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Senso-motoric-Maps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Senso-motoric-Maps/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sensory-Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sensory-Memory/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sepformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sepformer/</guid><description>[[ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION]] ![[Pasted image 20220205000313.png]] ![[Pasted image 20220205000323.png]] ![[Pasted image 20220205000444.png]]The encoder is basically a convolutional layer to learn the [[Short-Time Fourier Transform]] representation of the time input The masking network predicts the mask for each speaker (for reconstruction) The sepformer block is just a transformer block And the decoder is just a transposed convolutional layer to reconstruct the speeches</description></item><item><title/><link>https://aibrain.dhecloud.xyz/September-10th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-10th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-11th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-11th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-12th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-12th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-13th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-13th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-14th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-14th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-15th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-15th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-16th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-16th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-17th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-17th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-18th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-18th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-19th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-19th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-1st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-1st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-20th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-20th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-21st-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-21st-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-22nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-22nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-23rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-23rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-24th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-24th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-25th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-25th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-26th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-26th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-27th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-27th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-28th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-28th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-29th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-29th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-2nd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-2nd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-30th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-30th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-3rd-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-3rd-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-4th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-4th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-5th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-5th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-6th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-6th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-7th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-7th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-8th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-8th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/September-9th-2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/September-9th-2020/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sequence-Refinement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sequence-Refinement/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sequence-Level-Interpolation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sequence-Level-Interpolation/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SFX-restaurant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SFX-restaurant/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shallow-To-Deep-SDT-Algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shallow-To-Deep-SDT-Algorithm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shallow-to-Deep-Training-for-Neural-Machine-Translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shallow-to-Deep-Training-for-Neural-Machine-Translation/</guid><description>Author(s): [[Bei Li]], [[Ziyang Wang]], [[Hui Liu]], [[Yufan Jiang]], [[Quan Du]], [[Tong Xiao]], [[Huizhen Wang]], [[Jingbo Zhu]] Tags: #Neural_Machine_Translation, #academic_papers Read on: [[December 1st, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Shane-A.-Synder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shane-A.-Synder/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sheng-Zhao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sheng-Zhao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shikib-Mehri/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shikib-Mehri/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shiyu-Chang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shiyu-Chang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Short-Term-Memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Short-Term-Memory/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shortest-Path/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shortest-Path/</guid><description>between a pair of nodes is defined as $$p_{st}^{sp} = arg \min_{p\in P_{st}} |p|$$</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Shucong-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shucong-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shujian-Huang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shujian-Huang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Shuzi-Niu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Shuzi-Niu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Signed-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Signed-Graphs/</guid><description>![[Pasted image 20201203144245.png]] contains both positive and negative edges. An edge can only be either positive or negative. Therefore, there should be no overlap between the positive and negatives edges; ie $E^+ \cap E^- = \emptyset$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Sijia-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sijia-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sim-Kai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sim-Kai/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Similar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Similar/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Similarity-Invariant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Similarity-Invariant/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Similarity-Transform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Similarity-Transform/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Simon-See/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Simon-See/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Simple-Graph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Simple-Graph/</guid><description>denoted as $G={V,E}$ where $V = {v_1,&amp;hellip;,v_N}$ is a set of $|V|$ nodes and $E={e_1,&amp;hellip;,e_M}$ is a set of $M$ edges.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Singleton-Fuzzy-Rule-Based-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Singleton-Fuzzy-Rule-Based-Systems/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Singular-value-decomposition-and-QR-with-column-pivoting-methods-SVD-QR/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Singular-Value-Decomposition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Singular-Value-Decomposition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Singular-Values/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Singular-Values/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Singular/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Singular/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sintiani-Teddy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sintiani-Teddy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Siqi-Sun/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Siqi-Sun/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Site-wide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Site-wide/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Small-World-Graphs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Small-World-Graphs/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SNE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SNE/</guid><description> Stochastic Neighbor Embedding</description></item><item><title/><link>https://aibrain.dhecloud.xyz/SNIPS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SNIPS/</guid><description> Snips NLU benchmark (Coucke et al., 2018)</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Sobel-Gradient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sobel-Gradient/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Social-Good/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Social-Good/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Softmax/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Softmax/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Solon-Barocas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Solon-Barocas/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Somatosensoric-Maps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Somatosensoric-Maps/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sophie-Rosset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sophie-Rosset/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SOUND-CONTEXT-CLASSIFICATION-BASING-ON-JOINT-LEARNING-MODEL-AND-MULTI-SPECTROGRAM-FEATURES/</guid><description>Author(s): [[Dat Ngo]], [[Hao Hoang]], [[Anh Nguyen]], [[Tien Ly]], [[Lam Pham]] Tags: #academic_papers Read on: [[31-May-2021]] URL: [2005.12779] Sound Context Classification Basing on Join Learning Model and Multi-Spectrogram Features (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Span/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Span/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spanning-Tree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spanning-Tree/</guid><description>Taken from here A spanning tree is a subset of Graph G, which has all the vertices covered with minimum possible number of edges.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Spatial-Filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spatial-Filtering/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spatio-Temporal-Attention-Pooling-for-Audio-Scene-Classification/</guid><description>Author(s): [[Huy Phan]], [[Oliver Y. Chen]], [[Lam Pham]], [[Philipp Koch]], [[Maarten De Vos]], [[Ian McLoughlin]], [[Alfred Mertins]] Tags: #academic_papers Read on: [[01-Jun-2021]] URL: [1904.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Speaker-Sensitive-Response-Evaluation-Model-SSREM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Speaker-Sensitive-Response-Evaluation-Model-SSREM/</guid><description>Author(s): [[JinYeong Bak]], [[Alice Oh]] Tags: #Evaluation_Metric, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 15th, 2020]] URL: https://arxiv.org/abs/2006.07015
Main Contribution(s) Propose an automatic evaluation model to judge generated conversations ELI5 SSREM uses speaker sensitive samples to output a score for generated conversational dialogue Summary Speaker utterances are categorized into: 1.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Speakers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Speakers/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Decomposition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Decomposition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Graph-Convolutions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Graph-Convolutions/</guid><description>[[SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS]], [[Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering]] [[Spectral Graph]] [[Convolution]] is done with a filter $g = \text{diag}(\theta)$ where $\theta \in \mathbb{R}^N$ in the fourier domain: $$g_\theta \star x = U g_\theta U^Tx $$ where $U$ is the matrix of [[Eigenvector]]s of the normalized graph [[Laplacian Matrix]] $L=I_N - D^{-\frac{1}{2}}AD^{-\frac{1}{2}} = U \Lambda U^T$, with a diagonal matrix of its eigenvalues $\Lambda$ and $U^Tx$ being the [[Graph Fourier Transform]] of $x$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Graph-Theory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Graph-Theory/</guid><description>not to be confused with [[Spectral Theorem]] which is for non-graph [[Linear Algebra]]
studies the properties of a graph through analyzing the [[Eigenvalue]] and [[Eigenvector]] of its [[Laplacian Matrix]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Graph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Graph/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Power-Distribution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Power-Distribution/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectral-Theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectral-Theorem/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spectrum/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spectrum/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Speech-Recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Speech-Recognition/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Speech-XLNet-Unsupervised-Acoustic-Model-Pretraining-For-Self-Attention-Networks/</guid><description>Author(s): [[Xingchen Song]], [[Guangsen Wang]], [[Yiheng Huang]], [[Zhiyong Wu]], [[Dan Su]], [[Helen Meng]] Tags: #academic_papers, #speech_representations Read on: [[May 1st 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/speech/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/speech/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spoken-Moments-Learning-Joint-Audio-Visual-Representations-from-Video-Descriptions/</guid><description>Author(s): [[Mathew Monfort]], [[SouYong Jin]], [[Alexander Liu]], [[David Harwath]], [[Rogerio Feris]], [[James Glass]], [[Aude Oliva]] Tags: #academic_papers, #datasets Read on: [[May 18th 2021]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Spoken-Moments-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Spoken-Moments-dataset/</guid><description>[[Spoken Moments - Learning Joint Audio-Visual Representations from Video Descriptions]] ![[Pasted image 20210518152457.png]] 500k contains, randomly chosen from the [[Multi-Moments in Time]] train set, and 10k videoes from the validation set.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/SQuADv2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SQuADv2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Srinadh-Bhojanapalli/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Srinadh-Bhojanapalli/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SST-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SST-2/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Standard-Basis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Standard-Basis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Starplots/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Starplots/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stavros-Volos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stavros-Volos/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stefan-Ultes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stefan-Ultes/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stephen-Casper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stephen-Casper/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stephen-Roller/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stephen-Roller/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Steve-Renals/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Steve-Renals/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stochastic-Gradient-Descent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stochastic-Gradient-Descent/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/structural-causal-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/structural-causal-model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Structural-Message-Passing-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Structural-Message-Passing-Networks/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Stuart-Shieber/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Stuart-Shieber/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Su-Lin-Blodgett/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Su-Lin-Blodgett/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Subgraph-wise-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Subgraph-wise-Sampling/</guid><description>sample [[Subgraph]]s for node representation and model training</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Subgraph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Subgraph/</guid><description>Given a graph $G = {V, E}$, a subset formed with a subset of nodes $V^\prime \subset V$ and subset of edges $E^\prime \subset E$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Subject-Vector-Machines/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Subject-Vector-Machines/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SubTle-Corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SubTle-Corpus/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Subtractive-Color-Mixing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Subtractive-Color-Mixing/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Suchi-Saria/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Suchi-Saria/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/summarization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/summarization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Sunayana-Sitaram/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Sunayana-Sitaram/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Super-Resolution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Super-Resolution/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SuperGLUE-Benchmark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SuperGLUE-Benchmark/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Survey-on-Evaluation-Methods-for-Dialogue-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Survey-on-Evaluation-Methods-for-Dialogue-Systems/</guid><description>Author(s): [[Jan Deriu]], [[Alvaro Rodrigo]], [[Arantxa Otegi]], [[Guillermo Echegoyen]], [[Sophie Rosset]], [[Eneko Agirre]], [[Mark Cieliebak]] Tags: #Dialogue_Modelling, #Conversational_Dialogue_Systems, #survey, #Evaluation_Metric, #Task_Oriented_Dialogue_Systems, #Question-Answering_Dialogue_Systems, #academic_papers Read on: [[June 19th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/survey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/survey/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Susan-Athey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Susan-Athey/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Susan-Dumais/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Susan-Dumais/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Switchable-Normalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Switchable-Normalization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Switchboard-Coherence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Switchboard-Coherence/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/SwitchBoard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/SwitchBoard/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Symmetric/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Symmetric/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Syntax-GNN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Syntax-GNN/</guid><description>[[Do Syntax Trees Help Pre-trained Transformers Extract Information]] ![[Pasted image 20210105184339.png]] The [[Multi-Head Self-Attention]] in the [[Transformer]] encoder is replaced by an [[Graph Attention]] mechanism.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/T-conorm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/T-conorm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/T-norm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/T-norm/</guid><description>The standard [[T-norm]] is non-decreasing and commutative, and only lower semi continuous if and only if it is left-continuous in the first component Types [[Gödel T-norm]] $$T_{min} (a,b) = min{a,b}$$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/t-SNE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/t-SNE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TAC-Knowledge-Base-Population/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TAC-Knowledge-Base-Population/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tag-Styles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tag-Styles/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tags/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Takagi-Sugeno-Kang-type-Fuzzy-Rule-Based-Systems-TSK-type-FRBSs/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Takeaways/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Takeaways/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tam%C3%A1s-Szab%C3%B3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tam%C3%A1s-Szab%C3%B3/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tangled-up-in-BLEU-Reevaluating-the-Evaluation-of-Automatic-Machine-Translation-Evaluation-Metrics/</guid><description>Author(s): [[Nitika Mathur]], [[Timothy Baldwin]], [[Trevor Cohn]] Tags: #critique, #Evaluation_Metric, #academic_papers Read on: [[June 17th, 2020]] URL: http://arxiv.org/abs/2006.06264
Main Contribution(s) Show that current methods for judging metrics are highly sensitive to the translations used for assessments, particularly the presence of outliers Propose a pair-wise system ranking which allows quantification of [[Type I Errors]] and [[Type II Errors]] Summary [[WMT]] has a method using [[Pearson&amp;rsquo;s Correlation Coefficient]] for measuring how well automatic metrics match with human judgments of translation quality.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Tao-Qin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tao-Qin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Task-Oriented-Dialogue-Systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Task-Oriented-Dialogue-Systems/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Task-Regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Task-Regularization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Task-Success-Rate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Task-Success-Rate/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Telecoupling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Telecoupling/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Temporal-Random-Walk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Temporal-Random-Walk/</guid><description>a [[Random Walk]] with increasing timestamps.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/TER/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TER/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/test/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tetsuro-Takahashi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tetsuro-Takahashi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Text-to-Speech/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Text-to-Speech/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TEXT-TO-AUDIO-GROUNDING-BUILDING-CORRESPONDENCE-BETWEEN-CAPTIONS-AND-SOUND-EVENTS/</guid><description>Author(s): [[Xuenan Xu]], [[Heinrich Dinkel]], [[Mengyue Wu]], [[Kai Yu]] Tags: #academic_papers, #datasets, #text_to_audio Read on: [[May 3rd 2021]] URL: https://arxiv.org/abs/2102.11474</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Text-To-Text-Transfer-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Text-To-Text-Transfer-Transformer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Texture-Synthesis-by-Non-parametric-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Texture-Synthesis-by-Non-parametric-Sampling/</guid><description>Author(s): [[Alexei A. Efros]], [[Thomas K. Leung]] Tags: #Computer_Vision, #Texture_Synthesis, #academic_papers Read on: [[September 24th, 2020]] URL: https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/efros-iccv99.pdf
Main Contribution(s) Introduces a non-parametric method for texture synthesis Summary Applies the idea of n-gram from text to texture.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Texture-Synthesis-Using-Convolutional-Neural-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Texture-Synthesis-Using-Convolutional-Neural-Networks/</guid><description>Author(s): [[Leon A. Gatys]], [[Alexander S. Ecker]], [[Matthias Bethge]] Tags: #academic_papers Read on: [[October 20th, 2020]] URL: https://arxiv.org/abs/1505.07376
Main Contribution(s) Uses [[VGG19 (Architecture)]] to generate [[Gram-matrix]] representation of input textures Summary Learning Gaps/Thoughts</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Texture-Synthesis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Texture-Synthesis/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TF-IDF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TF-IDF/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/THE-BENEFIT-OF-TEMPORALLY-STRONG-LABELS-IN-AUDIO-EVENT-CLASSIFICATION/</guid><description>Author(s): [[Shawn Hershey]], [[Daniel P W Ellis]], [[Eduardo Fonseca]], [[Aren Jansen]], [[Caroline Liu]], [[R Channing Moore]], [[Manoj Plakal]] Tags: #academic_papers, #audio_tagging Read on: [[07-Jun-2021]] URL: [2105.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/The-Book-of-Why-The-New-Science-of-Cause-and-Effect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/The-Book-of-Why-The-New-Science-of-Cause-and-Effect/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/The-Concept-of-a-Linguistic-Variable-and-its-Application-to-Approximate-Reasoning/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/The-Dialogue-Breakdown-Detection-Challenge-Task-description-Datasets-and-Evaluation-Metrics/</guid><description>Author(s): [[Ryuichiro Higashinaka]], [[Kotaro Funakoshi]], [[Yuka Kobayashi]], [[Michimasa Inaba]] Tags: #datasets, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 20th, 2020]] URL: https://www.aclweb.org/anthology/L16-1502/</description></item><item><title/><link>https://aibrain.dhecloud.xyz/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/The-Lottery-Ticket-Hypothesis-for-Pre-trained-BERT-Networks/</guid><description>Author(s): [[Tianlong Chen]], [[Jonathan Frankle]], [[Shiyu Chang]], [[Sijia Liu]], [[Yang Zhang]], [[Zhangyang Wang]], [[Michael Carbin]] Tags: #meta-learning, #BERT, #Lottery_Ticket_Hypothesis, #academic_papers Read on: [[July 30th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/The-Unreasonable-Volatility-of-Neural-Machine-Translation-Models/</guid><description>Author(s): [[Marzieh Fadaee]], [[Christof Monz]] Tags: #critique, #Neural_Machine_Translation, #academic_papers Read on: [[May 27th, 2020]] URL: https://arxiv.org/abs/2005.12398
Main Contribution(s) Checks for volatility of NMT models including RNN Provides ways of noisy text generation ELI5 You should be able to understand the same sentence even with a few grammar mistakes.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Thomas-Dietterich/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Thomas-Dietterich/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Thomas-K.-Leung/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Thomas-K.-Leung/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tianlong-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tianlong-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tie-Yan-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tie-Yan-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Timothy-Baldwin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Timothy-Baldwin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tom-B.-Brown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tom-B.-Brown/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tom-Henighan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tom-Henighan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tong-Xiao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tong-Xiao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tovly-Deutsch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tovly-Deutsch/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Towards-a-Human-like-Open-Domain-Chatbot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Towards-a-Human-like-Open-Domain-Chatbot/</guid><description>Author(s): [[Daniel Adiwardana]], [[Minh-Thang Luong]], [[David R. So]], [[Jamie Hall]], [[Noah Fiedel]], [[Romal Thoppilan]], [[Zi Yang]], [[Apoorv Kulshreshtha]], [[Gaurav Nemade]], [[Yifeng Lu]], [[Quoc V.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Towards-Empathetic-Open-domain-Conversation-Models-a-New-Benchmark-and-Dataset/</guid><description>Author(s): [[Hannah Rashkin]], [[Eric Michael Smith]], [[Margaret Li]], [[Y-Lan Boureau]] Tags: #Conversational_Dialogue_Systems, #Evaluation_Metric, #datasets., #academic_papers Read on: [[July 16th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Towards-Unified-Dialogue-System-Evaluation-A-Comprehensive-Analysis-of-Current-Evaluation-Protocols/</guid><description>Author(s): Tags: #critique, #survey, #Conversational_Dialogue_Systems, #Evaluation_Metric, #academic_papers Read on: [[June 22nd, 2020]] URL: http://arxiv.org/abs/2006.06110
Main Contribution(s) Survey 20 evaluation protocols from the last 20 years Summary Evaluation metrics need to be a close approximation of human judgements, but unfortunately often correlate weakly with human judgements.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Trace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Trace/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TRACKE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TRACKE/</guid><description>[[A Transformer-based Audio Captioning Model with Keyword Estimation]] ![[Pasted image 20210209175637.png]] The bottleneck feature of [[VGGish]] is used for audio embedding, and [[FastText]] for caption-word and keyword embedding.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Trail/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Trail/</guid><description>a [[Walk]] whose edges are distinct.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/TransE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TransE/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] ![[Pasted image 20201228192057.png]]Used to make [[Knowledge Graphs Embeddings]]. Uses k-dimensional vectors to represent both entities and relationships.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Transformer-XL/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Transformer-XL/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/transformer/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Translational-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Translational-Models/</guid><description>[[Knowledge Graph Embeddings and Explainable AI]] Aim to learn the translation from the head entity to the tail entity. Have advantage of having a concise definition and getting good performance.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Transportability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Transportability/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TREC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TREC/</guid><description> (Li and Roth, 2002) Question classification dataset</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Tree-LSTM/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tree-LSTM/</guid><description>[[Deep Learning On Graphs Chapter 9 - Beyond GNNs, More Deep Models on Graphs]] It is assumed the information flows from the first node to the last node in the sequence.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Trevor-Cohn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Trevor-Cohn/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TriPy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TriPy/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tristimulus-Color-Theory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tristimulus-Color-Theory/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tristimulus-Values/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tristimulus-Values/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/TriviaQA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/TriviaQA/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Trusted-Execution-Environments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Trusted-Execution-Environments/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Tsung-Hsien-Wen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Tsung-Hsien-Wen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Twitter-Conversation-Corpus-Bak-and-Oh-2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Twitter-Conversation-Corpus-Bak-and-Oh-2019/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Type-I-Errors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Type-I-Errors/</guid><description> False positive</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Type-II-Errors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Type-II-Errors/</guid><description> False negative</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Ubuntu-Dialogue-Corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ubuntu-Dialogue-Corpus/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/UNDERSTANDING-KNOWLEDGE-DISTILLATION-IN-NON-AUTOREGRESSIVE-MACHINE-TRANSLATION/</guid><description>Author(s): [[Chunting Zhou]], [[Graham Neubig]], [[Jiatao Gu]] Tags: #academic_papers, #Non-Autoregressive, #Neural_Machine_Translation Read on: [[August 13th, 2020]] URL: https://arxiv.org/abs/1911.02727
Main Contribution(s) Designs systematic experiments to investigate why knowledge distillation is crucial for NAT training Propose two metrics, [[Complexity]] and [[Faithfulness]] to evaluate datasets to determine the extent of its modality.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/UNI-SNE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/UNI-SNE/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Unit-Vector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unit-Vector/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Unlikelihood-Training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unlikelihood-Training/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unsupervised-Audio-Caption-Aligning-Learns-Correspondences-between-Individual-Sound-Events-and-Textual-Phrases/</guid><description>Author(s): [[Huang Xie]], [[Okko Räsänen]], [[Konstantinos Drossos]], [[Tuomas Virtanen]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[05-Jan-2022]] URL: https://arxiv.org/abs/2110.02939
Main Contribution(s) Problem: Investigate unsupervised learning of correspondences between sound events and textual phrases Solution: Audio clip is split into a sequence of frames and each frame is represented by a sequence of words</description></item><item><title/><link>https://aibrain.dhecloud.xyz/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/UNSUPERVISED-DISCRIMINATIVE-LEARNING-OF-SOUNDS-FOR-AUDIO-EVENT-CLASSIFICATION/</guid><description>Author(s): [[Sascha Hornauer]], [[Ke Li]], [[Stella X. Yu]], [[Shabnam Ghaffarzadegan]], [[Liu Ren]] Tags: #academic_papers, #audio_tagging Read on: [[07-Jun-2021]] URL: [2105.09279] Unsupervised Discriminative Learning of Sounds for Audio Event Classification (arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Unsupervised-Discriminative-Learning-of-Sounds/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unsupervised-Discriminative-Learning-of-Sounds/</guid><description>[[UNSUPERVISED DISCRIMINATIVE LEARNING OF SOUNDS FOR AUDIO EVENT CLASSIFICATION]] ![[Pasted image 20210607141938.png]] Power spectrograms created via [[Short-Time Fourier Transform]] are used as input.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unsupervised-Evaluation-of-Interactive-Dialog-with-DialoGPT/</guid><description>Author(s): [[Shikib Mehri]], [[Maxine Eskenazi]] Tags: #Evaluation_Metric, #datasets, #Conversational_Dialogue_Systems, #academic_papers Read on: [[June 25th, 2020]] URL: https://arxiv.org/abs/2006.12719
Main Contribution(s) Propose the [[FED metric]] which does not rely on a ground truth response Prpose the [[FED dataset]] which is constructed by annotating a set of human-system and human-human conversations with eighteen fine-grained dialog quality Summary [[FED metric]] leverages a massively pretrained model, [[DialoGPT]], and performs [[Partial Scoring]] to obtain probabilities of follow up utterances.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Unsupervised/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Unsupervised/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/URBAN-SOUND-CLASSIFICATION-USING-CONVOLUTIONAL-NEURAL-NETWORKS-FOR-DCASE-2020-CHALLENGE/</guid><description>Author(s): [[Itxasne Diez Gaspon]], [[Peio Gonzalez]], [[Ibon Saratxaga]] Tags: #academic_papers, #dcase2020_task5, #audio_tagging Read on: [[April 27th 2021]] URL: http://dcase.community/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results#technical-reports
Main Contribution(s) Refer to [[INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING]], [[Multisystem fusion model based on tag relationship]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/URBAN-SOUND-TAGGING-USING-MULTI-CHANNEL-AUDIO-FEATURE-WITH-CONVOLUTIONAL-NEURAL-NETWORKS/</guid><description>Author(s): [[Jaehun Kim]] Tags: #academic_papers, #dcase2020_task5, #audio_tagging Read on: [[April 27th 2021]] URL: http://dcase.community/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results#technical-reports
Main Contribution(s) Proposes a multi-channel audio feature using [[EfficientNet]] and median-filtering [[Harmonic Percussive Source Separation]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Uri-Shaham/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Uri-Shaham/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Variational-Auto-Encoder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Variational-Auto-Encoder/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Variational-Deep-Reinforcement-Learning-VariBad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Variational-Deep-Reinforcement-Learning-VariBad/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/VGG19-Architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/VGG19-Architecture/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Vicinal-Risk-Minimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Vicinal-Risk-Minimization/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Victor-O.K.-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Victor-O.K.-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Vikas-Joshi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Vikas-Joshi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Virtual-Reality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Virtual-Reality/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Visualizing-Data-using-t-SNE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Visualizing-Data-using-t-SNE/</guid><description>Author(s): [[Laurens van der Maaten]], [[Geoffrey Hinton]] Tags: #Machine_Learning, #academic_papers Read on: [[July 6th, 2020]] URL: http://www.cs.toronto.edu/~hinton/absps/tsne.pdf
Main Contribution(s) Present a technique called [[t-SNE]] which visualizes high dimensional data in a 2 or 3 dimensional map Summary [[t-SNE]] allows for an more accurate 2/3-dimensional mapping Learning Gaps [[SNE]] Converts high dimensional Euclidean distance between datapoints into conditional probabilities that represent similarities.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Voted-Appropriateness/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Voted-Appropriateness/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/VQ-WAV2VEC-SELF-SUPERVISED-LEARNING-OF-DISCRETE-SPEECH-REPRESENTATIONS/</guid><description>Author(s): [[Alexei Baevski]], [[Steffen Schneider]], [[Michael Auli]] Tags: #academic_papers, #self_supervised_learning, #speech_representations Read on: [[April 30th 2021]] URL: https://arxiv.org/abs/1910.05453
Main Contribution(s) Problem: Well performing NLP algorithms cannot be applied to speech data because of the continuous nature of speech data Solution: Discretize speech representations using</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Walk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Walk/</guid><description>An alternating sequence of nodes and edges, starting with a node and ending with a node where each edge is incident with the nodes immediately preceding and following it</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Wall-Street-Journal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Wall-Street-Journal/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WAT2017-Small-NMT-En-Ja/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WAT2017-Small-NMT-En-Ja/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/wav2vec-2.0-A-Framework-for-Self-Supervised-Learning-of-Speech-Representations/</guid><description>Author(s): [[Alexei Baevski]], [[Henry Zhou]], [[Abdelrahman Mohamed]], [[Michael Auli]] Tags: #academic_papers, #self_supervised_learning Read on: [[April 27th 2021]] URL: https://arxiv.org/abs/2006.11477
Main Contribution(s) Problem: Speech recognition systems require thousands of hours of transcribed speech to reach acceptable performance.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WaveTransformer-A-Novel-Architecture-for-Audio-Captioning-Based-on-Learning-Temporal-and-Time-Frequency-Information/</guid><description>Author(s): [[An Tran]], [[Konstantinos Drossos]], [[Tuomas Virtanen]] Tags: #academic_papers, #Automated_Audio_Captioning Read on: [[February 9th 2021]] URL: https://arxiv.org/abs/2010.11098
Main Contribution(s) Proposes the [[WaveTransformer]] for [[Automated Audio Captioning]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/WaveTransformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WaveTransformer/</guid><description>[[WaveTransformer - A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information]] ![[Pasted image 20210209171421.png]] Encoder consists of three learnable processes $E_{temp}(\cdot)$, $E_{tf}(\cdot)$, $E_{merge}(\cdot)$.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Weak-Agreement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weak-Agreement/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summaries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summaries/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-010620-210620/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-010620-210620/</guid><description>Start-End Date: [[June 1st, 2020]] - [[June 21st, 2020]] Written on: [[June 21st, 2020]] Tags: #Week_Summaries
Week in Review [[Is this Dialogue Coherent - Learning from Dialogue Acts and Entities]] [[The Dialogue Breakdown Detection Challenge - Task description, Datasets, and Evaluation Metrics]] [[Learning not to Discriminate - Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition]] [[Tangled up in BLEU - Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics]] [[ProphetNet - Predicting Future N-gram for Sequence-to-Sequence Pre-training]] [[Language Models are Few-Shot Learners]] [[Evaluating dialogue breakdown detection in chat-oriented dialogue systems]] [[Dialogue breakdown detection using BERT with traditional dialogue features]] [[Overview of the Dialogue Breakdown Detection Challenge 4]] [[Survey on Evaluation Methods for Dialogue Systems]] [[MultiWOZ &amp;ndash; A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling]] [[YiSi - a Unified Semantic MT Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources]] [[Misinformation has High Perplexity]] [[Probing Neural Dialog Models for Conversational Understanding]] [[Speaker Sensitive Response Evaluation Model (SSREM)]] [[Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation]] [[Language Models are Few-Shot Learners]] Other than throwing more data and compute at a model, [[OpenAI]] provides some insights into [[meta-learning]] and single/zero shot learning.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-021120-221120/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-021120-221120/</guid><description>Start-End Date: [[November 2nd, 2020]] - [[November 22nd, 2020]] Written on: [[November 22nd, 2020]] Tags: #Week_Summaries
Week in Review [[PSECMAC - A Novel Self-Organizing Multiresolution Associative Memory Architecture]] [[Kernel CMAC With Improved Capability]] [[Learning Convergence of CMAC Technique]] [[Improved MCMAC with Momentum, Neighborhood, and Averaged Trapezoidal Output]] [[Hierarchically Clustered Adaptive Quantization CMAC and Its Learning Convergence]] [[Generalizing CMAC Architecture and Training]] [[Comparison of Convergence Properties of CMAC Neural Network and Traditional Adaptive Controllers]] [[Comparison of CMAC Architectures for Neural Network Based Control]] CMAC month!</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-030820-160820/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-030820-160820/</guid><description>Start-End Date: [[August 3rd, 2020]] Written on: [[August 16th, 2020]] Tags: #Week_Summaries
Week in Review [[Imputer - Sequence Modelling via Imputation and Dynamic Programming]] [[Big Bird - Transformers for Longer Sequences]] [[Non-Autoregressive Machine Translation with Latent Alignments]] [[Non-Autoregressive Transformer by Position Learning]] [[NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION]] [[UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION]] [[Discovering and Categorizing Language Biases in Reddit]] [[Defining and Evaluating Fair Natural Language Generation]] Paper of the Week [[UNDERSTANDING KNOWLEDGE DISTILLATION IN NON-AUTOREGRESSIVE MACHINE TRANSLATION]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-060720-190720/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-060720-190720/</guid><description>Start-End Date: [[July 6th, 2020]] - [[July 19th, 2020]] Written on: [[July 19th, 2020]] Tags: #Week_Summaries
Week in Review [[Personalizing Dialogue Agents - I have a dog, do you have pets too]] [[DialoGPT - Large-Scale Generative Pre-training for Conversational Response Generation]] [[Towards Empathetic Open-domain Conversation Models - a New Benchmark and Dataset]] [[DailyDialog - A Manually Labelled Multi-turn Dialogue Dataset]] [[Modeling Local Coherence - An Entity-Based Approach]] [[Visualizing Data using t-SNE]] Paper of the Week None</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-071220-131220/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-071220-131220/</guid><description>Start-End Date: [[December 7th 2020]] - [[December 13th 2020]] Written on: [[December 13th 2020]] Tags: #Week_Summaries
Week in Review [[Document Graph for Neural Machine Translation]] Paper of the Week Honorable Mentions Shame and Blame</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-141220-271220/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-141220-271220/</guid><description>Start-End Date: [[December 14th 2020]] - [[December 27th 2020]] Written on: [[December 27th 2020]] Tags: #Week_Summaries
Week in Review [[Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering]] [[Relational inductive biases, deep learning, and graph networks]] [[Graph-Aware Transformer - Is Attention All Graphs Need]] [[LANGUAGE MODELS ARE OPEN KNOWLEDGE GRAPHS]] [[Graphite - Iterative Generative Modeling of Graphs]] [[GRAPH ATTENTION NETWORKS (Paper)]] [[A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation]] Week papers focus on #Graph_Neural_Networks</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-170820-230820/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-170820-230820/</guid><description>Start-End Date: [[August 17th, 2020]] - [[August 23rd, 2020]] Written on: [[August 23rd, 2020]] Tags: #Week_Summaries
Week in Review [[(Paper) Levenshtein Transformer]] [[Mask-Predict - Parallel Decoding of Conditional Masked Language Models]] [[Multilingual KERMIT - It’s Not Easy Being Generative]] [[KERMIT - Generative Insertion-Based Modeling for Sequences]] [[Insertion Transformer - Flexible Sequence Generation via Insertion Operations]] [[Semi-Autoregressive Neural Machine Translation]] Paper of the Week [[Mask-Predict]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-180520-240520/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-180520-240520/</guid><description>Start-End Date: [[May 18th, 2020]] - [[May 24th, 2020]] Written on: [[May 24th, 2020]] Tags: #Week_Summaries
Week in Review [[Breaking the Softmax Bottleneck - A High-Rank RNN Language Model]] (not in notes) [[Poor Man&amp;rsquo;s BERT - Smaller and Faster Transformer Models]] [[Semi Autoregressive Neural Machine Translation]] [[A Study of Non-autoregressive Model for Sequence Generation]] [[Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation]] [[Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-200720-020820/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-200720-020820/</guid><description>Start-End Date: [[July 20th, 2020]] - [[August 2nd, 2020]] Written on: [[August 2nd, 2020]] Tags: #Week_Summaries
Week in Review [[Do Transformers Need Deep Long-Range Memory]] [[The Lottery Ticket Hypothesis for Pre-trained BERT Networks]] Paper of the Week [[The Lottery Ticket Hypothesis for Pre-trained BERT Networks]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-210920-011120/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-210920-011120/</guid><description>Start-End Date: [[September 21st, 2020]] - [[November 1st, 2020]] Written on: [[November 1st, 2020]] Tags: #Week_Summaries
Week in Review [[NEFCLASS - A Neuro-Fuzzy approach for the classification of data (Paper)]] [[Interpretability Improvements to Find the Balance Interpretability-Accuracy in Fuzzy Modeling - An Overview (2003)]] [[HEDGE ALGEBRAS - AN ALGEBRAIC APPROACH TO STRUCTURE OF SETS OF LINGUISTIC TRUTH VALUES]] [[Generative Pretraining from Pixels]] [[Texture Synthesis Using Convolutional Neural Networks]] [[Image Quilting for Texture Synthesis and Transfer]] [[Implementing fuzzy logic controllers using a neural network framework (1990)]] [[Fuzzy Sets (1965)]] [[Color Indexing]] [[Face Recognition Using Eigenfaces]] [[Mean Shift Analysis and Applications]] [[Texture Synthesis by Non-parametric Sampling]] [[Compositional rule of inference as an analogical scheme]] Paper of the Week</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-220620-050720/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-220620-050720/</guid><description>Start-End Date: [[June 22nd, 2020]] - [[July 5th, 2020]] Written on: [[July 5th, 2020]] Tags: #Week_Summaries
Week in Review [[ACUTE-EVAL - Improved Dialogue Evaluation with Optimized Questions and Multi-turn Comparisons]] [[Towards Unified Dialogue System Evaluation - A Comprehensive Analysis of Current Evaluation Protocols]] [[Unsupervised Evaluation of Interactive Dialog with DialoGPT]] [[Recipes for building an open domain chatbot (Generative BST)]] [[Towards a Human-like Open-Domain Chatbot]] [[Overview of the dialogue breakdown detection challenge 3]] [[(SPOLIN) Grounding Conversations with Improvised Dialogues]] Paper of the Week [[Recipes for building an open domain chatbot (Generative BST)]] Honorable Mentions [[Towards a Human-like Open-Domain Chatbot]] Shame and Blame Honestly, all the DBDC papers will kinda badly written</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-231120-291120/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-231120-291120/</guid><description>Start-End Date: [[November 23rd, 2020]] - [[November 29th, 2020]] Written on: [[November 29th, 2020]] Tags: #Week_Summaries
Week in Review [[What Can We Do to Improve Peer Review in NLP]] [[Rethinking the Value of Transformer Components]] [[FROM UNSUPERVISED MACHINE TRANSLATION TO ADVERSARIAL TEXT GENERATION]] [[Catch the ”Tails” of BERT]] [[Context-Aware Cross-Attention for Non-Autoregressive Translation]] Paper of the Week [[Rethinking the Value of Transformer Components]].</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-240820-300820/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-240820-300820/</guid><description>Start-End Date: Written on: Tags: #Week_Summaries
Week in Review [[GLAT - Glancing Transformer for Non-Autoregressive Neural Machine Translation]] [[FlowSeq - Non-Autoregressive Conditional Sequence Generation with Generative Flow]] [[Improving Non-autoregressive Neural Machine Translation with Monolingual Data]] [[Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information]] [[A Study of Non-autoregressive Model for Sequence Generation]] [[Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning]] [[Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation]] [[Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation]] Paper of the Week None</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-250520-310520/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-250520-310520/</guid><description>Start-End Date: [[May 25th, 2020]] - [[May 31st, 2020]] Written on: [[May 31st, 2020]] Tags: #Week_Summaries
Week in Review [[Improving Non-autoregressive Neural Machine Translation with Monolingual Data]] [[Faster Transformer Decoding - N-gram Masked Self-Attention]] [[The Unreasonable Volatility of Neural Machine Translation Models]] [[Are Transformers universal approximators of sequence-to-sequence functions]] [[When Can Self-Attention Be Replaced by Feed Forward Layers]] [[Language (Technology) is Power - A Critical Survey of Bias in NLP]] Paper of the Week [[Language (Technology) is Power - A Critical Survey of Bias in NLP]] Surprisingly informative paper which touches on the shortcomings papers analyzing &amp;lsquo;bias&amp;rsquo; Honorable mentions [[When Can Self-Attention Be Replaced by Feed Forward Layers]] A slightly different approach from others which usually focus on pruning, distillation.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-301120-061220/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-301120-061220/</guid><description>Start-End Date: [[November 30th, 2020]] - [[December 6th 2020]] Written on: [[December 7th 2020]] Tags: #Week_Summaries
Week in Review [[LANGUAGE MODEL IS ALL YOU NEED - NATURAL LANGUAGE UNDERSTANDING AS QUESTION ANSWERING]] [[Shallow-to-Deep Training for Neural Machine Translation]] [[Contextual BERT - Conditioning the Language Model Using a Global State]] [[Efficient Inference For Neural Machine Translation]] Paper of the Week None</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Week-Summary-310820-200920/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Week-Summary-310820-200920/</guid><description>Start-End Date: [[August 30th, 2020]] - [[September 20th, 2020]] Written on: [[September 20th, 2020]] Tags: #Week_Summaries
Week in Review [[Neural Machine Translation without Embeddings]] [[Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation]] Paper of the Week</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Weight-Poisoning-Attacks-on-Pre-trained-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weight-Poisoning-Attacks-on-Pre-trained-Model/</guid><description>Author(s): [[Keita Kurita]], [[Paul Michel]], [[Graham Neubig]] Tags: #adversarial_attacks, #critique, #academic_papers URL: https://arxiv.org/abs/2004.06660 Read on: [[June 1st, 2020]] Code: https://github.com/neulab/RIPPLe</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Weighted-Kappa-Agreement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weighted-Kappa-Agreement/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Weinan-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weinan-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Weisfieler-Lehman-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weisfieler-Lehman-test/</guid><description>[[CE7454 Deep Learning for Data Science Lecture Notes - Recent Developments in Graph Network Architectures]] ![[Pasted image 20201215215925.png]] Takes a pair (node, its neighborhood) (ie k=2) as input, and outputs a new color using a specified function.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Weizhen-Qi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Weizhen-Qi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Wenjie-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Wenjie-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Wenxuan-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Wenxuan-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/What-Can-We-Do-to-Improve-Peer-Review-in-NLP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/What-Can-We-Do-to-Improve-Peer-Review-in-NLP/</guid><description>Author(s): [[Anna Rogers]], [[Isabelle Augenstein]] Tags: #Peer_Review, #academic_papers Read on: [[November 29th, 2020]] URL: https://arxiv.org/abs/2010.03863
Main Contribution(s) Quantifies and analyses the pitfalls of peer review Summary Traditionally, [[Peer Review]] acts as a filter for high-quality impactful work.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/When-Can-Self-Attention-Be-Replaced-by-Feed-Forward-Layers/</guid><description>Author(s): [[Shucong Zhang]], [[Erfan Loweimi]], [[Peter Bell]], [[Steve Renals]] Tags: #critique, #speech_recognition, #transformer, #academic_papers Read on: [[May 29th, 2020]] URL: https://arxiv.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/White-box-attack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/White-box-attack/</guid><description>full information of model, data, architecture, etc</description></item><item><title/><link>https://aibrain.dhecloud.xyz/WiC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WiC/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Widrow-Hoff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Widrow-Hoff/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WIKIHOP-dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WIKIHOP-dataset/</guid><description>[[Deep Learning On Graphs Chapter 10 - Graph Neural Networks in Natural Language Processing]] ![[Pasted image 20201212190620.png]] The WIKIHOP dataset consists of a set of QA samples, and the goal is to choose the current answer from the candidate set.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/WikiText-103/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WikiText-103/</guid><description> 29K Wikipedia Articles (according to [[Probing Neural Dialog Models for Conversational Understanding]])</description></item><item><title/><link>https://aibrain.dhecloud.xyz/William-Chan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/William-Chan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/William-T.-Freeman/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/William-T.-Freeman/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Winograd-NLI/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Winograd-NLI/</guid><description> Variant of [[Winograd]]. Not to be confused with other variants like [[Winogrande]] Included in [[GLUE Benchmark]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Winograd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Winograd/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Winogrande/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Winogrande/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Wizard-of-Wikipedia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Wizard-of-Wikipedia/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT/</guid><description> Workshop on Statistical Machine Translation (WMT) 2014 [[WMT14 Fr-En]], [[WMT14 Fr-En]] [[WMT14 De-En]], [[WMT14 En-De]] 2016 [[WMT16 De-En]], [[WMT16 En-De]] 2017 [[WMT17 En-De]] 2018 [[WMT18 En-De]]</description></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT14-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT14-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT14-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT14-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT14-En-Fr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT14-En-Fr/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT14-Fr-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT14-Fr-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT16-De-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT16-De-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT16-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT16-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT16-En-Ro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT16-En-Ro/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT16-Ro-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT16-Ro-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT17-Automatic-Post-Editing-APE-Task-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT17-Automatic-Post-Editing-APE-Task-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT17-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT17-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT17-En-Zh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT17-En-Zh/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT17-Zh-En/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT17-Zh-En/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WMT18-En-De/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WMT18-En-De/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Wolfgang-Wechler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Wolfgang-Wechler/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Word-Error-Rate-WER/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Word-Error-Rate-WER/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/word2vec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/word2vec/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Working-Memory-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Working-Memory-Model/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/WSJ/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/WSJ/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xian-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xian-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xiang-Gao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xiang-Gao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xiaoyu-Shen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xiaoyu-Shen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xingjian-He/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xingjian-He/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/XinXin-Zhu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/XinXin-Zhu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/XLNet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/XLNet/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xu-Tan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xu-Tan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Xuezhe-Ma/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Xuezhe-Ma/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Y-Lan-Boureau/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Y-Lan-Boureau/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yang-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yang-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yankai-Lin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yankai-Lin/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yanran-Li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yanran-Li/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yap-Kim-Hui/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yap-Kim-Hui/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yejin-Bang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yejin-Bang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yen-Chun-Chen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yen-Chun-Chen/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yeyun-Gong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yeyun-Gong/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yi-Ren/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yi-Ren/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yifeng-Lu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yifeng-Lu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yinhan-Liu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yinhan-Liu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/YiSi-a-Unified-Semantic-MT-Quality-Evaluation-and-Estimation-Metric-for-Languages-with-Different-Levels-of-Available-Resources/</guid><description>Author(s): [[Chi-kiu Lo]] Tags: #Evaluation_Metric, #BERT, #academic_papers Read on: [[June 18th, 2020]] URL: https://www.aclweb.org/anthology/W19-5358
Main Contribution(s) Propose a new automatic metric for [[Neural Machine Translation]] Summary Propose 3 metrics: [[YiSi-0]], [[YiSi-1]], [[YiSi-2]] YiSi is the romanization of 意思 Procedure: Apply a shallow semantic parser to both E and F Apply the maximum weighted bipartite matching algorithm to align the semantic frames between E and F For each pair of aligned frame, apply the maximum weighted bipartite matching algorithm to align the arguments between E and F according to the lexical similarity of role fillers Compute the weighted f-score over the matching role labels of these aligned predicates and role fillers using the lexical weight of E and the lexical similarity of E and F [[YiSi-0]] Metric for extremely low resource languages Uses the longest common character sub-string accuracy to evaluate lexical similarity [[YiSi-1]] Requires an embedding model The lexical semantic similarity is the cosine similarity of the embedding from the lexical representation model [[YiSi-2]] Requires a cross-lingual embedding model Otherwise similar to [[YiSi-1]] [[BERT]] as lexical unit semantic similarity [[GloVe]] and [[word2vec]] are static embeddings and hence provide the same embedding representation for the same word without reflecting context of different sentences.</description></item><item><title/><link>https://aibrain.dhecloud.xyz/YiSi-0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/YiSi-0/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/YiSi-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/YiSi-1/</guid><description> https://www.aclweb.org/anthology/W19-5358.pdf</description></item><item><title/><link>https://aibrain.dhecloud.xyz/YiSi-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/YiSi-2/</guid><description> https://www.aclweb.org/anthology/W19-5358.pdf</description></item><item><title/><link>https://aibrain.dhecloud.xyz/Yizhe-Zhang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yizhe-Zhang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yonatan-Belinkov/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yonatan-Belinkov/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yong-Yu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yong-Yu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Younes-Bensouda-Mourri/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Younes-Bensouda-Mourri/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yu-Bao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yu-Bao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yu-Yan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yu-Yan/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yufan-Jiang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yufan-Jiang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yuiko-Tsunomori/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yuiko-Tsunomori/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Yuka-Kobayashi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Yuka-Kobayashi/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Zhangyang-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Zhangyang-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Zhaopeng-Tu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Zhaopeng-Tu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Zhou-Yu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Zhou-Yu/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Zhou-Zhao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Zhou-Zhao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Zi-Yang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Zi-Yang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ziqiang-Cao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ziqiang-Cao/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ziyang-Luo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ziyang-Luo/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/Ziyang-Wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/Ziyang-Wang/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/%C5%81ukasiewicz-T-norm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/%C5%81ukasiewicz-T-norm/</guid><description/></item><item><title/><link>https://aibrain.dhecloud.xyz/%C5%81ukasz-Kaiser/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aibrain.dhecloud.xyz/%C5%81ukasz-Kaiser/</guid><description/></item></channel></rss>